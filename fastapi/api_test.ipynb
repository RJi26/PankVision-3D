{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMK/rnpH5Ia5i9Mnxpb04jG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%%capture\n","!pip install fastapi nest_asyncio pyngrok uvicorn monai"],"metadata":{"id":"uudO2sZh_JKF","executionInfo":{"status":"ok","timestamp":1694851044111,"user_tz":-600,"elapsed":8137,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djsYMBNw_CDd","executionInfo":{"status":"ok","timestamp":1694851092594,"user_tz":-600,"elapsed":47743,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}},"outputId":"04ad3700-e78e-4a03-f5e3-696fb8fb91e8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Machine-Learning-Biomedicine/PankVision-3D/model/get_model.py /content\n","!cp /content/drive/MyDrive/Machine-Learning-Biomedicine/PankVision-3D/preprocess/final_preprocess.py /content"],"metadata":{"id":"Pjf87jc7_B_n","executionInfo":{"status":"ok","timestamp":1694851097355,"user_tz":-600,"elapsed":4764,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from monai.utils import first, set_determinism\n","from monai.transforms import(\n","    Compose,\n","    AddChanneld,\n","    LoadImaged,\n","    Resized,\n","    ToTensord,\n","    Spacingd,\n","    Orientationd,\n","    ScaleIntensityRanged,\n","    CropForegroundd,\n","    Activations,\n",")\n","\n","from monai.networks.nets import UNet\n","from monai.networks.layers import Norm\n","from monai.data import CacheDataset, DataLoader, Dataset\n","\n","import torch\n","import matplotlib.pyplot as plt\n","\n","import os\n","from glob import glob\n","import numpy as np\n","\n","from monai.inferers import sliding_window_inference\n","from final_preprocess import prepare\n","from get_model import get_model\n","\n","from fastapi import FastAPI, UploadFile\n","from pydantic import BaseModel\n","import nest_asyncio\n","from pyngrok import ngrok\n","import uvicorn\n","\n","import numpy as np\n","from PIL import Image\n","from io import BytesIO"],"metadata":{"id":"UehcFLOK_LUh","executionInfo":{"status":"ok","timestamp":1694851115327,"user_tz":-600,"elapsed":17976,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JIKdRJdH-_hz","executionInfo":{"status":"ok","timestamp":1694852655998,"user_tz":-600,"elapsed":544384,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}},"outputId":"f47d645e-f6f4-4bfe-8485-cba40407f0a6"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pyngrok.process.ngrok:t=2023-09-16T08:15:10+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"]},{"output_type":"stream","name":"stdout","text":["Public URL: NgrokTunnel: \"https://37c2-34-126-84-176.ngrok.io\" -> \"http://localhost:80\"\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [729]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:80 (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     118.211.55.184:0 - \"GET / HTTP/1.1\" 404 Not Found\n","INFO:     118.211.55.184:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n","INFO:     139.218.20.11:0 - \"GET / HTTP/1.1\" 404 Not Found\n","INFO:     118.211.55.184:0 - \"GET /predict HTTP/1.1\" 405 Method Not Allowed\n","INFO:     220.244.136.135:0 - \"GET /predict HTTP/1.1\" 405 Method Not Allowed\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [729]\n"]}],"source":["app = FastAPI()\n","\n","def convert_to_image(file_contents):\n","    \"\"\"\n","    Convert the uploaded file to an image format.\n","    This function assumes that the uploaded file is an image file.\n","    \"\"\"\n","    # Convert the file contents to a BytesIO object\n","    byte_stream = BytesIO(file_contents)\n","\n","    # Open the byte stream as an image\n","    image = Image.open(byte_stream)\n","\n","    # Convert the image to a NumPy array and return it\n","    return np.array(image)\n","\n","def preprocess_nifti_image(image_path):\n","    # Define the transformations\n","    combined_transforms = Compose(\n","        [\n","            LoadImaged(keys=[\"vol\"]),\n","            AddChanneld(keys=[\"vol\"]),\n","            Spacingd(keys=[\"vol\"], pixdim=(1.5, 1.5, 1.0), mode=(\"bilinear\")),\n","            Orientationd(keys=[\"vol\"], axcodes=\"RAS\"),\n","            ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200, b_min=0.0, b_max=1.0, clip=True),\n","            CropForegroundd(keys=['vol'], source_key='vol'),\n","            Resized(keys=[\"vol\"], spatial_size=[128, 128, 64]),\n","            ToTensord(keys=[\"vol\"]),\n","        ]\n","    )\n","\n","    # Create a dataset with the image file and apply the transformations\n","    data = [{\"vol\": image_path}]\n","    ds = Dataset(data=data, transform=combined_transforms)\n","\n","    # Create a DataLoader\n","    loader = DataLoader(ds, batch_size=1)\n","\n","    return loader\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Assuming you have a function to load your model\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","args = {\n","    'model_name': 'DynUNet',\n","    'pretrained': True,\n","    'dropout': 0.1\n","}\n","model = get_model(args)\n","model = model.to(device)\n","\n","# Replace 'model_dir' with the actual path to your model weights\n","model_dir = '/content/drive/MyDrive/Machine-Learning-Biomedicine/PankVision-3D/results/dataset-007/v6dynunet'\n","model_weights_path = os.path.join(model_dir, \"best_metric_model.pth\")\n","\n","model.load_state_dict(torch.load(model_weights_path))\n","model.eval()\n","\n","def run_model(image):\n","    \"\"\"\n","    Run the model on the preprocessed image and get the results.\n","    \"\"\"\n","    # Ensure the model is in evaluation mode\n","    model.eval()\n","\n","    # Move the image to the device used by the model\n","    image = image.to(device)\n","\n","    # Add an extra dimension for the batch size\n","    image = image.unsqueeze(0)\n","\n","    # Run the model on the image\n","    with torch.no_grad():\n","        output = model(image)\n","\n","    # Convert the output to a NumPy array and return it\n","    return output.cpu().numpy()\n","\n","class InputData(BaseModel):\n","    file: UploadFile\n","\n","@app.post(\"/predict\")\n","async def predict(input_data: InputData):\n","    # Read the file\n","    contents = await input_data.file.read()\n","\n","    # Convert the file contents to an image (this will depend on your file format)\n","    image = convert_to_image(contents)\n","\n","    # Preprocess the image\n","    preprocessed_image = preprocess_nifti_image(image)\n","\n","    # Run the model on the preprocessed image and get the results\n","    results = run_model(preprocessed_image)\n","\n","    # Return the results\n","    return {\"results\": results}\n","\n","nest_asyncio.apply()\n","\n","url = ngrok.connect(80)\n","print('Public URL:', url)\n","uvicorn.run(app, host='0.0.0.0', port=80)"]}]}