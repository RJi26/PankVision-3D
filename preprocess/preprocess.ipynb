{"cells":[{"cell_type":"markdown","metadata":{"id":"yNxc7axY4ffa"},"source":["# Installing Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24943,"status":"ok","timestamp":1691108323286,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"vS1c4gpwxHtX","outputId":"0e43dee5-f76d-4d05-f5c2-3cc2efc0056a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_A7_X8i0kYEp"},"outputs":[],"source":["%%capture\n","!pip install Monai\n","!pip install matplotlib\n","!pip install numpy\n","!pip install tqdm\n","!pip install glob2\n","!pip install dicom2nifti\n","!pip install pytest-shutil\n","!pip install nibabel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AehqTWnUxnlb"},"outputs":[],"source":["import torch\n","import nibabel as nib\n","import matplotlib.pyplot as plt\n","import os\n","from tqdm import tqdm\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"V7QMwlJ84cKv"},"source":["# Checking for GPU & Setting up images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1691108375661,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"ofu7uy6xxjwm","outputId":"30c8c9c4-a1b9-4cc1-93f2-92fbfb4a1416"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is available. Training on GPU ...\n"]}],"source":["#check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available. Training on CPU ...')\n","else:\n","    print('CUDA is available. Training on GPU ...')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKDQsLxAw0Go"},"outputs":[],"source":["data = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/panc/imagesTr/'\n","train_images = [os.path.join(data, image_name) for image_name in os.listdir(data) if image_name.endswith('.nii.gz')]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mbJeRD9XxHPP"},"outputs":[],"source":["labels = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/Task07_Pancreas/labelsTr/'\n","train_labels = [os.path.join(labels, image_name) for image_name in os.listdir(labels) if image_name.endswith('.nii.gz')]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"executionInfo":{"elapsed":341,"status":"error","timestamp":1690934316982,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"rpDCOQgw0j4P","outputId":"e2ef5cd0-d538-41f4-b667-cad8ef382121"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-3b5a4fc5f030>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming train_images and train_labels have been defined earlier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_images_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_labels_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Find the missing label file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"]}],"source":["# Assuming train_images and train_labels have been defined earlier\n","train_images_set = set(os.path.basename(image_path) for image_path in train_images)\n","train_labels_set = set(os.path.basename(label_path) for label_path in train_labels)\n","\n","# Find the missing label file name\n","missing_label = list(train_images_set - train_labels_set)\n","\n","print(f\"Missing Label: {missing_label[0]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":268,"status":"ok","timestamp":1690507929635,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"1-AlFMaZ0OV2","outputId":"b2de68bc-0ce5-4a6c-8cf9-a89ed8f643b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["281\n","281\n"]}],"source":["print(len(train_images))\n","print(len(train_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49Rx3JnNyNt_"},"outputs":[],"source":["train_images = sorted(train_images, key=lambda path: path.split('/')[-1])\n","train_labels = sorted(train_labels, key=lambda path: path.split('/')[-1])\n","train_df = pd.DataFrame({\n","    'image_path': train_images,\n","    'label_path': train_labels\n","})"]},{"cell_type":"markdown","metadata":{"id":"CpLvH9PR38VK"},"source":["# Check for invalid files (Does not work!)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hy2adxcI4ApF"},"outputs":[],"source":["image_path = train_df.iloc[0].image_path\n","label_path = train_df.iloc[0].label_path\n","\n","if os.path.basename(image_path).startswith('.') or not image_path.endswith('.nii.gz'):\n","    print(f\"Invalid image file: {image_path}\")\n","else:\n","    img = nib.load(image_path).get_fdata()\n","\n","if os.path.basename(label_path).startswith('.') or not label_path.endswith('.nii.gz'):\n","    print(f\"Invalid label file: {label_path}\")\n","else:\n","    label = nib.load(label_path).get_fdata()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276},"executionInfo":{"elapsed":541,"status":"error","timestamp":1690863653559,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"leln9fj_1GKy","outputId":"34d7dbff-7635-48cd-a42f-d049bc968371"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-95ef75788f60>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Define train_images and train_labels (file paths for images and labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imagesTr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imagesTr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labelsTr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labelsTr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/imagesTr'"]}],"source":["# Function to move files to an invalid folder\n","def move_to_invalid_folder(file_path, invalid_folder):\n","    file_name = os.path.basename(file_path)\n","    destination_path = os.path.join(invalid_folder, file_name)\n","    shutil.move(file_path, destination_path)\n","    print(f\"Moved {file_name} to {invalid_folder}\")\n","\n","# Function to check and move invalid files\n","def check_and_move_invalid_files(df, target_directory):\n","    invalid_images_folder = os.path.join(target_directory, \"invalid_images\")\n","    invalid_labels_folder = os.path.join(target_directory, \"invalid_labels\")\n","\n","    # Create the folders if they don't exist\n","    os.makedirs(invalid_images_folder, exist_ok=True)\n","    os.makedirs(invalid_labels_folder, exist_ok=True)\n","\n","    for index, row in df.iterrows():\n","        image_path = row['image_path']\n","        label_path = row['label_path']\n","\n","        if not os.path.exists(image_path) or not image_path.endswith('.nii.gz'):\n","            move_to_invalid_folder(image_path, invalid_images_folder)\n","\n","        if not os.path.exists(label_path) or not label_path.endswith('.nii.gz'):\n","            move_to_invalid_folder(label_path, invalid_labels_folder)\n","\n","# Define train_images and train_labels (file paths for images and labels)\n","data = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/'\n","train_images = [os.path.join(data, 'imagesTr', image_name) for image_name in os.listdir(os.path.join(data, 'imagesTr')) if image_name.endswith('.nii.gz')]\n","train_labels = [os.path.join(data, 'labelsTr', label_name) for label_name in os.listdir(os.path.join(data, 'labelsTr')) if label_name.endswith('.nii.gz')]\n","\n","# Zip the two lists together to create pairs of (image_path, label_path)\n","train_data = list(zip(train_images, train_labels))\n","\n","# Assuming train_df is already defined\n","invalid_files_directory = \"/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/invalid_files\"\n","\n","print(\"Checking for invalid files and moving them...\")\n","\n","check_and_move_invalid_files(train_df, invalid_files_directory)\n","\n","print(\"All invalid files have been checked and moved.\")\n"]},{"cell_type":"markdown","metadata":{"id":"NiQG1WNb4Zy3"},"source":["# Plotting the Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7oVmVlwcD9UG"},"outputs":[],"source":["import ipywidgets as widgets\n","from IPython.display import display\n","from matplotlib.colors import from_levels_and_colors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rwcbz_Fg4INj"},"outputs":[],"source":["%matplotlib inline\n","img = nib.load(train_df.iloc[50].image_path).get_fdata()\n","label = nib.load(train_df.iloc[50].label_path).get_fdata()\n","\n","# Create a custom colormap\n","my_cmap, _ = from_levels_and_colors(levels=[0, 1, 2], colors=[[0., 0., 0., 0.],  [0., 1., 0., 1], [0.8, 0., 0.8, 1]], extend='max')\n","\n","def plot_slice(slice_number):\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(img[:, :, slice_number], cmap='gray')\n","    plt.imshow(label[:, :, slice_number].astype('int'), cmap=my_cmap, vmin=0., vmax=1.)\n","    plt.title(f\"Slice {slice_number + 1}\")\n","    plt.axis('off')\n","    plt.show()\n","\n","# Create the interactive slider widget\n","slice_slider = widgets.IntSlider(value=0, min=0, max=img.shape[2] - 1, step=1, description='Slice:')\n","widgets.interactive(plot_slice, slice_number=slice_slider)"]},{"cell_type":"markdown","metadata":{"id":"eTxH7pheXaVk"},"source":["Refer to overlay.ipynb to compare the new 64 slices nifti files"]},{"cell_type":"markdown","metadata":{"id":"9IdLBn9WJgZG"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UQJBKRMxlmYg"},"outputs":[],"source":["import os\n","from glob import glob\n","import shutil\n","from tqdm import tqdm\n","import dicom2nifti\n","import numpy as np\n","import nibabel as nib\n","from monai.transforms import(\n","    Compose,\n","    AddChanneld,\n","    LoadImaged,\n","    Resized,\n","    ToTensord,\n","    Spacingd,\n","    Orientationd,\n","    ScaleIntensityRanged,\n","    CropForegroundd,\n",")\n","from monai.data import DataLoader, Dataset, CacheDataset\n","from monai.utils import set_determinism"]},{"cell_type":"markdown","metadata":{"id":"psLzVIbwcaYs"},"source":["# Testing"]},{"cell_type":"markdown","metadata":{"id":"zYZMA3NZg7Nq"},"source":["## Creating Groups"]},{"cell_type":"markdown","metadata":{"id":"pggBy2bI6Xvc"},"source":["Already completed, should not need to run this section again"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3H-PhkUl0bl"},"outputs":[],"source":["def create_groups(in_dir, out_dir, Number_slices):\n","    '''\n","    This function is to get the last part of the path so that we can use it to name the folder.\n","    `in_dir`: the path to your folders that contain dicom files\n","    `out_dir`: the path where you want to put the converted nifti files\n","    `Number_slices`: here you put the number of slices that you need for your project and it will\n","    create groups with this number.\n","    '''\n","\n","    for patient in tqdm(glob(in_dir + '/*')):\n","        patient_name = os.path.basename(os.path.normpath(patient))\n","\n","        # Here we need to calculate the number of folders which mean into how many groups we will divide the number of slices\n","        number_folders = int(len(glob(patient + '/*')) / Number_slices)\n","\n","        for i in range(number_folders):\n","            output_path = os.path.join(out_dir, patient_name + '_' + str(i))\n","            os.mkdir(output_path)\n","            print('made path:' + output_path)\n","\n","            # Move the slices into a specific folder so that you will save memory in your disk\n","            for i, file in enumerate(glob(patient + '/*')):\n","                if i == Number_slices + 1:\n","                    break\n","\n","                shutil.move(file, output_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c8QzIyH0g8tu"},"outputs":[],"source":["# in_path = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/dicom_files/images'\n","# out_path = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/dicom_groups/images'\n","in_path = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/dicom_files/labels'\n","out_path = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/dicom_groups/labels'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJF243YMhRtQ"},"outputs":[],"source":["create_groups(in_path, out_path, 64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lGYTzBYLnxYS"},"outputs":[],"source":["!ls /content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/dicom_groups/images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DrAUkiDQkJae"},"outputs":[],"source":["!ls /content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/dicom_groups/labels"]},{"cell_type":"markdown","metadata":{"id":"OEcGbqqdg9K5"},"source":["## Dcm 2 Nifti"]},{"cell_type":"markdown","metadata":{"id":"RokRHBRc6eYd"},"source":["Already completed, should not need to run this section again"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RE3ltFXNJ1MP"},"outputs":[],"source":["def dcm2nifti(in_dir, out_dir):\n","    '''\n","    This function will be used to convert dicoms into nifti files after creating the groups with\n","    the number of slices that you want.\n","    `in_dir`: the path to the folder where you have all the patients (folder of all the groups).\n","    `out_dir`: the path to the output, which means where you want to save the converted nifties.\n","    '''\n","\n","    for folder in tqdm(glob(in_dir + '/*')):\n","        patient_name = os.path.basename(os.path.normpath(folder))\n","        dicom2nifti.dicom_series_to_nifti(folder, os.path.join(out_dir, patient_name + '.nii.gz'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EN0iiG58cZ0R"},"outputs":[],"source":["in_path_images = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/dicom_groups/images'\n","in_path_labels = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/dicom_groups/labels'\n","out_path_images = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/nifti_files/images'\n","out_path_labels = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/nifti_files/labels'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1299155,"status":"ok","timestamp":1691062555354,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"d-74vn_0kgE2","outputId":"0548664e-466f-4b67-ec85-1141365f160d"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 278/278 [1:37:30<00:00, 21.04s/it]\n"]}],"source":["dcm2nifti(in_path_images, out_path_images) #out of 278\n","# dcm2nifti(in_path_labels, out_path_labels) #out of 278 hopefully..."]},{"cell_type":"markdown","metadata":{"id":"sT_6z60lhkkR"},"source":["## Find Empty"]},{"cell_type":"markdown","metadata":{"id":"zR-_jUP1WWV2"},"source":["Be careful this this section. Might need to rerun. Unclear ATM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzicU_OsJ5Fi"},"outputs":[],"source":["def find_empty(in_dir):\n","    '''\n","    This function will help you to find the empty volumes that you may not need for your training\n","    so instead of opening all the files and search for the empty ones, them use this function to make it quick.\n","    '''\n","\n","    list_patients = []\n","    for patient in tqdm(glob(os.path.join(in_dir, '*'))):\n","        img = nib.load(patient)\n","\n","        if len(np.unique(img.get_fdata())) > 2:\n","            print(os.path.basename(os.path.normpath(patient)))\n","            list_patients.append(os.path.basename(os.path.normpath(patient)))\n","\n","    return list_patients"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZmzo9TsdPZo"},"outputs":[],"source":["# in_dir = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/nifti_files/labels'\n","in_dir_lab = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/nifti_files/images'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VRNAE1B77js"},"outputs":[],"source":["find_empty(in_dir_lab)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnK7_VcN5yTM"},"outputs":[],"source":["find_empty(in_dir)"]},{"cell_type":"markdown","metadata":{"id":"XT7Y9F2-mv-r"},"source":["## Preparing the Data"]},{"cell_type":"markdown","metadata":{"id":"visNKZieWbDf"},"source":["Not running the code here. Run through final_preprocess.py in main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9q6ngi6QJ8HR"},"outputs":[],"source":["def preprocess_image(image, a_min=-200, a_max=200):\n","    # Apply windowing to the image\n","    adjusted_image = (image - 60 + 200) / 400  # Adjust intensity values\n","\n","    # Normalize the adjusted image to the range [0, 1]\n","    normalized_image = (adjusted_image - np.min(adjusted_image)) / (np.max(adjusted_image) - np.min(adjusted_image))\n","\n","    # Apply CLAHE enhancement\n","    enhanced_image = exposure.equalize_adapthist(normalized_image)\n","\n","    return enhanced_image\n","\n","def prepare(in_dir, pixdim=(1.5, 1.5, 1.0), a_min=-200, a_max=200, spatial_size=[128, 128, 64], cache=False):\n","\n","    set_determinism(seed=0)\n","\n","    def combined_transforms(image):\n","        enhanced_image = preprocess_image(image, a_min=a_min, a_max=a_max)\n","        return enhanced_image\n","\n","    path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n","    path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n","\n","    path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n","    path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSegmentation\", \"*.nii.gz\")))\n","\n","    train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n","    test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n","\n","    combined_train_transforms = Compose(\n","        [\n","            LoadImaged(keys=[\"vol\", \"seg\"]),\n","            AddChanneld(keys=[\"vol\", \"seg\"]),\n","            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n","            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n","            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n","            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n","            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n","            # Applying the combined preprocessing function here\n","            combined_transforms(keys=[\"vol\"]),\n","            ToTensord(keys=[\"vol\", \"seg\"]),\n","        ]\n","    )\n","\n","    combined_test_transforms = Compose(\n","        [\n","            LoadImaged(keys=[\"vol\", \"seg\"]),\n","            AddChanneld(keys=[\"vol\", \"seg\"]),\n","            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n","            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n","            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n","            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n","            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n","            # Applying the combined preprocessing function here\n","            combined_transforms(keys=[\"vol\"]),\n","            ToTensord(keys=[\"vol\", \"seg\"]),\n","        ]\n","    )\n","\n","    if cache:\n","        train_ds = CacheDataset(data=train_files, transform=combined_train_transforms, cache_rate=1.0)\n","        train_loader = DataLoader(train_ds, batch_size=1)\n","\n","        test_ds = CacheDataset(data=test_files, transform=combined_test_transforms, cache_rate=1.0)\n","        test_loader = DataLoader(test_ds, batch_size=1)\n","\n","        return train_loader, test_loader\n","\n","    else:\n","        train_ds = Dataset(data=train_files, transform=combined_train_transforms)\n","        train_loader = DataLoader(train_ds, batch_size=1)\n","\n","        test_ds = Dataset(data=test_files, transform=combined_test_transforms)\n","        test_loader = DataLoader(test_ds, batch_size=1)\n","\n","        return train_loader, test_loader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdVk_V0Ao347"},"outputs":[],"source":["data_dir = '/content/drive/MyDrive/Machine-Learning-Biomedicine/Pancreatic-Cancer/pancreas/Data_Train_Test/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lhHOWn7nm1q_"},"outputs":[],"source":["data_in = prepare(data_dir, cache = True)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyORo3L1sW7yiMepBwsLm1vh","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
