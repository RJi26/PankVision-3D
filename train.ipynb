{"cells":[{"cell_type":"markdown","metadata":{"id":"LnCNsTq9994Y"},"source":["# Install Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"eYjhuUq2I44M","executionInfo":{"status":"ok","timestamp":1692920653844,"user_tz":-600,"elapsed":11487,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}}},"outputs":[],"source":["%%capture\n","!pip install monai\n","!pip install dicom2nifti"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24134,"status":"ok","timestamp":1692920677970,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"zsV5Adna65oI","outputId":"682f8554-2225-40b9-fba4-8c3c46dc0df7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Wg3TQ8Zia0s7","executionInfo":{"status":"ok","timestamp":1692920682311,"user_tz":-600,"elapsed":4347,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}}},"outputs":[],"source":["!cp /content/drive/MyDrive/Machine-Learning-Biomedicine/PankVision-3D/preprocess/final_preprocess.py /content\n","!cp /content/drive/MyDrive/Machine-Learning-Biomedicine/PankVision-3D/utilities/final_utilities.py /content\n","!cp /content/drive/MyDrive/Machine-Learning-Biomedicine/PankVision-3D/model/get_model.py /content"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"SUFEgO04I1Gl","executionInfo":{"status":"ok","timestamp":1692920694078,"user_tz":-600,"elapsed":11770,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}}},"outputs":[],"source":["from monai.networks.nets import UNet\n","from monai.networks.layers import Norm\n","from monai.losses import DiceLoss, DiceCELoss\n","\n","import torch\n","from final_utilities import train\n","from get_model import get_model\n","from final_preprocess import preprocess_image, prepare\n","\n","import numpy as np\n","from skimage import exposure\n","from monai.transforms import (\n","    Compose,\n","    LoadImaged,\n","    AddChanneld,\n","    Spacingd,\n","    Orientationd,\n","    ScaleIntensityRanged,\n","    CropForegroundd,\n","    Resized,\n","    ToTensord,\n",")\n","from monai.data import CacheDataset, Dataset, DataLoader\n","from glob import glob\n","import os\n","from monai.utils import set_determinism"]},{"cell_type":"markdown","metadata":{"id":"XwIXQlpH-K2d"},"source":["## Checking for CUDA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1692616515511,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"zhTfwUiUknDz","outputId":"43c2581a-af6e-473b-edb5-d62f62343f2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is available. You can use the GPU.\n"]}],"source":["if torch.cuda.is_available():\n","    print(\"CUDA is available. You can use the GPU.\")\n","else:\n","    print(\"CUDA is not available. You can only use the CPU.\")"]},{"cell_type":"markdown","metadata":{"id":"1jDttZLv-OPm"},"source":["## Preprocess Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YP0-K4Mjk2i5","executionInfo":{"status":"ok","timestamp":1692920694079,"user_tz":-600,"elapsed":13,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}}},"outputs":[],"source":["data_dir = '/content/drive/MyDrive/Machine-Learning-Biomedicine/PankVision-3D/dataset/dataset-007/Data_Train_Test/'"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":981681,"status":"ok","timestamp":1692921675749,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"45Ab0DFFI4p_","outputId":"06cd3f30-293d-4d90-825e-d5e5fe3855d6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n","  warn_deprecated(argname, msg, warning_category)\n","/usr/local/lib/python3.10/dist-packages/monai/utils/deprecate_utils.py:111: FutureWarning: <class 'monai.transforms.utility.dictionary.AddChanneld'>: Class `AddChanneld` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirstd instead with `channel_dim='no_channel'`.\n","  warn_deprecated(obj, msg, warning_category)\n","/usr/local/lib/python3.10/dist-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.transforms.utility.dictionary EnsureChannelFirstd.__init__:meta_keys: Argument `meta_keys` has been deprecated since version 0.9. not needed if image is type `MetaTensor`.\n","  warn_deprecated(argname, msg, warning_category)\n","Loading dataset: 100%|██████████| 222/222 [11:31<00:00,  3.11s/it]\n","Loading dataset: 100%|██████████| 56/56 [04:46<00:00,  5.11s/it]\n"]}],"source":["data_in = prepare(data_dir, cache=True)"]},{"cell_type":"markdown","source":["# Testing New Architecture"],"metadata":{"id":"SEcgAmYTAfzE"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class conv_block(nn.Module):\n","    def __init__(self, in_c, out_c):\n","        super().__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_c),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_c),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class encoder_block(nn.Module):\n","    def __init__(self, in_c, out_c):\n","        super().__init__()\n","\n","        self.conv = conv_block(in_c, out_c)\n","        self.pool = nn.MaxPool2d((2, 2))\n","\n","    def forward(self, x):\n","        s = self.conv(x)\n","        p = self.pool(s)\n","        return s, p\n","\n","class attention_gate(nn.Module):\n","    def __init__(self, in_c, out_c):\n","        super().__init__()\n","\n","        self.Wg = nn.Sequential(\n","            nn.Conv2d(in_c[0], out_c, kernel_size=1, padding=0),\n","            nn.BatchNorm2d(out_c)\n","        )\n","        self.Ws = nn.Sequential(\n","            nn.Conv2d(in_c[1], out_c, kernel_size=1, padding=0),\n","            nn.BatchNorm2d(out_c)\n","        )\n","        self.relu = nn.ReLU(inplace=True)\n","        self.output = nn.Sequential(\n","            nn.Conv2d(out_c, out_c, kernel_size=1, padding=0),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, g, s):\n","        Wg = self.Wg(g)\n","        Ws = self.Ws(s)\n","        out = self.relu(Wg + Ws)\n","        out = self.output(out)\n","        return out * s\n","\n","class decoder_block(nn.Module):\n","    def __init__(self, in_c, out_c):\n","        super().__init__()\n","\n","        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        self.ag = attention_gate(in_c, out_c)\n","        self.c1 = conv_block(in_c[0]+out_c, out_c)\n","\n","    def forward(self, x, s):\n","        x = self.up(x)\n","        s = self.ag(x, s)\n","        x = torch.cat([x, s], axis=1)\n","        x = self.c1(x)\n","        return x\n","\n","class attention_unet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.e1 = encoder_block(3, 64)\n","        self.e2 = encoder_block(64, 128)\n","        self.e3 = encoder_block(128, 256)\n","\n","        self.b1 = conv_block(256, 512)\n","\n","        self.d1 = decoder_block([512, 256], 256)\n","        self.d2 = decoder_block([256, 128], 128)\n","        self.d3 = decoder_block([128, 64], 64)\n","\n","        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n","\n","    def forward(self, x):\n","        s1, p1 = self.e1(x)\n","        s2, p2 = self.e2(p1)\n","        s3, p3 = self.e3(p2)\n","\n","        b1 = self.b1(p3)\n","\n","        d1 = self.d1(b1, s3)\n","        d2 = self.d2(d1, s2)\n","        d3 = self.d3(d2, s1)\n","\n","        output = self.output(d3)\n","        return output\n","\n","\n","if __name__ == \"__main__\":\n","    x = torch.randn((8, 3, 256, 256))\n","    model = attention_unet()\n","    output = model(x)\n","    print(output.shape)"],"metadata":{"id":"BkSK0nF4AfQr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"36FPHWIw1GMS"},"source":["# Training"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"RtL9BAWlGN6z","executionInfo":{"status":"ok","timestamp":1692921675749,"user_tz":-600,"elapsed":6,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"}}},"outputs":[],"source":["model_dir = '/content/drive/MyDrive/Machine-Learning-Biomedicine/PankVision-3D/results/dataset-007/v7'"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2485364,"status":"error","timestamp":1692930548043,"user":{"displayName":"Richard Ji","userId":"09391666119164262630"},"user_tz":-600},"id":"5ROxEVxEfMCR","outputId":"5198c8e1-a85b-4774-9fac-9e44e1cf78a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","49/222, Train_loss: 0.0762\n","Train_dice: 0.9324\n","50/222, Train_loss: 0.0673\n","Train_dice: 0.9375\n","51/222, Train_loss: 0.2724\n","Train_dice: 0.6963\n","52/222, Train_loss: 0.0695\n","Train_dice: 0.9367\n","53/222, Train_loss: 0.0584\n","Train_dice: 0.9531\n","54/222, Train_loss: 0.0709\n","Train_dice: 0.9411\n","55/222, Train_loss: 0.0591\n","Train_dice: 0.9512\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0569\n","Train_dice: 0.9528\n","58/222, Train_loss: 0.0695\n","Train_dice: 0.9399\n","59/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","60/222, Train_loss: 0.0625\n","Train_dice: 0.9479\n","61/222, Train_loss: 0.0588\n","Train_dice: 0.9497\n","62/222, Train_loss: 0.0731\n","Train_dice: 0.9346\n","63/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","64/222, Train_loss: 0.0829\n","Train_dice: 0.9248\n","65/222, Train_loss: 0.0615\n","Train_dice: 0.9434\n","66/222, Train_loss: 0.0557\n","Train_dice: 0.9498\n","67/222, Train_loss: 0.0685\n","Train_dice: 0.9397\n","68/222, Train_loss: 0.0644\n","Train_dice: 0.9449\n","69/222, Train_loss: 0.0492\n","Train_dice: 0.9537\n","70/222, Train_loss: 0.0509\n","Train_dice: 0.9563\n","71/222, Train_loss: 0.0682\n","Train_dice: 0.9395\n","72/222, Train_loss: 0.0506\n","Train_dice: 0.9574\n","73/222, Train_loss: 0.0522\n","Train_dice: 0.9542\n","74/222, Train_loss: 0.0583\n","Train_dice: 0.9453\n","75/222, Train_loss: 0.0532\n","Train_dice: 0.9547\n","76/222, Train_loss: 0.0944\n","Train_dice: 0.9077\n","77/222, Train_loss: 0.0802\n","Train_dice: 0.9234\n","78/222, Train_loss: 0.0610\n","Train_dice: 0.9456\n","79/222, Train_loss: 0.0929\n","Train_dice: 0.9116\n","80/222, Train_loss: 0.0748\n","Train_dice: 0.9259\n","81/222, Train_loss: 0.0546\n","Train_dice: 0.9461\n","82/222, Train_loss: 0.0818\n","Train_dice: 0.9188\n","83/222, Train_loss: 0.0520\n","Train_dice: 0.9548\n","84/222, Train_loss: 0.0644\n","Train_dice: 0.9433\n","85/222, Train_loss: 0.0654\n","Train_dice: 0.9427\n","86/222, Train_loss: 0.0864\n","Train_dice: 0.9098\n","87/222, Train_loss: 0.0865\n","Train_dice: 0.9190\n","88/222, Train_loss: 0.0650\n","Train_dice: 0.9444\n","89/222, Train_loss: 0.0575\n","Train_dice: 0.9476\n","90/222, Train_loss: 0.0798\n","Train_dice: 0.9163\n","91/222, Train_loss: 0.0580\n","Train_dice: 0.9405\n","92/222, Train_loss: 0.0547\n","Train_dice: 0.9505\n","93/222, Train_loss: 0.0821\n","Train_dice: 0.9218\n","94/222, Train_loss: 0.0802\n","Train_dice: 0.9220\n","95/222, Train_loss: 0.0962\n","Train_dice: 0.9036\n","96/222, Train_loss: 0.0584\n","Train_dice: 0.9467\n","97/222, Train_loss: 0.0622\n","Train_dice: 0.9400\n","98/222, Train_loss: 0.0720\n","Train_dice: 0.9256\n","99/222, Train_loss: 0.0619\n","Train_dice: 0.9415\n","100/222, Train_loss: 0.0774\n","Train_dice: 0.9223\n","101/222, Train_loss: 0.0629\n","Train_dice: 0.9437\n","102/222, Train_loss: 0.0538\n","Train_dice: 0.9522\n","103/222, Train_loss: 0.0759\n","Train_dice: 0.9355\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0481\n","Train_dice: 0.9356\n","106/222, Train_loss: 0.0556\n","Train_dice: 0.9411\n","107/222, Train_loss: 0.0674\n","Train_dice: 0.9369\n","108/222, Train_loss: 0.0615\n","Train_dice: 0.9430\n","109/222, Train_loss: 0.0622\n","Train_dice: 0.9427\n","110/222, Train_loss: 0.0653\n","Train_dice: 0.9290\n","111/222, Train_loss: 0.0650\n","Train_dice: 0.9365\n","112/222, Train_loss: 0.0591\n","Train_dice: 0.9519\n","113/222, Train_loss: 0.0633\n","Train_dice: 0.9451\n","114/222, Train_loss: 0.0759\n","Train_dice: 0.9203\n","115/222, Train_loss: 0.0580\n","Train_dice: 0.9508\n","116/222, Train_loss: 0.0544\n","Train_dice: 0.9498\n","117/222, Train_loss: 0.0714\n","Train_dice: 0.9373\n","118/222, Train_loss: 0.0754\n","Train_dice: 0.9234\n","119/222, Train_loss: 0.0656\n","Train_dice: 0.9374\n","120/222, Train_loss: 0.0594\n","Train_dice: 0.9489\n","121/222, Train_loss: 0.0686\n","Train_dice: 0.9405\n","122/222, Train_loss: 0.0666\n","Train_dice: 0.9443\n","123/222, Train_loss: 0.0564\n","Train_dice: 0.9461\n","124/222, Train_loss: 0.0808\n","Train_dice: 0.8050\n","125/222, Train_loss: 0.0679\n","Train_dice: 0.9304\n","126/222, Train_loss: 0.0729\n","Train_dice: 0.9315\n","127/222, Train_loss: 0.0568\n","Train_dice: 0.9382\n","128/222, Train_loss: 0.0695\n","Train_dice: 0.9415\n","129/222, Train_loss: 0.0525\n","Train_dice: 0.9556\n","130/222, Train_loss: 0.0524\n","Train_dice: 0.9498\n","131/222, Train_loss: 0.0526\n","Train_dice: 0.9511\n","132/222, Train_loss: 0.0578\n","Train_dice: 0.9458\n","133/222, Train_loss: 0.0610\n","Train_dice: 0.9398\n","134/222, Train_loss: 0.0749\n","Train_dice: 0.9287\n","135/222, Train_loss: 0.0561\n","Train_dice: 0.9530\n","136/222, Train_loss: 0.0503\n","Train_dice: 0.9498\n","137/222, Train_loss: 0.0633\n","Train_dice: 0.9334\n","138/222, Train_loss: 0.0718\n","Train_dice: 0.9397\n","139/222, Train_loss: 0.0638\n","Train_dice: 0.9458\n","140/222, Train_loss: 0.0586\n","Train_dice: 0.9486\n","141/222, Train_loss: 0.0564\n","Train_dice: 0.9469\n","142/222, Train_loss: 0.0582\n","Train_dice: 0.9479\n","143/222, Train_loss: 0.0612\n","Train_dice: 0.9415\n","144/222, Train_loss: 0.0585\n","Train_dice: 0.9436\n","145/222, Train_loss: 0.0543\n","Train_dice: 0.9491\n","146/222, Train_loss: 0.0642\n","Train_dice: 0.9341\n","147/222, Train_loss: 0.0572\n","Train_dice: 0.9474\n","148/222, Train_loss: 0.0589\n","Train_dice: 0.9489\n","149/222, Train_loss: 0.1306\n","Train_dice: 0.8706\n","150/222, Train_loss: 0.0738\n","Train_dice: 0.9260\n","151/222, Train_loss: 0.0733\n","Train_dice: 0.9235\n","152/222, Train_loss: 0.0815\n","Train_dice: 0.9232\n","153/222, Train_loss: 0.0646\n","Train_dice: 0.9381\n","154/222, Train_loss: 0.0843\n","Train_dice: 0.9082\n","155/222, Train_loss: 0.0749\n","Train_dice: 0.9289\n","156/222, Train_loss: 0.0573\n","Train_dice: 0.9376\n","157/222, Train_loss: 0.0693\n","Train_dice: 0.9389\n","158/222, Train_loss: 0.0609\n","Train_dice: 0.9429\n","159/222, Train_loss: 0.0632\n","Train_dice: 0.9345\n","160/222, Train_loss: 0.0527\n","Train_dice: 0.9527\n","161/222, Train_loss: 0.0685\n","Train_dice: 0.9091\n","162/222, Train_loss: 0.0610\n","Train_dice: 0.9454\n","163/222, Train_loss: 0.0555\n","Train_dice: 0.9453\n","164/222, Train_loss: 0.0609\n","Train_dice: 0.9457\n","165/222, Train_loss: 0.0919\n","Train_dice: 0.9113\n","166/222, Train_loss: 0.0625\n","Train_dice: 0.9463\n","167/222, Train_loss: 0.0558\n","Train_dice: 0.9486\n","168/222, Train_loss: 0.0815\n","Train_dice: 0.9242\n","169/222, Train_loss: 0.0637\n","Train_dice: 0.9442\n","170/222, Train_loss: 0.0693\n","Train_dice: 0.9393\n","171/222, Train_loss: 0.0714\n","Train_dice: 0.9155\n","172/222, Train_loss: 0.0468\n","Train_dice: 0.9518\n","173/222, Train_loss: 0.1236\n","Train_dice: 0.8618\n","174/222, Train_loss: 0.0958\n","Train_dice: 0.9083\n","175/222, Train_loss: 0.0715\n","Train_dice: 0.9268\n","176/222, Train_loss: 0.0696\n","Train_dice: 0.9305\n","177/222, Train_loss: 0.0786\n","Train_dice: 0.9209\n","178/222, Train_loss: 0.0938\n","Train_dice: 0.9108\n","179/222, Train_loss: 0.0806\n","Train_dice: 0.9270\n","180/222, Train_loss: 0.1457\n","Train_dice: 0.7860\n","181/222, Train_loss: 0.0879\n","Train_dice: 0.9193\n","182/222, Train_loss: 0.0731\n","Train_dice: 0.9417\n","183/222, Train_loss: 0.0950\n","Train_dice: 0.8759\n","184/222, Train_loss: 0.0656\n","Train_dice: 0.9423\n","185/222, Train_loss: 0.0643\n","Train_dice: 0.9464\n","186/222, Train_loss: 0.0753\n","Train_dice: 0.9363\n","187/222, Train_loss: 0.0555\n","Train_dice: 0.9528\n","188/222, Train_loss: 0.0889\n","Train_dice: 0.9250\n","189/222, Train_loss: 0.0698\n","Train_dice: 0.9342\n","190/222, Train_loss: 0.0662\n","Train_dice: 0.9424\n","191/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0483\n","Train_dice: 0.9606\n","195/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0593\n","Train_dice: 0.9453\n","197/222, Train_loss: 0.1019\n","Train_dice: 0.8708\n","198/222, Train_loss: 0.0471\n","Train_dice: 0.9598\n","199/222, Train_loss: 0.0668\n","Train_dice: 0.9367\n","200/222, Train_loss: 0.0604\n","Train_dice: 0.9378\n","201/222, Train_loss: 0.0533\n","Train_dice: 0.9445\n","202/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","203/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","204/222, Train_loss: 0.0656\n","Train_dice: 0.9374\n","205/222, Train_loss: 0.0788\n","Train_dice: 0.9290\n","206/222, Train_loss: 0.0692\n","Train_dice: 0.9387\n","207/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","208/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","209/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","210/222, Train_loss: 0.5004\n","Train_dice: 0.4998\n","211/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0839\n","Train_dice: 0.9205\n","214/222, Train_loss: 0.0417\n","Train_dice: 0.9622\n","215/222, Train_loss: 0.0532\n","Train_dice: 0.9553\n","216/222, Train_loss: 0.0605\n","Train_dice: 0.9445\n","217/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","218/222, Train_loss: 0.0660\n","Train_dice: 0.9361\n","219/222, Train_loss: 0.0565\n","Train_dice: 0.9505\n","220/222, Train_loss: 0.0800\n","Train_dice: 0.8862\n","221/222, Train_loss: 0.3485\n","Train_dice: 0.5558\n","222/222, Train_loss: 0.0579\n","Train_dice: 0.9386\n","--------------------\n","Epoch_loss: 0.1027\n","Epoch_metric: 0.8990\n","test_loss_epoch: 0.2141\n","test_dice_epoch: 0.7995\n","Confusion Matrix:\n","[[58301152    62382]\n"," [  176805   179917]]\n","test_loss_epoch: 0.0038\n","test_dice_epoch: 0.0143\n","current epoch: 33 current mean dice: 0.8654\n","best mean dice: 0.0143 at epoch: 31\n","----------\n","epoch 34/150\n","1/222, Train_loss: 0.0528\n","Train_dice: 0.9520\n","2/222, Train_loss: 0.0652\n","Train_dice: 0.9457\n","3/222, Train_loss: 0.0548\n","Train_dice: 0.9526\n","4/222, Train_loss: 0.0427\n","Train_dice: 0.9629\n","5/222, Train_loss: 0.0604\n","Train_dice: 0.9524\n","6/222, Train_loss: 0.0721\n","Train_dice: 0.9382\n","7/222, Train_loss: 0.0485\n","Train_dice: 0.9589\n","8/222, Train_loss: 0.0509\n","Train_dice: 0.9573\n","9/222, Train_loss: 0.0593\n","Train_dice: 0.9491\n","10/222, Train_loss: 0.0506\n","Train_dice: 0.9550\n","11/222, Train_loss: 0.0581\n","Train_dice: 0.9498\n","12/222, Train_loss: 0.0587\n","Train_dice: 0.9520\n","13/222, Train_loss: 0.0695\n","Train_dice: 0.9426\n","14/222, Train_loss: 0.0653\n","Train_dice: 0.9472\n","15/222, Train_loss: 0.0572\n","Train_dice: 0.9498\n","16/222, Train_loss: 0.0737\n","Train_dice: 0.9313\n","17/222, Train_loss: 0.0727\n","Train_dice: 0.9338\n","18/222, Train_loss: 0.0530\n","Train_dice: 0.9546\n","19/222, Train_loss: 0.0761\n","Train_dice: 0.9257\n","20/222, Train_loss: 0.1051\n","Train_dice: 0.8958\n","21/222, Train_loss: 0.0810\n","Train_dice: 0.9228\n","22/222, Train_loss: 0.0719\n","Train_dice: 0.9405\n","23/222, Train_loss: 0.0580\n","Train_dice: 0.9462\n","24/222, Train_loss: 0.0644\n","Train_dice: 0.9389\n","25/222, Train_loss: 0.1498\n","Train_dice: 0.7971\n","26/222, Train_loss: 0.0629\n","Train_dice: 0.9463\n","27/222, Train_loss: 0.0585\n","Train_dice: 0.9505\n","28/222, Train_loss: 0.0902\n","Train_dice: 0.8773\n","29/222, Train_loss: 0.0594\n","Train_dice: 0.9451\n","30/222, Train_loss: 0.0666\n","Train_dice: 0.9332\n","31/222, Train_loss: 0.0677\n","Train_dice: 0.9371\n","32/222, Train_loss: 0.0490\n","Train_dice: 0.9561\n","33/222, Train_loss: 0.0683\n","Train_dice: 0.9379\n","34/222, Train_loss: 0.0700\n","Train_dice: 0.9416\n","35/222, Train_loss: 0.0479\n","Train_dice: 0.9591\n","36/222, Train_loss: 0.0686\n","Train_dice: 0.9431\n","37/222, Train_loss: 0.0552\n","Train_dice: 0.9559\n","38/222, Train_loss: 0.0965\n","Train_dice: 0.9139\n","39/222, Train_loss: 0.0431\n","Train_dice: 0.9631\n","40/222, Train_loss: 0.0527\n","Train_dice: 0.9548\n","41/222, Train_loss: 0.1099\n","Train_dice: 0.8802\n","42/222, Train_loss: 0.0721\n","Train_dice: 0.9380\n","43/222, Train_loss: 0.0580\n","Train_dice: 0.9510\n","44/222, Train_loss: 0.1061\n","Train_dice: 0.7975\n","45/222, Train_loss: 0.0639\n","Train_dice: 0.9348\n","46/222, Train_loss: 0.0604\n","Train_dice: 0.9498\n","47/222, Train_loss: 0.0626\n","Train_dice: 0.9338\n","48/222, Train_loss: 0.0589\n","Train_dice: 0.9448\n","49/222, Train_loss: 0.0824\n","Train_dice: 0.9219\n","50/222, Train_loss: 0.0773\n","Train_dice: 0.9201\n","51/222, Train_loss: 0.2868\n","Train_dice: 0.6909\n","52/222, Train_loss: 0.0784\n","Train_dice: 0.9254\n","53/222, Train_loss: 0.0544\n","Train_dice: 0.9496\n","54/222, Train_loss: 0.0638\n","Train_dice: 0.9443\n","55/222, Train_loss: 0.0530\n","Train_dice: 0.9548\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0587\n","Train_dice: 0.9486\n","58/222, Train_loss: 0.0661\n","Train_dice: 0.9421\n","59/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","60/222, Train_loss: 0.0599\n","Train_dice: 0.9481\n","61/222, Train_loss: 0.0574\n","Train_dice: 0.9532\n","62/222, Train_loss: 0.0774\n","Train_dice: 0.9352\n","63/222, Train_loss: 0.5004\n","Train_dice: 0.4997\n","64/222, Train_loss: 0.0795\n","Train_dice: 0.9324\n","65/222, Train_loss: 0.0602\n","Train_dice: 0.9490\n","66/222, Train_loss: 0.0578\n","Train_dice: 0.9522\n","67/222, Train_loss: 0.0783\n","Train_dice: 0.9344\n","68/222, Train_loss: 0.0640\n","Train_dice: 0.9457\n","69/222, Train_loss: 0.0499\n","Train_dice: 0.9551\n","70/222, Train_loss: 0.0548\n","Train_dice: 0.9551\n","71/222, Train_loss: 0.0683\n","Train_dice: 0.9334\n","72/222, Train_loss: 0.0478\n","Train_dice: 0.9609\n","73/222, Train_loss: 0.0582\n","Train_dice: 0.9477\n","74/222, Train_loss: 0.0570\n","Train_dice: 0.9463\n","75/222, Train_loss: 0.0504\n","Train_dice: 0.9557\n","76/222, Train_loss: 0.0893\n","Train_dice: 0.9112\n","77/222, Train_loss: 0.0929\n","Train_dice: 0.9114\n","78/222, Train_loss: 0.0604\n","Train_dice: 0.9472\n","79/222, Train_loss: 0.0820\n","Train_dice: 0.9236\n","80/222, Train_loss: 0.0823\n","Train_dice: 0.9200\n","81/222, Train_loss: 0.0528\n","Train_dice: 0.9527\n","82/222, Train_loss: 0.0612\n","Train_dice: 0.9403\n","83/222, Train_loss: 0.0530\n","Train_dice: 0.9518\n","84/222, Train_loss: 0.0765\n","Train_dice: 0.9263\n","85/222, Train_loss: 0.0715\n","Train_dice: 0.9353\n","86/222, Train_loss: 0.1013\n","Train_dice: 0.8910\n","87/222, Train_loss: 0.0760\n","Train_dice: 0.9236\n","88/222, Train_loss: 0.0573\n","Train_dice: 0.9467\n","89/222, Train_loss: 0.0663\n","Train_dice: 0.9408\n","90/222, Train_loss: 0.0741\n","Train_dice: 0.9247\n","91/222, Train_loss: 0.0621\n","Train_dice: 0.9407\n","92/222, Train_loss: 0.0630\n","Train_dice: 0.9438\n","93/222, Train_loss: 0.0719\n","Train_dice: 0.9323\n","94/222, Train_loss: 0.0668\n","Train_dice: 0.9383\n","95/222, Train_loss: 0.0872\n","Train_dice: 0.9145\n","96/222, Train_loss: 0.0545\n","Train_dice: 0.9523\n","97/222, Train_loss: 0.0717\n","Train_dice: 0.9347\n","98/222, Train_loss: 0.0699\n","Train_dice: 0.9258\n","99/222, Train_loss: 0.0622\n","Train_dice: 0.9417\n","100/222, Train_loss: 0.0711\n","Train_dice: 0.9313\n","101/222, Train_loss: 0.0699\n","Train_dice: 0.9393\n","102/222, Train_loss: 0.0553\n","Train_dice: 0.9497\n","103/222, Train_loss: 0.0666\n","Train_dice: 0.9443\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0476\n","Train_dice: 0.9353\n","106/222, Train_loss: 0.0547\n","Train_dice: 0.9443\n","107/222, Train_loss: 0.0678\n","Train_dice: 0.9360\n","108/222, Train_loss: 0.0728\n","Train_dice: 0.9270\n","109/222, Train_loss: 0.0629\n","Train_dice: 0.9379\n","110/222, Train_loss: 0.0616\n","Train_dice: 0.9325\n","111/222, Train_loss: 0.0603\n","Train_dice: 0.9422\n","112/222, Train_loss: 0.0647\n","Train_dice: 0.9410\n","113/222, Train_loss: 0.0711\n","Train_dice: 0.9390\n","114/222, Train_loss: 0.0779\n","Train_dice: 0.9222\n","115/222, Train_loss: 0.0544\n","Train_dice: 0.9525\n","116/222, Train_loss: 0.0499\n","Train_dice: 0.9567\n","117/222, Train_loss: 0.0727\n","Train_dice: 0.9371\n","118/222, Train_loss: 0.0822\n","Train_dice: 0.9174\n","119/222, Train_loss: 0.0821\n","Train_dice: 0.9290\n","120/222, Train_loss: 0.0560\n","Train_dice: 0.9512\n","121/222, Train_loss: 0.0626\n","Train_dice: 0.9441\n","122/222, Train_loss: 0.0716\n","Train_dice: 0.9378\n","123/222, Train_loss: 0.0549\n","Train_dice: 0.9486\n","124/222, Train_loss: 0.1215\n","Train_dice: 0.8091\n","125/222, Train_loss: 0.0737\n","Train_dice: 0.9265\n","126/222, Train_loss: 0.0723\n","Train_dice: 0.9304\n","127/222, Train_loss: 0.0650\n","Train_dice: 0.9337\n","128/222, Train_loss: 0.0639\n","Train_dice: 0.9445\n","129/222, Train_loss: 0.0500\n","Train_dice: 0.9557\n","130/222, Train_loss: 0.0508\n","Train_dice: 0.9514\n","131/222, Train_loss: 0.0498\n","Train_dice: 0.9538\n","132/222, Train_loss: 0.0618\n","Train_dice: 0.9433\n","133/222, Train_loss: 0.0571\n","Train_dice: 0.9447\n","134/222, Train_loss: 0.0742\n","Train_dice: 0.9289\n","135/222, Train_loss: 0.0543\n","Train_dice: 0.9522\n","136/222, Train_loss: 0.0479\n","Train_dice: 0.9547\n","137/222, Train_loss: 0.0542\n","Train_dice: 0.9436\n","138/222, Train_loss: 0.0620\n","Train_dice: 0.9429\n","139/222, Train_loss: 0.0579\n","Train_dice: 0.9458\n","140/222, Train_loss: 0.0517\n","Train_dice: 0.9531\n","141/222, Train_loss: 0.0560\n","Train_dice: 0.9503\n","142/222, Train_loss: 0.0640\n","Train_dice: 0.9411\n","143/222, Train_loss: 0.0602\n","Train_dice: 0.9464\n","144/222, Train_loss: 0.0586\n","Train_dice: 0.9497\n","145/222, Train_loss: 0.0577\n","Train_dice: 0.9473\n","146/222, Train_loss: 0.0683\n","Train_dice: 0.9340\n","147/222, Train_loss: 0.0639\n","Train_dice: 0.9458\n","148/222, Train_loss: 0.0598\n","Train_dice: 0.9493\n","149/222, Train_loss: 0.0897\n","Train_dice: 0.9075\n","150/222, Train_loss: 0.0696\n","Train_dice: 0.9272\n","151/222, Train_loss: 0.0771\n","Train_dice: 0.9218\n","152/222, Train_loss: 0.0845\n","Train_dice: 0.9236\n","153/222, Train_loss: 0.0711\n","Train_dice: 0.9304\n","154/222, Train_loss: 0.0927\n","Train_dice: 0.9000\n","155/222, Train_loss: 0.0694\n","Train_dice: 0.9361\n","156/222, Train_loss: 0.0579\n","Train_dice: 0.9337\n","157/222, Train_loss: 0.0605\n","Train_dice: 0.9411\n","158/222, Train_loss: 0.0625\n","Train_dice: 0.9419\n","159/222, Train_loss: 0.0730\n","Train_dice: 0.9290\n","160/222, Train_loss: 0.0581\n","Train_dice: 0.9475\n","161/222, Train_loss: 0.0708\n","Train_dice: 0.9104\n","162/222, Train_loss: 0.0628\n","Train_dice: 0.9402\n","163/222, Train_loss: 0.0729\n","Train_dice: 0.9321\n","164/222, Train_loss: 0.0602\n","Train_dice: 0.9459\n","165/222, Train_loss: 0.0810\n","Train_dice: 0.9176\n","166/222, Train_loss: 0.0519\n","Train_dice: 0.9542\n","167/222, Train_loss: 0.0611\n","Train_dice: 0.9481\n","168/222, Train_loss: 0.0768\n","Train_dice: 0.9285\n","169/222, Train_loss: 0.0623\n","Train_dice: 0.9423\n","170/222, Train_loss: 0.0774\n","Train_dice: 0.9342\n","171/222, Train_loss: 0.0718\n","Train_dice: 0.9179\n","172/222, Train_loss: 0.0480\n","Train_dice: 0.9507\n","173/222, Train_loss: 0.1060\n","Train_dice: 0.8769\n","174/222, Train_loss: 0.0935\n","Train_dice: 0.9131\n","175/222, Train_loss: 0.0700\n","Train_dice: 0.9337\n","176/222, Train_loss: 0.0648\n","Train_dice: 0.9394\n","177/222, Train_loss: 0.0721\n","Train_dice: 0.9288\n","178/222, Train_loss: 0.0923\n","Train_dice: 0.9151\n","179/222, Train_loss: 0.0678\n","Train_dice: 0.9371\n","180/222, Train_loss: 0.1170\n","Train_dice: 0.8299\n","181/222, Train_loss: 0.0861\n","Train_dice: 0.9146\n","182/222, Train_loss: 0.0582\n","Train_dice: 0.9512\n","183/222, Train_loss: 0.0633\n","Train_dice: 0.9120\n","184/222, Train_loss: 0.0624\n","Train_dice: 0.9436\n","185/222, Train_loss: 0.0541\n","Train_dice: 0.9555\n","186/222, Train_loss: 0.0649\n","Train_dice: 0.9443\n","187/222, Train_loss: 0.0504\n","Train_dice: 0.9517\n","188/222, Train_loss: 0.0754\n","Train_dice: 0.9366\n","189/222, Train_loss: 0.0707\n","Train_dice: 0.9343\n","190/222, Train_loss: 0.0667\n","Train_dice: 0.9412\n","191/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0455\n","Train_dice: 0.9620\n","195/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0667\n","Train_dice: 0.9430\n","197/222, Train_loss: 0.0954\n","Train_dice: 0.8882\n","198/222, Train_loss: 0.0496\n","Train_dice: 0.9603\n","199/222, Train_loss: 0.0617\n","Train_dice: 0.9430\n","200/222, Train_loss: 0.0549\n","Train_dice: 0.9445\n","201/222, Train_loss: 0.0917\n","Train_dice: 0.9159\n","202/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","203/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","204/222, Train_loss: 0.0666\n","Train_dice: 0.9432\n","205/222, Train_loss: 0.0769\n","Train_dice: 0.9251\n","206/222, Train_loss: 0.0610\n","Train_dice: 0.9461\n","207/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","208/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","209/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","210/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","211/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","213/222, Train_loss: 0.0848\n","Train_dice: 0.9241\n","214/222, Train_loss: 0.0393\n","Train_dice: 0.9618\n","215/222, Train_loss: 0.0512\n","Train_dice: 0.9585\n","216/222, Train_loss: 0.0650\n","Train_dice: 0.9405\n","217/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0689\n","Train_dice: 0.9316\n","219/222, Train_loss: 0.0605\n","Train_dice: 0.9467\n","220/222, Train_loss: 0.1046\n","Train_dice: 0.8886\n","221/222, Train_loss: 0.3984\n","Train_dice: 0.5870\n","222/222, Train_loss: 0.0568\n","Train_dice: 0.9443\n","--------------------\n","Epoch_loss: 0.1028\n","Epoch_metric: 0.8996\n","test_loss_epoch: 0.2150\n","test_dice_epoch: 0.7987\n","Confusion Matrix:\n","[[58302947    60587]\n"," [  179325   177397]]\n","test_loss_epoch: 0.0038\n","test_dice_epoch: 0.0143\n","current epoch: 34 current mean dice: 0.8721\n","best mean dice: 0.0143 at epoch: 31\n","----------\n","epoch 35/150\n","1/222, Train_loss: 0.0541\n","Train_dice: 0.9505\n","2/222, Train_loss: 0.0675\n","Train_dice: 0.9410\n","3/222, Train_loss: 0.0525\n","Train_dice: 0.9556\n","4/222, Train_loss: 0.0364\n","Train_dice: 0.9665\n","5/222, Train_loss: 0.0657\n","Train_dice: 0.9452\n","6/222, Train_loss: 0.0604\n","Train_dice: 0.9483\n","7/222, Train_loss: 0.0469\n","Train_dice: 0.9596\n","8/222, Train_loss: 0.0529\n","Train_dice: 0.9549\n","9/222, Train_loss: 0.0473\n","Train_dice: 0.9567\n","10/222, Train_loss: 0.0521\n","Train_dice: 0.9531\n","11/222, Train_loss: 0.0543\n","Train_dice: 0.9536\n","12/222, Train_loss: 0.0596\n","Train_dice: 0.9521\n","13/222, Train_loss: 0.0702\n","Train_dice: 0.9423\n","14/222, Train_loss: 0.0680\n","Train_dice: 0.9446\n","15/222, Train_loss: 0.0600\n","Train_dice: 0.9487\n","16/222, Train_loss: 0.0725\n","Train_dice: 0.9361\n","17/222, Train_loss: 0.0734\n","Train_dice: 0.9366\n","18/222, Train_loss: 0.0527\n","Train_dice: 0.9563\n","19/222, Train_loss: 0.0492\n","Train_dice: 0.9520\n","20/222, Train_loss: 0.0694\n","Train_dice: 0.9307\n","21/222, Train_loss: 0.0590\n","Train_dice: 0.9420\n","22/222, Train_loss: 0.0655\n","Train_dice: 0.9442\n","23/222, Train_loss: 0.0577\n","Train_dice: 0.9465\n","24/222, Train_loss: 0.0722\n","Train_dice: 0.9309\n","25/222, Train_loss: 0.1611\n","Train_dice: 0.7542\n","26/222, Train_loss: 0.0588\n","Train_dice: 0.9488\n","27/222, Train_loss: 0.0560\n","Train_dice: 0.9520\n","28/222, Train_loss: 0.0844\n","Train_dice: 0.8934\n","29/222, Train_loss: 0.0602\n","Train_dice: 0.9456\n","30/222, Train_loss: 0.0714\n","Train_dice: 0.9308\n","31/222, Train_loss: 0.0687\n","Train_dice: 0.9380\n","32/222, Train_loss: 0.0512\n","Train_dice: 0.9490\n","33/222, Train_loss: 0.0625\n","Train_dice: 0.9448\n","34/222, Train_loss: 0.0755\n","Train_dice: 0.9323\n","35/222, Train_loss: 0.0523\n","Train_dice: 0.9518\n","36/222, Train_loss: 0.0637\n","Train_dice: 0.9435\n","37/222, Train_loss: 0.0628\n","Train_dice: 0.9456\n","38/222, Train_loss: 0.0968\n","Train_dice: 0.9067\n","39/222, Train_loss: 0.0488\n","Train_dice: 0.9607\n","40/222, Train_loss: 0.0468\n","Train_dice: 0.9597\n","41/222, Train_loss: 0.0989\n","Train_dice: 0.8948\n","42/222, Train_loss: 0.0778\n","Train_dice: 0.9364\n","43/222, Train_loss: 0.0554\n","Train_dice: 0.9558\n","44/222, Train_loss: 0.0930\n","Train_dice: 0.8529\n","45/222, Train_loss: 0.0689\n","Train_dice: 0.9408\n","46/222, Train_loss: 0.0525\n","Train_dice: 0.9542\n","47/222, Train_loss: 0.0725\n","Train_dice: 0.9371\n","48/222, Train_loss: 0.0632\n","Train_dice: 0.9453\n","49/222, Train_loss: 0.0791\n","Train_dice: 0.9328\n","50/222, Train_loss: 0.0542\n","Train_dice: 0.9463\n","51/222, Train_loss: 0.2741\n","Train_dice: 0.6965\n","52/222, Train_loss: 0.0686\n","Train_dice: 0.9347\n","53/222, Train_loss: 0.0565\n","Train_dice: 0.9522\n","54/222, Train_loss: 0.0577\n","Train_dice: 0.9516\n","55/222, Train_loss: 0.0497\n","Train_dice: 0.9558\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0544\n","Train_dice: 0.9526\n","58/222, Train_loss: 0.0692\n","Train_dice: 0.9343\n","59/222, Train_loss: 0.5004\n","Train_dice: 0.4997\n","60/222, Train_loss: 0.0615\n","Train_dice: 0.9445\n","61/222, Train_loss: 0.0602\n","Train_dice: 0.9468\n","62/222, Train_loss: 0.0770\n","Train_dice: 0.9311\n","63/222, Train_loss: 0.5004\n","Train_dice: 0.4997\n","64/222, Train_loss: 0.0777\n","Train_dice: 0.9280\n","65/222, Train_loss: 0.0608\n","Train_dice: 0.9466\n","66/222, Train_loss: 0.0538\n","Train_dice: 0.9499\n","67/222, Train_loss: 0.0729\n","Train_dice: 0.9342\n","68/222, Train_loss: 0.0638\n","Train_dice: 0.9473\n","69/222, Train_loss: 0.0576\n","Train_dice: 0.9529\n","70/222, Train_loss: 0.0560\n","Train_dice: 0.9546\n","71/222, Train_loss: 0.0672\n","Train_dice: 0.9405\n","72/222, Train_loss: 0.0466\n","Train_dice: 0.9602\n","73/222, Train_loss: 0.0560\n","Train_dice: 0.9489\n","74/222, Train_loss: 0.0621\n","Train_dice: 0.9464\n","75/222, Train_loss: 0.0552\n","Train_dice: 0.9518\n","76/222, Train_loss: 0.1005\n","Train_dice: 0.9021\n","77/222, Train_loss: 0.0860\n","Train_dice: 0.9217\n","78/222, Train_loss: 0.0568\n","Train_dice: 0.9522\n","79/222, Train_loss: 0.0775\n","Train_dice: 0.9301\n","80/222, Train_loss: 0.0659\n","Train_dice: 0.9387\n","81/222, Train_loss: 0.0460\n","Train_dice: 0.9565\n","82/222, Train_loss: 0.0575\n","Train_dice: 0.9467\n","83/222, Train_loss: 0.0483\n","Train_dice: 0.9565\n","84/222, Train_loss: 0.0602\n","Train_dice: 0.9457\n","85/222, Train_loss: 0.0627\n","Train_dice: 0.9449\n","86/222, Train_loss: 0.0855\n","Train_dice: 0.9110\n","87/222, Train_loss: 0.0730\n","Train_dice: 0.9285\n","88/222, Train_loss: 0.0551\n","Train_dice: 0.9521\n","89/222, Train_loss: 0.0721\n","Train_dice: 0.9317\n","90/222, Train_loss: 0.0893\n","Train_dice: 0.9082\n","91/222, Train_loss: 0.0633\n","Train_dice: 0.9376\n","92/222, Train_loss: 0.0572\n","Train_dice: 0.9481\n","93/222, Train_loss: 0.0750\n","Train_dice: 0.9324\n","94/222, Train_loss: 0.0699\n","Train_dice: 0.9332\n","95/222, Train_loss: 0.0879\n","Train_dice: 0.9193\n","96/222, Train_loss: 0.0507\n","Train_dice: 0.9532\n","97/222, Train_loss: 0.0639\n","Train_dice: 0.9414\n","98/222, Train_loss: 0.0936\n","Train_dice: 0.9010\n","99/222, Train_loss: 0.0624\n","Train_dice: 0.9414\n","100/222, Train_loss: 0.0668\n","Train_dice: 0.9334\n","101/222, Train_loss: 0.0600\n","Train_dice: 0.9425\n","102/222, Train_loss: 0.0535\n","Train_dice: 0.9521\n","103/222, Train_loss: 0.0732\n","Train_dice: 0.9397\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0463\n","Train_dice: 0.9447\n","106/222, Train_loss: 0.0568\n","Train_dice: 0.9363\n","107/222, Train_loss: 0.0777\n","Train_dice: 0.9282\n","108/222, Train_loss: 0.0597\n","Train_dice: 0.9418\n","109/222, Train_loss: 0.0677\n","Train_dice: 0.9395\n","110/222, Train_loss: 0.0611\n","Train_dice: 0.9374\n","111/222, Train_loss: 0.0618\n","Train_dice: 0.9381\n","112/222, Train_loss: 0.0581\n","Train_dice: 0.9485\n","113/222, Train_loss: 0.0615\n","Train_dice: 0.9468\n","114/222, Train_loss: 0.0777\n","Train_dice: 0.9225\n","115/222, Train_loss: 0.0525\n","Train_dice: 0.9517\n","116/222, Train_loss: 0.0630\n","Train_dice: 0.9423\n","117/222, Train_loss: 0.0703\n","Train_dice: 0.9383\n","118/222, Train_loss: 0.0765\n","Train_dice: 0.9224\n","119/222, Train_loss: 0.0743\n","Train_dice: 0.9276\n","120/222, Train_loss: 0.0661\n","Train_dice: 0.9431\n","121/222, Train_loss: 0.0691\n","Train_dice: 0.9395\n","122/222, Train_loss: 0.0610\n","Train_dice: 0.9484\n","123/222, Train_loss: 0.0543\n","Train_dice: 0.9480\n","124/222, Train_loss: 0.1073\n","Train_dice: 0.8037\n","125/222, Train_loss: 0.0715\n","Train_dice: 0.9280\n","126/222, Train_loss: 0.0771\n","Train_dice: 0.9331\n","127/222, Train_loss: 0.0707\n","Train_dice: 0.9312\n","128/222, Train_loss: 0.0714\n","Train_dice: 0.9390\n","129/222, Train_loss: 0.0514\n","Train_dice: 0.9553\n","130/222, Train_loss: 0.0540\n","Train_dice: 0.9472\n","131/222, Train_loss: 0.0580\n","Train_dice: 0.9450\n","132/222, Train_loss: 0.0591\n","Train_dice: 0.9466\n","133/222, Train_loss: 0.0583\n","Train_dice: 0.9423\n","134/222, Train_loss: 0.0771\n","Train_dice: 0.9306\n","135/222, Train_loss: 0.0600\n","Train_dice: 0.9464\n","136/222, Train_loss: 0.0503\n","Train_dice: 0.9528\n","137/222, Train_loss: 0.0663\n","Train_dice: 0.9383\n","138/222, Train_loss: 0.0690\n","Train_dice: 0.9414\n","139/222, Train_loss: 0.0683\n","Train_dice: 0.9362\n","140/222, Train_loss: 0.0562\n","Train_dice: 0.9489\n","141/222, Train_loss: 0.0544\n","Train_dice: 0.9521\n","142/222, Train_loss: 0.0530\n","Train_dice: 0.9544\n","143/222, Train_loss: 0.0645\n","Train_dice: 0.9417\n","144/222, Train_loss: 0.0568\n","Train_dice: 0.9471\n","145/222, Train_loss: 0.0557\n","Train_dice: 0.9454\n","146/222, Train_loss: 0.0670\n","Train_dice: 0.9310\n","147/222, Train_loss: 0.0550\n","Train_dice: 0.9510\n","148/222, Train_loss: 0.0584\n","Train_dice: 0.9503\n","149/222, Train_loss: 0.1022\n","Train_dice: 0.8934\n","150/222, Train_loss: 0.0729\n","Train_dice: 0.9248\n","151/222, Train_loss: 0.0685\n","Train_dice: 0.9302\n","152/222, Train_loss: 0.0852\n","Train_dice: 0.9236\n","153/222, Train_loss: 0.0712\n","Train_dice: 0.9330\n","154/222, Train_loss: 0.0777\n","Train_dice: 0.9161\n","155/222, Train_loss: 0.0699\n","Train_dice: 0.9375\n","156/222, Train_loss: 0.0561\n","Train_dice: 0.9399\n","157/222, Train_loss: 0.0605\n","Train_dice: 0.9439\n","158/222, Train_loss: 0.0643\n","Train_dice: 0.9427\n","159/222, Train_loss: 0.0797\n","Train_dice: 0.9209\n","160/222, Train_loss: 0.0556\n","Train_dice: 0.9483\n","161/222, Train_loss: 0.0637\n","Train_dice: 0.9228\n","162/222, Train_loss: 0.0564\n","Train_dice: 0.9457\n","163/222, Train_loss: 0.0604\n","Train_dice: 0.9369\n","164/222, Train_loss: 0.0548\n","Train_dice: 0.9484\n","165/222, Train_loss: 0.0767\n","Train_dice: 0.9218\n","166/222, Train_loss: 0.0551\n","Train_dice: 0.9506\n","167/222, Train_loss: 0.0507\n","Train_dice: 0.9541\n","168/222, Train_loss: 0.0777\n","Train_dice: 0.9251\n","169/222, Train_loss: 0.0529\n","Train_dice: 0.9523\n","170/222, Train_loss: 0.0729\n","Train_dice: 0.9384\n","171/222, Train_loss: 0.0650\n","Train_dice: 0.9235\n","172/222, Train_loss: 0.0617\n","Train_dice: 0.9393\n","173/222, Train_loss: 0.1070\n","Train_dice: 0.8776\n","174/222, Train_loss: 0.0931\n","Train_dice: 0.9157\n","175/222, Train_loss: 0.0726\n","Train_dice: 0.9295\n","176/222, Train_loss: 0.0563\n","Train_dice: 0.9486\n","177/222, Train_loss: 0.0744\n","Train_dice: 0.9310\n","178/222, Train_loss: 0.0815\n","Train_dice: 0.9256\n","179/222, Train_loss: 0.0678\n","Train_dice: 0.9413\n","180/222, Train_loss: 0.1204\n","Train_dice: 0.8127\n","181/222, Train_loss: 0.0810\n","Train_dice: 0.9240\n","182/222, Train_loss: 0.0570\n","Train_dice: 0.9536\n","183/222, Train_loss: 0.0681\n","Train_dice: 0.9054\n","184/222, Train_loss: 0.0607\n","Train_dice: 0.9469\n","185/222, Train_loss: 0.0540\n","Train_dice: 0.9571\n","186/222, Train_loss: 0.0653\n","Train_dice: 0.9451\n","187/222, Train_loss: 0.0585\n","Train_dice: 0.9458\n","188/222, Train_loss: 0.0729\n","Train_dice: 0.9381\n","189/222, Train_loss: 0.0680\n","Train_dice: 0.9344\n","190/222, Train_loss: 0.0597\n","Train_dice: 0.9460\n","191/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0526\n","Train_dice: 0.9580\n","195/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0583\n","Train_dice: 0.9499\n","197/222, Train_loss: 0.0874\n","Train_dice: 0.8944\n","198/222, Train_loss: 0.0468\n","Train_dice: 0.9619\n","199/222, Train_loss: 0.0642\n","Train_dice: 0.9441\n","200/222, Train_loss: 0.0553\n","Train_dice: 0.9456\n","201/222, Train_loss: 0.0809\n","Train_dice: 0.9252\n","202/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","203/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","204/222, Train_loss: 0.0665\n","Train_dice: 0.9391\n","205/222, Train_loss: 0.0765\n","Train_dice: 0.9246\n","206/222, Train_loss: 0.0582\n","Train_dice: 0.9508\n","207/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","208/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","209/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","210/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","211/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0728\n","Train_dice: 0.9302\n","214/222, Train_loss: 0.0346\n","Train_dice: 0.9698\n","215/222, Train_loss: 0.0524\n","Train_dice: 0.9547\n","216/222, Train_loss: 0.0594\n","Train_dice: 0.9463\n","217/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0629\n","Train_dice: 0.9396\n","219/222, Train_loss: 0.0618\n","Train_dice: 0.9433\n","220/222, Train_loss: 0.0894\n","Train_dice: 0.8979\n","221/222, Train_loss: 0.4022\n","Train_dice: 0.5833\n","222/222, Train_loss: 0.0518\n","Train_dice: 0.9467\n","--------------------\n","Epoch_loss: 0.1014\n","Epoch_metric: 0.9011\n","test_loss_epoch: 0.2099\n","test_dice_epoch: 0.8023\n","Confusion Matrix:\n","[[58286329    77205]\n"," [  166002   190720]]\n","test_loss_epoch: 0.0037\n","test_dice_epoch: 0.0143\n","current epoch: 35 current mean dice: 0.8731\n","best mean dice: 0.0143 at epoch: 35\n","----------\n","epoch 36/150\n","1/222, Train_loss: 0.0540\n","Train_dice: 0.9514\n","2/222, Train_loss: 0.0669\n","Train_dice: 0.9456\n","3/222, Train_loss: 0.0517\n","Train_dice: 0.9552\n","4/222, Train_loss: 0.0359\n","Train_dice: 0.9709\n","5/222, Train_loss: 0.0645\n","Train_dice: 0.9465\n","6/222, Train_loss: 0.0653\n","Train_dice: 0.9440\n","7/222, Train_loss: 0.0517\n","Train_dice: 0.9562\n","8/222, Train_loss: 0.0523\n","Train_dice: 0.9561\n","9/222, Train_loss: 0.0519\n","Train_dice: 0.9528\n","10/222, Train_loss: 0.0596\n","Train_dice: 0.9464\n","11/222, Train_loss: 0.0504\n","Train_dice: 0.9570\n","12/222, Train_loss: 0.0548\n","Train_dice: 0.9558\n","13/222, Train_loss: 0.0621\n","Train_dice: 0.9476\n","14/222, Train_loss: 0.0669\n","Train_dice: 0.9460\n","15/222, Train_loss: 0.0534\n","Train_dice: 0.9546\n","16/222, Train_loss: 0.0808\n","Train_dice: 0.9264\n","17/222, Train_loss: 0.0646\n","Train_dice: 0.9478\n","18/222, Train_loss: 0.0568\n","Train_dice: 0.9546\n","19/222, Train_loss: 0.0512\n","Train_dice: 0.9525\n","20/222, Train_loss: 0.0793\n","Train_dice: 0.9236\n","21/222, Train_loss: 0.0562\n","Train_dice: 0.9475\n","22/222, Train_loss: 0.0663\n","Train_dice: 0.9436\n","23/222, Train_loss: 0.0549\n","Train_dice: 0.9540\n","24/222, Train_loss: 0.0645\n","Train_dice: 0.9390\n","25/222, Train_loss: 0.1563\n","Train_dice: 0.8166\n","26/222, Train_loss: 0.0563\n","Train_dice: 0.9512\n","27/222, Train_loss: 0.0531\n","Train_dice: 0.9539\n","28/222, Train_loss: 0.0787\n","Train_dice: 0.8938\n","29/222, Train_loss: 0.0610\n","Train_dice: 0.9496\n","30/222, Train_loss: 0.0640\n","Train_dice: 0.9386\n","31/222, Train_loss: 0.0629\n","Train_dice: 0.9430\n","32/222, Train_loss: 0.0524\n","Train_dice: 0.9534\n","33/222, Train_loss: 0.0615\n","Train_dice: 0.9461\n","34/222, Train_loss: 0.0724\n","Train_dice: 0.9350\n","35/222, Train_loss: 0.0436\n","Train_dice: 0.9615\n","36/222, Train_loss: 0.0698\n","Train_dice: 0.9383\n","37/222, Train_loss: 0.0581\n","Train_dice: 0.9499\n","38/222, Train_loss: 0.0970\n","Train_dice: 0.9080\n","39/222, Train_loss: 0.0447\n","Train_dice: 0.9594\n","40/222, Train_loss: 0.0428\n","Train_dice: 0.9636\n","41/222, Train_loss: 0.1026\n","Train_dice: 0.8921\n","42/222, Train_loss: 0.0701\n","Train_dice: 0.9398\n","43/222, Train_loss: 0.0541\n","Train_dice: 0.9535\n","44/222, Train_loss: 0.0958\n","Train_dice: 0.8138\n","45/222, Train_loss: 0.0690\n","Train_dice: 0.9342\n","46/222, Train_loss: 0.0518\n","Train_dice: 0.9544\n","47/222, Train_loss: 0.0496\n","Train_dice: 0.9517\n","48/222, Train_loss: 0.0508\n","Train_dice: 0.9566\n","49/222, Train_loss: 0.0725\n","Train_dice: 0.9328\n","50/222, Train_loss: 0.0611\n","Train_dice: 0.9425\n","51/222, Train_loss: 0.2411\n","Train_dice: 0.7221\n","52/222, Train_loss: 0.0640\n","Train_dice: 0.9409\n","53/222, Train_loss: 0.0549\n","Train_dice: 0.9545\n","54/222, Train_loss: 0.0711\n","Train_dice: 0.9422\n","55/222, Train_loss: 0.0586\n","Train_dice: 0.9516\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0521\n","Train_dice: 0.9559\n","58/222, Train_loss: 0.0625\n","Train_dice: 0.9447\n","59/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","60/222, Train_loss: 0.0643\n","Train_dice: 0.9450\n","61/222, Train_loss: 0.0589\n","Train_dice: 0.9516\n","62/222, Train_loss: 0.0692\n","Train_dice: 0.9390\n","63/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","64/222, Train_loss: 0.0684\n","Train_dice: 0.9418\n","65/222, Train_loss: 0.0582\n","Train_dice: 0.9494\n","66/222, Train_loss: 0.0565\n","Train_dice: 0.9471\n","67/222, Train_loss: 0.0672\n","Train_dice: 0.9394\n","68/222, Train_loss: 0.0657\n","Train_dice: 0.9409\n","69/222, Train_loss: 0.0505\n","Train_dice: 0.9541\n","70/222, Train_loss: 0.0466\n","Train_dice: 0.9612\n","71/222, Train_loss: 0.0680\n","Train_dice: 0.9360\n","72/222, Train_loss: 0.0559\n","Train_dice: 0.9525\n","73/222, Train_loss: 0.0561\n","Train_dice: 0.9504\n","74/222, Train_loss: 0.0619\n","Train_dice: 0.9416\n","75/222, Train_loss: 0.0494\n","Train_dice: 0.9545\n","76/222, Train_loss: 0.0892\n","Train_dice: 0.9103\n","77/222, Train_loss: 0.0800\n","Train_dice: 0.9275\n","78/222, Train_loss: 0.0574\n","Train_dice: 0.9497\n","79/222, Train_loss: 0.0712\n","Train_dice: 0.9347\n","80/222, Train_loss: 0.0694\n","Train_dice: 0.9325\n","81/222, Train_loss: 0.0469\n","Train_dice: 0.9581\n","82/222, Train_loss: 0.0553\n","Train_dice: 0.9466\n","83/222, Train_loss: 0.0569\n","Train_dice: 0.9515\n","84/222, Train_loss: 0.0584\n","Train_dice: 0.9471\n","85/222, Train_loss: 0.0691\n","Train_dice: 0.9452\n","86/222, Train_loss: 0.0783\n","Train_dice: 0.9180\n","87/222, Train_loss: 0.0743\n","Train_dice: 0.9291\n","88/222, Train_loss: 0.0537\n","Train_dice: 0.9541\n","89/222, Train_loss: 0.0642\n","Train_dice: 0.9386\n","90/222, Train_loss: 0.0708\n","Train_dice: 0.9289\n","91/222, Train_loss: 0.0553\n","Train_dice: 0.9436\n","92/222, Train_loss: 0.0552\n","Train_dice: 0.9518\n","93/222, Train_loss: 0.0762\n","Train_dice: 0.9263\n","94/222, Train_loss: 0.0664\n","Train_dice: 0.9362\n","95/222, Train_loss: 0.0968\n","Train_dice: 0.9068\n","96/222, Train_loss: 0.0485\n","Train_dice: 0.9578\n","97/222, Train_loss: 0.0603\n","Train_dice: 0.9440\n","98/222, Train_loss: 0.0666\n","Train_dice: 0.9272\n","99/222, Train_loss: 0.0581\n","Train_dice: 0.9476\n","100/222, Train_loss: 0.0702\n","Train_dice: 0.9331\n","101/222, Train_loss: 0.0522\n","Train_dice: 0.9529\n","102/222, Train_loss: 0.0568\n","Train_dice: 0.9498\n","103/222, Train_loss: 0.0697\n","Train_dice: 0.9430\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0443\n","Train_dice: 0.9367\n","106/222, Train_loss: 0.0648\n","Train_dice: 0.9377\n","107/222, Train_loss: 0.0653\n","Train_dice: 0.9371\n","108/222, Train_loss: 0.0537\n","Train_dice: 0.9452\n","109/222, Train_loss: 0.0589\n","Train_dice: 0.9413\n","110/222, Train_loss: 0.0692\n","Train_dice: 0.9272\n","111/222, Train_loss: 0.0566\n","Train_dice: 0.9423\n","112/222, Train_loss: 0.0565\n","Train_dice: 0.9501\n","113/222, Train_loss: 0.0689\n","Train_dice: 0.9378\n","114/222, Train_loss: 0.0722\n","Train_dice: 0.9252\n","115/222, Train_loss: 0.0495\n","Train_dice: 0.9539\n","116/222, Train_loss: 0.0536\n","Train_dice: 0.9501\n","117/222, Train_loss: 0.0653\n","Train_dice: 0.9411\n","118/222, Train_loss: 0.0715\n","Train_dice: 0.9298\n","119/222, Train_loss: 0.0696\n","Train_dice: 0.9339\n","120/222, Train_loss: 0.0561\n","Train_dice: 0.9543\n","121/222, Train_loss: 0.0601\n","Train_dice: 0.9504\n","122/222, Train_loss: 0.0561\n","Train_dice: 0.9547\n","123/222, Train_loss: 0.0620\n","Train_dice: 0.9450\n","124/222, Train_loss: 0.0890\n","Train_dice: 0.8406\n","125/222, Train_loss: 0.0753\n","Train_dice: 0.9235\n","126/222, Train_loss: 0.0720\n","Train_dice: 0.9337\n","127/222, Train_loss: 0.0612\n","Train_dice: 0.9372\n","128/222, Train_loss: 0.0734\n","Train_dice: 0.9372\n","129/222, Train_loss: 0.0486\n","Train_dice: 0.9584\n","130/222, Train_loss: 0.0484\n","Train_dice: 0.9546\n","131/222, Train_loss: 0.0530\n","Train_dice: 0.9519\n","132/222, Train_loss: 0.0617\n","Train_dice: 0.9445\n","133/222, Train_loss: 0.0584\n","Train_dice: 0.9422\n","134/222, Train_loss: 0.0707\n","Train_dice: 0.9354\n","135/222, Train_loss: 0.0551\n","Train_dice: 0.9528\n","136/222, Train_loss: 0.0502\n","Train_dice: 0.9547\n","137/222, Train_loss: 0.0507\n","Train_dice: 0.9493\n","138/222, Train_loss: 0.0604\n","Train_dice: 0.9457\n","139/222, Train_loss: 0.0549\n","Train_dice: 0.9498\n","140/222, Train_loss: 0.0583\n","Train_dice: 0.9457\n","141/222, Train_loss: 0.0506\n","Train_dice: 0.9544\n","142/222, Train_loss: 0.0530\n","Train_dice: 0.9519\n","143/222, Train_loss: 0.0592\n","Train_dice: 0.9451\n","144/222, Train_loss: 0.0510\n","Train_dice: 0.9549\n","145/222, Train_loss: 0.0528\n","Train_dice: 0.9522\n","146/222, Train_loss: 0.0677\n","Train_dice: 0.9359\n","147/222, Train_loss: 0.0525\n","Train_dice: 0.9547\n","148/222, Train_loss: 0.0535\n","Train_dice: 0.9563\n","149/222, Train_loss: 0.0973\n","Train_dice: 0.8976\n","150/222, Train_loss: 0.0749\n","Train_dice: 0.9252\n","151/222, Train_loss: 0.0674\n","Train_dice: 0.9344\n","152/222, Train_loss: 0.0757\n","Train_dice: 0.9335\n","153/222, Train_loss: 0.0634\n","Train_dice: 0.9405\n","154/222, Train_loss: 0.0724\n","Train_dice: 0.9160\n","155/222, Train_loss: 0.0687\n","Train_dice: 0.9379\n","156/222, Train_loss: 0.0493\n","Train_dice: 0.9491\n","157/222, Train_loss: 0.0572\n","Train_dice: 0.9449\n","158/222, Train_loss: 0.0683\n","Train_dice: 0.9431\n","159/222, Train_loss: 0.0738\n","Train_dice: 0.9283\n","160/222, Train_loss: 0.0559\n","Train_dice: 0.9502\n","161/222, Train_loss: 0.0540\n","Train_dice: 0.9298\n","162/222, Train_loss: 0.0546\n","Train_dice: 0.9481\n","163/222, Train_loss: 0.0558\n","Train_dice: 0.9441\n","164/222, Train_loss: 0.0670\n","Train_dice: 0.9383\n","165/222, Train_loss: 0.0718\n","Train_dice: 0.9301\n","166/222, Train_loss: 0.0539\n","Train_dice: 0.9515\n","167/222, Train_loss: 0.0539\n","Train_dice: 0.9485\n","168/222, Train_loss: 0.0718\n","Train_dice: 0.9314\n","169/222, Train_loss: 0.0545\n","Train_dice: 0.9507\n","170/222, Train_loss: 0.0658\n","Train_dice: 0.9445\n","171/222, Train_loss: 0.0611\n","Train_dice: 0.9261\n","172/222, Train_loss: 0.0460\n","Train_dice: 0.9553\n","173/222, Train_loss: 0.0996\n","Train_dice: 0.8837\n","174/222, Train_loss: 0.0843\n","Train_dice: 0.9222\n","175/222, Train_loss: 0.0796\n","Train_dice: 0.9225\n","176/222, Train_loss: 0.0570\n","Train_dice: 0.9477\n","177/222, Train_loss: 0.0706\n","Train_dice: 0.9277\n","178/222, Train_loss: 0.0832\n","Train_dice: 0.9252\n","179/222, Train_loss: 0.0676\n","Train_dice: 0.9409\n","180/222, Train_loss: 0.1125\n","Train_dice: 0.8327\n","181/222, Train_loss: 0.0781\n","Train_dice: 0.9236\n","182/222, Train_loss: 0.0580\n","Train_dice: 0.9527\n","183/222, Train_loss: 0.0642\n","Train_dice: 0.9130\n","184/222, Train_loss: 0.0613\n","Train_dice: 0.9457\n","185/222, Train_loss: 0.0510\n","Train_dice: 0.9579\n","186/222, Train_loss: 0.0715\n","Train_dice: 0.9361\n","187/222, Train_loss: 0.0523\n","Train_dice: 0.9548\n","188/222, Train_loss: 0.0690\n","Train_dice: 0.9449\n","189/222, Train_loss: 0.0714\n","Train_dice: 0.9331\n","190/222, Train_loss: 0.0606\n","Train_dice: 0.9461\n","191/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","192/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0497\n","Train_dice: 0.9565\n","195/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0644\n","Train_dice: 0.9439\n","197/222, Train_loss: 0.0810\n","Train_dice: 0.8915\n","198/222, Train_loss: 0.0490\n","Train_dice: 0.9585\n","199/222, Train_loss: 0.0702\n","Train_dice: 0.9328\n","200/222, Train_loss: 0.0518\n","Train_dice: 0.9481\n","201/222, Train_loss: 0.0593\n","Train_dice: 0.9401\n","202/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","203/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","204/222, Train_loss: 0.0615\n","Train_dice: 0.9432\n","205/222, Train_loss: 0.0712\n","Train_dice: 0.9323\n","206/222, Train_loss: 0.0556\n","Train_dice: 0.9530\n","207/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","208/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","209/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","210/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","211/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0963\n","Train_dice: 0.9182\n","214/222, Train_loss: 0.0323\n","Train_dice: 0.9744\n","215/222, Train_loss: 0.0522\n","Train_dice: 0.9583\n","216/222, Train_loss: 0.0599\n","Train_dice: 0.9483\n","217/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0612\n","Train_dice: 0.9452\n","219/222, Train_loss: 0.0643\n","Train_dice: 0.9449\n","220/222, Train_loss: 0.0709\n","Train_dice: 0.9103\n","221/222, Train_loss: 0.3781\n","Train_dice: 0.5904\n","222/222, Train_loss: 0.0495\n","Train_dice: 0.9514\n","--------------------\n","Epoch_loss: 0.0988\n","Epoch_metric: 0.9037\n","test_loss_epoch: 0.2119\n","test_dice_epoch: 0.8005\n","Confusion Matrix:\n","[[58294385    69149]\n"," [  172085   184637]]\n","test_loss_epoch: 0.0038\n","test_dice_epoch: 0.0143\n","current epoch: 36 current mean dice: 0.8740\n","best mean dice: 0.0143 at epoch: 35\n","----------\n","epoch 37/150\n","1/222, Train_loss: 0.0501\n","Train_dice: 0.9560\n","2/222, Train_loss: 0.0656\n","Train_dice: 0.9436\n","3/222, Train_loss: 0.0553\n","Train_dice: 0.9532\n","4/222, Train_loss: 0.0358\n","Train_dice: 0.9663\n","5/222, Train_loss: 0.0593\n","Train_dice: 0.9509\n","6/222, Train_loss: 0.0577\n","Train_dice: 0.9504\n","7/222, Train_loss: 0.0525\n","Train_dice: 0.9542\n","8/222, Train_loss: 0.0504\n","Train_dice: 0.9566\n","9/222, Train_loss: 0.0578\n","Train_dice: 0.9494\n","10/222, Train_loss: 0.0646\n","Train_dice: 0.9385\n","11/222, Train_loss: 0.0479\n","Train_dice: 0.9582\n","12/222, Train_loss: 0.0568\n","Train_dice: 0.9526\n","13/222, Train_loss: 0.0700\n","Train_dice: 0.9412\n","14/222, Train_loss: 0.0617\n","Train_dice: 0.9494\n","15/222, Train_loss: 0.0560\n","Train_dice: 0.9494\n","16/222, Train_loss: 0.0699\n","Train_dice: 0.9372\n","17/222, Train_loss: 0.0579\n","Train_dice: 0.9482\n","18/222, Train_loss: 0.0483\n","Train_dice: 0.9592\n","19/222, Train_loss: 0.0498\n","Train_dice: 0.9529\n","20/222, Train_loss: 0.0805\n","Train_dice: 0.9222\n","21/222, Train_loss: 0.0592\n","Train_dice: 0.9460\n","22/222, Train_loss: 0.0750\n","Train_dice: 0.9392\n","23/222, Train_loss: 0.0559\n","Train_dice: 0.9567\n","24/222, Train_loss: 0.0680\n","Train_dice: 0.9390\n","25/222, Train_loss: 0.1405\n","Train_dice: 0.8182\n","26/222, Train_loss: 0.0588\n","Train_dice: 0.9518\n","27/222, Train_loss: 0.0568\n","Train_dice: 0.9522\n","28/222, Train_loss: 0.0903\n","Train_dice: 0.8873\n","29/222, Train_loss: 0.0550\n","Train_dice: 0.9544\n","30/222, Train_loss: 0.0561\n","Train_dice: 0.9423\n","31/222, Train_loss: 0.0681\n","Train_dice: 0.9411\n","32/222, Train_loss: 0.0539\n","Train_dice: 0.9490\n","33/222, Train_loss: 0.0567\n","Train_dice: 0.9501\n","34/222, Train_loss: 0.0669\n","Train_dice: 0.9440\n","35/222, Train_loss: 0.0497\n","Train_dice: 0.9572\n","36/222, Train_loss: 0.0649\n","Train_dice: 0.9466\n","37/222, Train_loss: 0.0504\n","Train_dice: 0.9601\n","38/222, Train_loss: 0.0821\n","Train_dice: 0.9234\n","39/222, Train_loss: 0.0443\n","Train_dice: 0.9614\n","40/222, Train_loss: 0.0581\n","Train_dice: 0.9480\n","41/222, Train_loss: 0.1123\n","Train_dice: 0.8835\n","42/222, Train_loss: 0.0708\n","Train_dice: 0.9392\n","43/222, Train_loss: 0.0603\n","Train_dice: 0.9484\n","44/222, Train_loss: 0.1107\n","Train_dice: 0.8184\n","45/222, Train_loss: 0.0662\n","Train_dice: 0.9365\n","46/222, Train_loss: 0.0586\n","Train_dice: 0.9480\n","47/222, Train_loss: 0.0477\n","Train_dice: 0.9508\n","48/222, Train_loss: 0.0494\n","Train_dice: 0.9549\n","49/222, Train_loss: 0.0622\n","Train_dice: 0.9453\n","50/222, Train_loss: 0.0637\n","Train_dice: 0.9403\n","51/222, Train_loss: 0.2353\n","Train_dice: 0.7106\n","52/222, Train_loss: 0.0665\n","Train_dice: 0.9378\n","53/222, Train_loss: 0.0511\n","Train_dice: 0.9564\n","54/222, Train_loss: 0.0627\n","Train_dice: 0.9474\n","55/222, Train_loss: 0.0500\n","Train_dice: 0.9580\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0560\n","Train_dice: 0.9532\n","58/222, Train_loss: 0.0610\n","Train_dice: 0.9482\n","59/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","60/222, Train_loss: 0.0599\n","Train_dice: 0.9486\n","61/222, Train_loss: 0.0573\n","Train_dice: 0.9530\n","62/222, Train_loss: 0.0713\n","Train_dice: 0.9383\n","63/222, Train_loss: 0.5002\n","Train_dice: 0.4998\n","64/222, Train_loss: 0.0759\n","Train_dice: 0.9311\n","65/222, Train_loss: 0.0610\n","Train_dice: 0.9503\n","66/222, Train_loss: 0.0571\n","Train_dice: 0.9506\n","67/222, Train_loss: 0.0643\n","Train_dice: 0.9406\n","68/222, Train_loss: 0.0545\n","Train_dice: 0.9532\n","69/222, Train_loss: 0.0526\n","Train_dice: 0.9556\n","70/222, Train_loss: 0.0471\n","Train_dice: 0.9590\n","71/222, Train_loss: 0.0641\n","Train_dice: 0.9386\n","72/222, Train_loss: 0.0549\n","Train_dice: 0.9535\n","73/222, Train_loss: 0.0505\n","Train_dice: 0.9548\n","74/222, Train_loss: 0.0533\n","Train_dice: 0.9553\n","75/222, Train_loss: 0.0499\n","Train_dice: 0.9543\n","76/222, Train_loss: 0.0776\n","Train_dice: 0.9186\n","77/222, Train_loss: 0.0795\n","Train_dice: 0.9276\n","78/222, Train_loss: 0.0560\n","Train_dice: 0.9496\n","79/222, Train_loss: 0.0695\n","Train_dice: 0.9342\n","80/222, Train_loss: 0.0781\n","Train_dice: 0.9233\n","81/222, Train_loss: 0.0483\n","Train_dice: 0.9574\n","82/222, Train_loss: 0.0562\n","Train_dice: 0.9454\n","83/222, Train_loss: 0.0539\n","Train_dice: 0.9541\n","84/222, Train_loss: 0.0689\n","Train_dice: 0.9399\n","85/222, Train_loss: 0.0674\n","Train_dice: 0.9380\n","86/222, Train_loss: 0.0867\n","Train_dice: 0.9095\n","87/222, Train_loss: 0.0663\n","Train_dice: 0.9340\n","88/222, Train_loss: 0.0562\n","Train_dice: 0.9504\n","89/222, Train_loss: 0.0648\n","Train_dice: 0.9433\n","90/222, Train_loss: 0.0660\n","Train_dice: 0.9311\n","91/222, Train_loss: 0.0545\n","Train_dice: 0.9485\n","92/222, Train_loss: 0.0546\n","Train_dice: 0.9506\n","93/222, Train_loss: 0.0758\n","Train_dice: 0.9297\n","94/222, Train_loss: 0.0662\n","Train_dice: 0.9394\n","95/222, Train_loss: 0.0937\n","Train_dice: 0.9140\n","96/222, Train_loss: 0.0516\n","Train_dice: 0.9556\n","97/222, Train_loss: 0.0684\n","Train_dice: 0.9362\n","98/222, Train_loss: 0.0661\n","Train_dice: 0.9299\n","99/222, Train_loss: 0.0572\n","Train_dice: 0.9480\n","100/222, Train_loss: 0.0669\n","Train_dice: 0.9348\n","101/222, Train_loss: 0.0551\n","Train_dice: 0.9488\n","102/222, Train_loss: 0.0517\n","Train_dice: 0.9562\n","103/222, Train_loss: 0.0645\n","Train_dice: 0.9460\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0390\n","Train_dice: 0.9501\n","106/222, Train_loss: 0.0499\n","Train_dice: 0.9466\n","107/222, Train_loss: 0.0665\n","Train_dice: 0.9356\n","108/222, Train_loss: 0.0529\n","Train_dice: 0.9483\n","109/222, Train_loss: 0.0503\n","Train_dice: 0.9489\n","110/222, Train_loss: 0.0576\n","Train_dice: 0.9435\n","111/222, Train_loss: 0.0653\n","Train_dice: 0.9397\n","112/222, Train_loss: 0.0532\n","Train_dice: 0.9521\n","113/222, Train_loss: 0.0615\n","Train_dice: 0.9433\n","114/222, Train_loss: 0.0699\n","Train_dice: 0.9294\n","115/222, Train_loss: 0.0478\n","Train_dice: 0.9573\n","116/222, Train_loss: 0.0484\n","Train_dice: 0.9552\n","117/222, Train_loss: 0.0635\n","Train_dice: 0.9433\n","118/222, Train_loss: 0.0784\n","Train_dice: 0.9189\n","119/222, Train_loss: 0.0669\n","Train_dice: 0.9384\n","120/222, Train_loss: 0.0568\n","Train_dice: 0.9513\n","121/222, Train_loss: 0.0587\n","Train_dice: 0.9491\n","122/222, Train_loss: 0.0590\n","Train_dice: 0.9506\n","123/222, Train_loss: 0.0581\n","Train_dice: 0.9432\n","124/222, Train_loss: 0.0801\n","Train_dice: 0.8474\n","125/222, Train_loss: 0.0572\n","Train_dice: 0.9406\n","126/222, Train_loss: 0.0718\n","Train_dice: 0.9356\n","127/222, Train_loss: 0.0630\n","Train_dice: 0.9333\n","128/222, Train_loss: 0.0732\n","Train_dice: 0.9387\n","129/222, Train_loss: 0.0474\n","Train_dice: 0.9606\n","130/222, Train_loss: 0.0499\n","Train_dice: 0.9551\n","131/222, Train_loss: 0.0481\n","Train_dice: 0.9595\n","132/222, Train_loss: 0.0593\n","Train_dice: 0.9493\n","133/222, Train_loss: 0.0579\n","Train_dice: 0.9461\n","134/222, Train_loss: 0.0703\n","Train_dice: 0.9355\n","135/222, Train_loss: 0.0529\n","Train_dice: 0.9530\n","136/222, Train_loss: 0.0515\n","Train_dice: 0.9528\n","137/222, Train_loss: 0.0578\n","Train_dice: 0.9428\n","138/222, Train_loss: 0.0584\n","Train_dice: 0.9510\n","139/222, Train_loss: 0.0578\n","Train_dice: 0.9465\n","140/222, Train_loss: 0.0553\n","Train_dice: 0.9493\n","141/222, Train_loss: 0.0553\n","Train_dice: 0.9520\n","142/222, Train_loss: 0.0509\n","Train_dice: 0.9526\n","143/222, Train_loss: 0.0591\n","Train_dice: 0.9439\n","144/222, Train_loss: 0.0542\n","Train_dice: 0.9520\n","145/222, Train_loss: 0.0513\n","Train_dice: 0.9528\n","146/222, Train_loss: 0.0586\n","Train_dice: 0.9429\n","147/222, Train_loss: 0.0652\n","Train_dice: 0.9416\n","148/222, Train_loss: 0.0568\n","Train_dice: 0.9508\n","149/222, Train_loss: 0.0948\n","Train_dice: 0.9121\n","150/222, Train_loss: 0.0695\n","Train_dice: 0.9320\n","151/222, Train_loss: 0.0690\n","Train_dice: 0.9312\n","152/222, Train_loss: 0.0781\n","Train_dice: 0.9276\n","153/222, Train_loss: 0.0560\n","Train_dice: 0.9513\n","154/222, Train_loss: 0.0910\n","Train_dice: 0.9130\n","155/222, Train_loss: 0.0675\n","Train_dice: 0.9368\n","156/222, Train_loss: 0.0500\n","Train_dice: 0.9446\n","157/222, Train_loss: 0.0639\n","Train_dice: 0.9442\n","158/222, Train_loss: 0.0628\n","Train_dice: 0.9416\n","159/222, Train_loss: 0.0744\n","Train_dice: 0.9258\n","160/222, Train_loss: 0.0590\n","Train_dice: 0.9449\n","161/222, Train_loss: 0.0627\n","Train_dice: 0.9246\n","162/222, Train_loss: 0.0555\n","Train_dice: 0.9494\n","163/222, Train_loss: 0.0593\n","Train_dice: 0.9395\n","164/222, Train_loss: 0.0561\n","Train_dice: 0.9490\n","165/222, Train_loss: 0.0634\n","Train_dice: 0.9350\n","166/222, Train_loss: 0.0511\n","Train_dice: 0.9525\n","167/222, Train_loss: 0.0568\n","Train_dice: 0.9476\n","168/222, Train_loss: 0.0709\n","Train_dice: 0.9298\n","169/222, Train_loss: 0.0550\n","Train_dice: 0.9476\n","170/222, Train_loss: 0.0634\n","Train_dice: 0.9439\n","171/222, Train_loss: 0.0746\n","Train_dice: 0.9166\n","172/222, Train_loss: 0.0471\n","Train_dice: 0.9511\n","173/222, Train_loss: 0.0997\n","Train_dice: 0.8884\n","174/222, Train_loss: 0.0890\n","Train_dice: 0.9217\n","175/222, Train_loss: 0.0699\n","Train_dice: 0.9346\n","176/222, Train_loss: 0.0594\n","Train_dice: 0.9466\n","177/222, Train_loss: 0.0706\n","Train_dice: 0.9322\n","178/222, Train_loss: 0.0775\n","Train_dice: 0.9291\n","179/222, Train_loss: 0.0815\n","Train_dice: 0.9303\n","180/222, Train_loss: 0.1225\n","Train_dice: 0.8189\n","181/222, Train_loss: 0.0843\n","Train_dice: 0.9211\n","182/222, Train_loss: 0.0605\n","Train_dice: 0.9495\n","183/222, Train_loss: 0.0711\n","Train_dice: 0.9071\n","184/222, Train_loss: 0.0597\n","Train_dice: 0.9457\n","185/222, Train_loss: 0.0538\n","Train_dice: 0.9566\n","186/222, Train_loss: 0.0719\n","Train_dice: 0.9363\n","187/222, Train_loss: 0.0590\n","Train_dice: 0.9434\n","188/222, Train_loss: 0.0703\n","Train_dice: 0.9424\n","189/222, Train_loss: 0.0674\n","Train_dice: 0.9384\n","190/222, Train_loss: 0.0594\n","Train_dice: 0.9480\n","191/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0470\n","Train_dice: 0.9621\n","195/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0557\n","Train_dice: 0.9515\n","197/222, Train_loss: 0.1051\n","Train_dice: 0.8804\n","198/222, Train_loss: 0.0473\n","Train_dice: 0.9624\n","199/222, Train_loss: 0.0725\n","Train_dice: 0.9358\n","200/222, Train_loss: 0.0559\n","Train_dice: 0.9503\n","201/222, Train_loss: 0.0612\n","Train_dice: 0.9412\n","202/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","203/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","204/222, Train_loss: 0.0716\n","Train_dice: 0.9327\n","205/222, Train_loss: 0.0696\n","Train_dice: 0.9350\n","206/222, Train_loss: 0.0513\n","Train_dice: 0.9567\n","207/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","208/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","209/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","210/222, Train_loss: 0.5002\n","Train_dice: 0.4998\n","211/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0795\n","Train_dice: 0.9251\n","214/222, Train_loss: 0.0447\n","Train_dice: 0.9584\n","215/222, Train_loss: 0.0491\n","Train_dice: 0.9576\n","216/222, Train_loss: 0.0484\n","Train_dice: 0.9591\n","217/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0698\n","Train_dice: 0.9326\n","219/222, Train_loss: 0.0556\n","Train_dice: 0.9498\n","220/222, Train_loss: 0.0718\n","Train_dice: 0.9121\n","221/222, Train_loss: 0.3678\n","Train_dice: 0.5921\n","222/222, Train_loss: 0.0452\n","Train_dice: 0.9558\n","--------------------\n","Epoch_loss: 0.0984\n","Epoch_metric: 0.9042\n","test_loss_epoch: 0.2237\n","test_dice_epoch: 0.7906\n","Confusion Matrix:\n","[[58314351    49183]\n"," [  191274   165448]]\n","test_loss_epoch: 0.0040\n","test_dice_epoch: 0.0141\n","current epoch: 37 current mean dice: 0.8388\n","best mean dice: 0.0143 at epoch: 35\n","----------\n","epoch 38/150\n","1/222, Train_loss: 0.0485\n","Train_dice: 0.9571\n","2/222, Train_loss: 0.0672\n","Train_dice: 0.9462\n","3/222, Train_loss: 0.0529\n","Train_dice: 0.9591\n","4/222, Train_loss: 0.0439\n","Train_dice: 0.9656\n","5/222, Train_loss: 0.0656\n","Train_dice: 0.9466\n","6/222, Train_loss: 0.0644\n","Train_dice: 0.9473\n","7/222, Train_loss: 0.0555\n","Train_dice: 0.9544\n","8/222, Train_loss: 0.0518\n","Train_dice: 0.9568\n","9/222, Train_loss: 0.0524\n","Train_dice: 0.9561\n","10/222, Train_loss: 0.0589\n","Train_dice: 0.9490\n","11/222, Train_loss: 0.0432\n","Train_dice: 0.9630\n","12/222, Train_loss: 0.0563\n","Train_dice: 0.9517\n","13/222, Train_loss: 0.0582\n","Train_dice: 0.9510\n","14/222, Train_loss: 0.0630\n","Train_dice: 0.9474\n","15/222, Train_loss: 0.0548\n","Train_dice: 0.9516\n","16/222, Train_loss: 0.0654\n","Train_dice: 0.9408\n","17/222, Train_loss: 0.0581\n","Train_dice: 0.9477\n","18/222, Train_loss: 0.0437\n","Train_dice: 0.9618\n","19/222, Train_loss: 0.0479\n","Train_dice: 0.9496\n","20/222, Train_loss: 0.0877\n","Train_dice: 0.9161\n","21/222, Train_loss: 0.0538\n","Train_dice: 0.9476\n","22/222, Train_loss: 0.0652\n","Train_dice: 0.9437\n","23/222, Train_loss: 0.0600\n","Train_dice: 0.9434\n","24/222, Train_loss: 0.0635\n","Train_dice: 0.9407\n","25/222, Train_loss: 0.1270\n","Train_dice: 0.8216\n","26/222, Train_loss: 0.0538\n","Train_dice: 0.9556\n","27/222, Train_loss: 0.0570\n","Train_dice: 0.9516\n","28/222, Train_loss: 0.0694\n","Train_dice: 0.9043\n","29/222, Train_loss: 0.0542\n","Train_dice: 0.9547\n","30/222, Train_loss: 0.0707\n","Train_dice: 0.9368\n","31/222, Train_loss: 0.0602\n","Train_dice: 0.9453\n","32/222, Train_loss: 0.0498\n","Train_dice: 0.9557\n","33/222, Train_loss: 0.0554\n","Train_dice: 0.9515\n","34/222, Train_loss: 0.0622\n","Train_dice: 0.9466\n","35/222, Train_loss: 0.0543\n","Train_dice: 0.9565\n","36/222, Train_loss: 0.0654\n","Train_dice: 0.9419\n","37/222, Train_loss: 0.0534\n","Train_dice: 0.9568\n","38/222, Train_loss: 0.0817\n","Train_dice: 0.9229\n","39/222, Train_loss: 0.0441\n","Train_dice: 0.9635\n","40/222, Train_loss: 0.0472\n","Train_dice: 0.9600\n","41/222, Train_loss: 0.1020\n","Train_dice: 0.8921\n","42/222, Train_loss: 0.0736\n","Train_dice: 0.9366\n","43/222, Train_loss: 0.0493\n","Train_dice: 0.9594\n","44/222, Train_loss: 0.0880\n","Train_dice: 0.8355\n","45/222, Train_loss: 0.0643\n","Train_dice: 0.9390\n","46/222, Train_loss: 0.0570\n","Train_dice: 0.9456\n","47/222, Train_loss: 0.0623\n","Train_dice: 0.9376\n","48/222, Train_loss: 0.0482\n","Train_dice: 0.9574\n","49/222, Train_loss: 0.0644\n","Train_dice: 0.9414\n","50/222, Train_loss: 0.0601\n","Train_dice: 0.9437\n","51/222, Train_loss: 0.2290\n","Train_dice: 0.7217\n","52/222, Train_loss: 0.0612\n","Train_dice: 0.9433\n","53/222, Train_loss: 0.0535\n","Train_dice: 0.9526\n","54/222, Train_loss: 0.0550\n","Train_dice: 0.9532\n","55/222, Train_loss: 0.0501\n","Train_dice: 0.9574\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0550\n","Train_dice: 0.9519\n","58/222, Train_loss: 0.0678\n","Train_dice: 0.9388\n","59/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","60/222, Train_loss: 0.0588\n","Train_dice: 0.9492\n","61/222, Train_loss: 0.0568\n","Train_dice: 0.9507\n","62/222, Train_loss: 0.0729\n","Train_dice: 0.9382\n","63/222, Train_loss: 0.5002\n","Train_dice: 0.4998\n","64/222, Train_loss: 0.0694\n","Train_dice: 0.9403\n","65/222, Train_loss: 0.0558\n","Train_dice: 0.9507\n","66/222, Train_loss: 0.0542\n","Train_dice: 0.9528\n","67/222, Train_loss: 0.0670\n","Train_dice: 0.9428\n","68/222, Train_loss: 0.0629\n","Train_dice: 0.9466\n","69/222, Train_loss: 0.0491\n","Train_dice: 0.9560\n","70/222, Train_loss: 0.0543\n","Train_dice: 0.9571\n","71/222, Train_loss: 0.0686\n","Train_dice: 0.9382\n","72/222, Train_loss: 0.0465\n","Train_dice: 0.9611\n","73/222, Train_loss: 0.0516\n","Train_dice: 0.9537\n","74/222, Train_loss: 0.0571\n","Train_dice: 0.9471\n","75/222, Train_loss: 0.0486\n","Train_dice: 0.9571\n","76/222, Train_loss: 0.0780\n","Train_dice: 0.9288\n","77/222, Train_loss: 0.0749\n","Train_dice: 0.9303\n","78/222, Train_loss: 0.0548\n","Train_dice: 0.9515\n","79/222, Train_loss: 0.0650\n","Train_dice: 0.9407\n","80/222, Train_loss: 0.0692\n","Train_dice: 0.9366\n","81/222, Train_loss: 0.0562\n","Train_dice: 0.9448\n","82/222, Train_loss: 0.0558\n","Train_dice: 0.9480\n","83/222, Train_loss: 0.0467\n","Train_dice: 0.9577\n","84/222, Train_loss: 0.0648\n","Train_dice: 0.9376\n","85/222, Train_loss: 0.0666\n","Train_dice: 0.9375\n","86/222, Train_loss: 0.0741\n","Train_dice: 0.9193\n","87/222, Train_loss: 0.0660\n","Train_dice: 0.9358\n","88/222, Train_loss: 0.0518\n","Train_dice: 0.9556\n","89/222, Train_loss: 0.0743\n","Train_dice: 0.9323\n","90/222, Train_loss: 0.0779\n","Train_dice: 0.9211\n","91/222, Train_loss: 0.0547\n","Train_dice: 0.9436\n","92/222, Train_loss: 0.0523\n","Train_dice: 0.9541\n","93/222, Train_loss: 0.0803\n","Train_dice: 0.9323\n","94/222, Train_loss: 0.0723\n","Train_dice: 0.9311\n","95/222, Train_loss: 0.0999\n","Train_dice: 0.9027\n","96/222, Train_loss: 0.0505\n","Train_dice: 0.9553\n","97/222, Train_loss: 0.0546\n","Train_dice: 0.9508\n","98/222, Train_loss: 0.0644\n","Train_dice: 0.9323\n","99/222, Train_loss: 0.0608\n","Train_dice: 0.9475\n","100/222, Train_loss: 0.0731\n","Train_dice: 0.9319\n","101/222, Train_loss: 0.0568\n","Train_dice: 0.9537\n","102/222, Train_loss: 0.0517\n","Train_dice: 0.9538\n","103/222, Train_loss: 0.0690\n","Train_dice: 0.9439\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0409\n","Train_dice: 0.9489\n","106/222, Train_loss: 0.0491\n","Train_dice: 0.9504\n","107/222, Train_loss: 0.0610\n","Train_dice: 0.9464\n","108/222, Train_loss: 0.0562\n","Train_dice: 0.9483\n","109/222, Train_loss: 0.0532\n","Train_dice: 0.9488\n","110/222, Train_loss: 0.0637\n","Train_dice: 0.9338\n","111/222, Train_loss: 0.0625\n","Train_dice: 0.9417\n","112/222, Train_loss: 0.0516\n","Train_dice: 0.9529\n","113/222, Train_loss: 0.0577\n","Train_dice: 0.9495\n","114/222, Train_loss: 0.0671\n","Train_dice: 0.9302\n","115/222, Train_loss: 0.0539\n","Train_dice: 0.9544\n","116/222, Train_loss: 0.0572\n","Train_dice: 0.9490\n","117/222, Train_loss: 0.0627\n","Train_dice: 0.9453\n","118/222, Train_loss: 0.0780\n","Train_dice: 0.9214\n","119/222, Train_loss: 0.0662\n","Train_dice: 0.9374\n","120/222, Train_loss: 0.0545\n","Train_dice: 0.9540\n","121/222, Train_loss: 0.0583\n","Train_dice: 0.9491\n","122/222, Train_loss: 0.0589\n","Train_dice: 0.9500\n","123/222, Train_loss: 0.0603\n","Train_dice: 0.9434\n","124/222, Train_loss: 0.0832\n","Train_dice: 0.8324\n","125/222, Train_loss: 0.0675\n","Train_dice: 0.9319\n","126/222, Train_loss: 0.0716\n","Train_dice: 0.9370\n","127/222, Train_loss: 0.0567\n","Train_dice: 0.9404\n","128/222, Train_loss: 0.0701\n","Train_dice: 0.9406\n","129/222, Train_loss: 0.0481\n","Train_dice: 0.9563\n","130/222, Train_loss: 0.0496\n","Train_dice: 0.9496\n","131/222, Train_loss: 0.0485\n","Train_dice: 0.9563\n","132/222, Train_loss: 0.0533\n","Train_dice: 0.9516\n","133/222, Train_loss: 0.0565\n","Train_dice: 0.9412\n","134/222, Train_loss: 0.0807\n","Train_dice: 0.9283\n","135/222, Train_loss: 0.0491\n","Train_dice: 0.9571\n","136/222, Train_loss: 0.0473\n","Train_dice: 0.9550\n","137/222, Train_loss: 0.0576\n","Train_dice: 0.9449\n","138/222, Train_loss: 0.0561\n","Train_dice: 0.9513\n","139/222, Train_loss: 0.0690\n","Train_dice: 0.9385\n","140/222, Train_loss: 0.0562\n","Train_dice: 0.9493\n","141/222, Train_loss: 0.0558\n","Train_dice: 0.9509\n","142/222, Train_loss: 0.0544\n","Train_dice: 0.9499\n","143/222, Train_loss: 0.0537\n","Train_dice: 0.9538\n","144/222, Train_loss: 0.0517\n","Train_dice: 0.9541\n","145/222, Train_loss: 0.0556\n","Train_dice: 0.9511\n","146/222, Train_loss: 0.0673\n","Train_dice: 0.9341\n","147/222, Train_loss: 0.0546\n","Train_dice: 0.9515\n","148/222, Train_loss: 0.0554\n","Train_dice: 0.9535\n","149/222, Train_loss: 0.0938\n","Train_dice: 0.8996\n","150/222, Train_loss: 0.0687\n","Train_dice: 0.9339\n","151/222, Train_loss: 0.0683\n","Train_dice: 0.9329\n","152/222, Train_loss: 0.0734\n","Train_dice: 0.9330\n","153/222, Train_loss: 0.0644\n","Train_dice: 0.9425\n","154/222, Train_loss: 0.0859\n","Train_dice: 0.9110\n","155/222, Train_loss: 0.0618\n","Train_dice: 0.9482\n","156/222, Train_loss: 0.0468\n","Train_dice: 0.9474\n","157/222, Train_loss: 0.0715\n","Train_dice: 0.9344\n","158/222, Train_loss: 0.0623\n","Train_dice: 0.9458\n","159/222, Train_loss: 0.0631\n","Train_dice: 0.9379\n","160/222, Train_loss: 0.0489\n","Train_dice: 0.9558\n","161/222, Train_loss: 0.0644\n","Train_dice: 0.9187\n","162/222, Train_loss: 0.0577\n","Train_dice: 0.9472\n","163/222, Train_loss: 0.0579\n","Train_dice: 0.9457\n","164/222, Train_loss: 0.0528\n","Train_dice: 0.9524\n","165/222, Train_loss: 0.0656\n","Train_dice: 0.9363\n","166/222, Train_loss: 0.0537\n","Train_dice: 0.9502\n","167/222, Train_loss: 0.0519\n","Train_dice: 0.9532\n","168/222, Train_loss: 0.0766\n","Train_dice: 0.9277\n","169/222, Train_loss: 0.0502\n","Train_dice: 0.9536\n","170/222, Train_loss: 0.0648\n","Train_dice: 0.9417\n","171/222, Train_loss: 0.0656\n","Train_dice: 0.9263\n","172/222, Train_loss: 0.0472\n","Train_dice: 0.9518\n","173/222, Train_loss: 0.1078\n","Train_dice: 0.8788\n","174/222, Train_loss: 0.0945\n","Train_dice: 0.9088\n","175/222, Train_loss: 0.0625\n","Train_dice: 0.9393\n","176/222, Train_loss: 0.0570\n","Train_dice: 0.9463\n","177/222, Train_loss: 0.0777\n","Train_dice: 0.9263\n","178/222, Train_loss: 0.0835\n","Train_dice: 0.9251\n","179/222, Train_loss: 0.0703\n","Train_dice: 0.9382\n","180/222, Train_loss: 0.1276\n","Train_dice: 0.8155\n","181/222, Train_loss: 0.0869\n","Train_dice: 0.9202\n","182/222, Train_loss: 0.0638\n","Train_dice: 0.9485\n","183/222, Train_loss: 0.0611\n","Train_dice: 0.9151\n","184/222, Train_loss: 0.0599\n","Train_dice: 0.9493\n","185/222, Train_loss: 0.0538\n","Train_dice: 0.9589\n","186/222, Train_loss: 0.0628\n","Train_dice: 0.9469\n","187/222, Train_loss: 0.0463\n","Train_dice: 0.9595\n","188/222, Train_loss: 0.0670\n","Train_dice: 0.9448\n","189/222, Train_loss: 0.0778\n","Train_dice: 0.9301\n","190/222, Train_loss: 0.0574\n","Train_dice: 0.9497\n","191/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0459\n","Train_dice: 0.9623\n","195/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0585\n","Train_dice: 0.9486\n","197/222, Train_loss: 0.0845\n","Train_dice: 0.8928\n","198/222, Train_loss: 0.0462\n","Train_dice: 0.9610\n","199/222, Train_loss: 0.0627\n","Train_dice: 0.9413\n","200/222, Train_loss: 0.0514\n","Train_dice: 0.9492\n","201/222, Train_loss: 0.0699\n","Train_dice: 0.9310\n","202/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","203/222, Train_loss: 0.5002\n","Train_dice: 0.4998\n","204/222, Train_loss: 0.0615\n","Train_dice: 0.9442\n","205/222, Train_loss: 0.0725\n","Train_dice: 0.9318\n","206/222, Train_loss: 0.0590\n","Train_dice: 0.9481\n","207/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","208/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","209/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","210/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","211/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0768\n","Train_dice: 0.9288\n","214/222, Train_loss: 0.0331\n","Train_dice: 0.9694\n","215/222, Train_loss: 0.0495\n","Train_dice: 0.9613\n","216/222, Train_loss: 0.0547\n","Train_dice: 0.9532\n","217/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0596\n","Train_dice: 0.9423\n","219/222, Train_loss: 0.0601\n","Train_dice: 0.9489\n","220/222, Train_loss: 0.0595\n","Train_dice: 0.9135\n","221/222, Train_loss: 0.3593\n","Train_dice: 0.5993\n","222/222, Train_loss: 0.0487\n","Train_dice: 0.9491\n","--------------------\n","Epoch_loss: 0.0975\n","Epoch_metric: 0.9049\n","test_loss_epoch: 0.2179\n","test_dice_epoch: 0.7967\n","Confusion Matrix:\n","[[58316004    47530]\n"," [  187627   169095]]\n","test_loss_epoch: 0.0039\n","test_dice_epoch: 0.0142\n","current epoch: 38 current mean dice: 0.8806\n","best mean dice: 0.0143 at epoch: 35\n","----------\n","epoch 39/150\n","1/222, Train_loss: 0.0514\n","Train_dice: 0.9531\n","2/222, Train_loss: 0.0625\n","Train_dice: 0.9483\n","3/222, Train_loss: 0.0487\n","Train_dice: 0.9592\n","4/222, Train_loss: 0.0317\n","Train_dice: 0.9720\n","5/222, Train_loss: 0.0586\n","Train_dice: 0.9518\n","6/222, Train_loss: 0.0666\n","Train_dice: 0.9449\n","7/222, Train_loss: 0.0467\n","Train_dice: 0.9600\n","8/222, Train_loss: 0.0514\n","Train_dice: 0.9581\n","9/222, Train_loss: 0.0570\n","Train_dice: 0.9496\n","10/222, Train_loss: 0.0587\n","Train_dice: 0.9489\n","11/222, Train_loss: 0.0484\n","Train_dice: 0.9615\n","12/222, Train_loss: 0.0543\n","Train_dice: 0.9558\n","13/222, Train_loss: 0.0549\n","Train_dice: 0.9543\n","14/222, Train_loss: 0.0651\n","Train_dice: 0.9455\n","15/222, Train_loss: 0.0510\n","Train_dice: 0.9563\n","16/222, Train_loss: 0.0661\n","Train_dice: 0.9404\n","17/222, Train_loss: 0.0567\n","Train_dice: 0.9522\n","18/222, Train_loss: 0.0532\n","Train_dice: 0.9566\n","19/222, Train_loss: 0.0498\n","Train_dice: 0.9535\n","20/222, Train_loss: 0.0885\n","Train_dice: 0.9124\n","21/222, Train_loss: 0.0611\n","Train_dice: 0.9395\n","22/222, Train_loss: 0.0598\n","Train_dice: 0.9498\n","23/222, Train_loss: 0.0505\n","Train_dice: 0.9521\n","24/222, Train_loss: 0.0611\n","Train_dice: 0.9422\n","25/222, Train_loss: 0.1125\n","Train_dice: 0.8321\n","26/222, Train_loss: 0.0508\n","Train_dice: 0.9575\n","27/222, Train_loss: 0.0533\n","Train_dice: 0.9545\n","28/222, Train_loss: 0.0724\n","Train_dice: 0.9034\n","29/222, Train_loss: 0.0491\n","Train_dice: 0.9576\n","30/222, Train_loss: 0.0589\n","Train_dice: 0.9410\n","31/222, Train_loss: 0.0654\n","Train_dice: 0.9430\n","32/222, Train_loss: 0.0417\n","Train_dice: 0.9599\n","33/222, Train_loss: 0.0599\n","Train_dice: 0.9504\n","34/222, Train_loss: 0.0663\n","Train_dice: 0.9417\n","35/222, Train_loss: 0.0484\n","Train_dice: 0.9621\n","36/222, Train_loss: 0.0595\n","Train_dice: 0.9518\n","37/222, Train_loss: 0.0625\n","Train_dice: 0.9491\n","38/222, Train_loss: 0.0842\n","Train_dice: 0.9262\n","39/222, Train_loss: 0.0413\n","Train_dice: 0.9672\n","40/222, Train_loss: 0.0480\n","Train_dice: 0.9622\n","41/222, Train_loss: 0.1001\n","Train_dice: 0.8941\n","42/222, Train_loss: 0.0681\n","Train_dice: 0.9420\n","43/222, Train_loss: 0.0481\n","Train_dice: 0.9602\n","44/222, Train_loss: 0.0828\n","Train_dice: 0.8542\n","45/222, Train_loss: 0.0622\n","Train_dice: 0.9432\n","46/222, Train_loss: 0.0513\n","Train_dice: 0.9534\n","47/222, Train_loss: 0.0478\n","Train_dice: 0.9497\n","48/222, Train_loss: 0.0526\n","Train_dice: 0.9524\n","49/222, Train_loss: 0.0613\n","Train_dice: 0.9441\n","50/222, Train_loss: 0.0581\n","Train_dice: 0.9407\n","51/222, Train_loss: 0.1781\n","Train_dice: 0.7305\n","52/222, Train_loss: 0.0607\n","Train_dice: 0.9450\n","53/222, Train_loss: 0.0484\n","Train_dice: 0.9589\n","54/222, Train_loss: 0.0567\n","Train_dice: 0.9507\n","55/222, Train_loss: 0.0507\n","Train_dice: 0.9567\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0518\n","Train_dice: 0.9545\n","58/222, Train_loss: 0.0563\n","Train_dice: 0.9501\n","59/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","60/222, Train_loss: 0.0608\n","Train_dice: 0.9452\n","61/222, Train_loss: 0.0545\n","Train_dice: 0.9536\n","62/222, Train_loss: 0.0655\n","Train_dice: 0.9440\n","63/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","64/222, Train_loss: 0.0673\n","Train_dice: 0.9439\n","65/222, Train_loss: 0.0544\n","Train_dice: 0.9549\n","66/222, Train_loss: 0.0546\n","Train_dice: 0.9544\n","67/222, Train_loss: 0.0685\n","Train_dice: 0.9404\n","68/222, Train_loss: 0.0629\n","Train_dice: 0.9466\n","69/222, Train_loss: 0.0502\n","Train_dice: 0.9556\n","70/222, Train_loss: 0.0497\n","Train_dice: 0.9580\n","71/222, Train_loss: 0.0724\n","Train_dice: 0.9349\n","72/222, Train_loss: 0.0505\n","Train_dice: 0.9575\n","73/222, Train_loss: 0.0456\n","Train_dice: 0.9584\n","74/222, Train_loss: 0.0574\n","Train_dice: 0.9493\n","75/222, Train_loss: 0.0479\n","Train_dice: 0.9585\n","76/222, Train_loss: 0.0735\n","Train_dice: 0.9286\n","77/222, Train_loss: 0.0807\n","Train_dice: 0.9260\n","78/222, Train_loss: 0.0515\n","Train_dice: 0.9561\n","79/222, Train_loss: 0.0764\n","Train_dice: 0.9259\n","80/222, Train_loss: 0.0659\n","Train_dice: 0.9367\n","81/222, Train_loss: 0.0459\n","Train_dice: 0.9545\n","82/222, Train_loss: 0.0556\n","Train_dice: 0.9470\n","83/222, Train_loss: 0.0499\n","Train_dice: 0.9567\n","84/222, Train_loss: 0.0631\n","Train_dice: 0.9410\n","85/222, Train_loss: 0.0590\n","Train_dice: 0.9494\n","86/222, Train_loss: 0.0861\n","Train_dice: 0.9080\n","87/222, Train_loss: 0.0743\n","Train_dice: 0.9322\n","88/222, Train_loss: 0.0546\n","Train_dice: 0.9509\n","89/222, Train_loss: 0.0714\n","Train_dice: 0.9323\n","90/222, Train_loss: 0.0995\n","Train_dice: 0.9034\n","91/222, Train_loss: 0.0664\n","Train_dice: 0.9343\n","92/222, Train_loss: 0.0598\n","Train_dice: 0.9443\n","93/222, Train_loss: 0.0800\n","Train_dice: 0.9237\n","94/222, Train_loss: 0.0815\n","Train_dice: 0.9206\n","95/222, Train_loss: 0.1022\n","Train_dice: 0.9027\n","96/222, Train_loss: 0.0561\n","Train_dice: 0.9487\n","97/222, Train_loss: 0.0605\n","Train_dice: 0.9430\n","98/222, Train_loss: 0.0594\n","Train_dice: 0.9351\n","99/222, Train_loss: 0.0613\n","Train_dice: 0.9437\n","100/222, Train_loss: 0.0711\n","Train_dice: 0.9339\n","101/222, Train_loss: 0.0617\n","Train_dice: 0.9477\n","102/222, Train_loss: 0.0536\n","Train_dice: 0.9527\n","103/222, Train_loss: 0.0819\n","Train_dice: 0.9328\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0582\n","Train_dice: 0.9308\n","106/222, Train_loss: 0.0528\n","Train_dice: 0.9462\n","107/222, Train_loss: 0.0658\n","Train_dice: 0.9394\n","108/222, Train_loss: 0.0528\n","Train_dice: 0.9508\n","109/222, Train_loss: 0.0593\n","Train_dice: 0.9498\n","110/222, Train_loss: 0.0611\n","Train_dice: 0.9405\n","111/222, Train_loss: 0.0634\n","Train_dice: 0.9374\n","112/222, Train_loss: 0.0582\n","Train_dice: 0.9509\n","113/222, Train_loss: 0.0574\n","Train_dice: 0.9486\n","114/222, Train_loss: 0.0693\n","Train_dice: 0.9267\n","115/222, Train_loss: 0.0545\n","Train_dice: 0.9517\n","116/222, Train_loss: 0.0570\n","Train_dice: 0.9476\n","117/222, Train_loss: 0.0587\n","Train_dice: 0.9473\n","118/222, Train_loss: 0.0760\n","Train_dice: 0.9242\n","119/222, Train_loss: 0.0613\n","Train_dice: 0.9411\n","120/222, Train_loss: 0.0536\n","Train_dice: 0.9514\n","121/222, Train_loss: 0.0579\n","Train_dice: 0.9469\n","122/222, Train_loss: 0.0585\n","Train_dice: 0.9525\n","123/222, Train_loss: 0.0533\n","Train_dice: 0.9493\n","124/222, Train_loss: 0.0990\n","Train_dice: 0.8367\n","125/222, Train_loss: 0.0663\n","Train_dice: 0.9345\n","126/222, Train_loss: 0.0722\n","Train_dice: 0.9344\n","127/222, Train_loss: 0.0660\n","Train_dice: 0.9381\n","128/222, Train_loss: 0.0661\n","Train_dice: 0.9445\n","129/222, Train_loss: 0.0554\n","Train_dice: 0.9552\n","130/222, Train_loss: 0.0605\n","Train_dice: 0.9510\n","131/222, Train_loss: 0.0558\n","Train_dice: 0.9518\n","132/222, Train_loss: 0.0615\n","Train_dice: 0.9459\n","133/222, Train_loss: 0.0600\n","Train_dice: 0.9456\n","134/222, Train_loss: 0.0688\n","Train_dice: 0.9406\n","135/222, Train_loss: 0.0511\n","Train_dice: 0.9557\n","136/222, Train_loss: 0.0590\n","Train_dice: 0.9454\n","137/222, Train_loss: 0.0600\n","Train_dice: 0.9370\n","138/222, Train_loss: 0.0553\n","Train_dice: 0.9496\n","139/222, Train_loss: 0.0601\n","Train_dice: 0.9440\n","140/222, Train_loss: 0.0548\n","Train_dice: 0.9485\n","141/222, Train_loss: 0.0552\n","Train_dice: 0.9470\n","142/222, Train_loss: 0.0583\n","Train_dice: 0.9449\n","143/222, Train_loss: 0.0553\n","Train_dice: 0.9513\n","144/222, Train_loss: 0.0476\n","Train_dice: 0.9572\n","145/222, Train_loss: 0.0517\n","Train_dice: 0.9505\n","146/222, Train_loss: 0.0624\n","Train_dice: 0.9385\n","147/222, Train_loss: 0.0649\n","Train_dice: 0.9470\n","148/222, Train_loss: 0.0506\n","Train_dice: 0.9568\n","149/222, Train_loss: 0.0800\n","Train_dice: 0.9143\n","150/222, Train_loss: 0.0717\n","Train_dice: 0.9350\n","151/222, Train_loss: 0.0574\n","Train_dice: 0.9426\n","152/222, Train_loss: 0.0725\n","Train_dice: 0.9359\n","153/222, Train_loss: 0.0629\n","Train_dice: 0.9435\n","154/222, Train_loss: 0.0832\n","Train_dice: 0.9140\n","155/222, Train_loss: 0.0673\n","Train_dice: 0.9424\n","156/222, Train_loss: 0.0469\n","Train_dice: 0.9498\n","157/222, Train_loss: 0.0639\n","Train_dice: 0.9432\n","158/222, Train_loss: 0.0577\n","Train_dice: 0.9464\n","159/222, Train_loss: 0.0687\n","Train_dice: 0.9386\n","160/222, Train_loss: 0.0515\n","Train_dice: 0.9542\n","161/222, Train_loss: 0.0569\n","Train_dice: 0.9327\n","162/222, Train_loss: 0.0522\n","Train_dice: 0.9500\n","163/222, Train_loss: 0.0567\n","Train_dice: 0.9417\n","164/222, Train_loss: 0.0545\n","Train_dice: 0.9495\n","165/222, Train_loss: 0.0792\n","Train_dice: 0.9194\n","166/222, Train_loss: 0.0457\n","Train_dice: 0.9576\n","167/222, Train_loss: 0.0489\n","Train_dice: 0.9534\n","168/222, Train_loss: 0.0654\n","Train_dice: 0.9393\n","169/222, Train_loss: 0.0505\n","Train_dice: 0.9545\n","170/222, Train_loss: 0.0694\n","Train_dice: 0.9391\n","171/222, Train_loss: 0.0644\n","Train_dice: 0.9267\n","172/222, Train_loss: 0.0465\n","Train_dice: 0.9536\n","173/222, Train_loss: 0.0883\n","Train_dice: 0.9037\n","174/222, Train_loss: 0.0773\n","Train_dice: 0.9299\n","175/222, Train_loss: 0.0658\n","Train_dice: 0.9392\n","176/222, Train_loss: 0.0523\n","Train_dice: 0.9517\n","177/222, Train_loss: 0.0740\n","Train_dice: 0.9279\n","178/222, Train_loss: 0.0726\n","Train_dice: 0.9306\n","179/222, Train_loss: 0.0617\n","Train_dice: 0.9419\n","180/222, Train_loss: 0.1069\n","Train_dice: 0.8412\n","181/222, Train_loss: 0.0740\n","Train_dice: 0.9298\n","182/222, Train_loss: 0.0512\n","Train_dice: 0.9580\n","183/222, Train_loss: 0.0499\n","Train_dice: 0.9271\n","184/222, Train_loss: 0.0621\n","Train_dice: 0.9439\n","185/222, Train_loss: 0.0512\n","Train_dice: 0.9568\n","186/222, Train_loss: 0.0582\n","Train_dice: 0.9495\n","187/222, Train_loss: 0.0491\n","Train_dice: 0.9514\n","188/222, Train_loss: 0.0678\n","Train_dice: 0.9431\n","189/222, Train_loss: 0.0695\n","Train_dice: 0.9364\n","190/222, Train_loss: 0.0570\n","Train_dice: 0.9503\n","191/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0444\n","Train_dice: 0.9634\n","195/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0556\n","Train_dice: 0.9540\n","197/222, Train_loss: 0.0880\n","Train_dice: 0.8968\n","198/222, Train_loss: 0.0458\n","Train_dice: 0.9625\n","199/222, Train_loss: 0.0587\n","Train_dice: 0.9474\n","200/222, Train_loss: 0.0500\n","Train_dice: 0.9502\n","201/222, Train_loss: 0.0503\n","Train_dice: 0.9508\n","202/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","203/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","204/222, Train_loss: 0.0579\n","Train_dice: 0.9463\n","205/222, Train_loss: 0.0676\n","Train_dice: 0.9349\n","206/222, Train_loss: 0.0520\n","Train_dice: 0.9558\n","207/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","208/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","209/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","210/222, Train_loss: 0.5002\n","Train_dice: 0.4998\n","211/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0781\n","Train_dice: 0.9276\n","214/222, Train_loss: 0.0373\n","Train_dice: 0.9668\n","215/222, Train_loss: 0.0547\n","Train_dice: 0.9530\n","216/222, Train_loss: 0.0528\n","Train_dice: 0.9512\n","217/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0585\n","Train_dice: 0.9437\n","219/222, Train_loss: 0.0571\n","Train_dice: 0.9498\n","220/222, Train_loss: 0.0547\n","Train_dice: 0.9263\n","221/222, Train_loss: 0.3488\n","Train_dice: 0.5961\n","222/222, Train_loss: 0.0450\n","Train_dice: 0.9526\n","--------------------\n","Epoch_loss: 0.0964\n","Epoch_metric: 0.9060\n","test_loss_epoch: 0.2130\n","test_dice_epoch: 0.8005\n","Confusion Matrix:\n","[[58310016    53518]\n"," [  180867   175855]]\n","test_loss_epoch: 0.0038\n","test_dice_epoch: 0.0143\n","current epoch: 39 current mean dice: 0.8443\n","best mean dice: 0.0143 at epoch: 35\n","----------\n","epoch 40/150\n","1/222, Train_loss: 0.0490\n","Train_dice: 0.9568\n","2/222, Train_loss: 0.0654\n","Train_dice: 0.9448\n","3/222, Train_loss: 0.0469\n","Train_dice: 0.9617\n","4/222, Train_loss: 0.0355\n","Train_dice: 0.9690\n","5/222, Train_loss: 0.0622\n","Train_dice: 0.9510\n","6/222, Train_loss: 0.0571\n","Train_dice: 0.9520\n","7/222, Train_loss: 0.0480\n","Train_dice: 0.9584\n","8/222, Train_loss: 0.0501\n","Train_dice: 0.9585\n","9/222, Train_loss: 0.0511\n","Train_dice: 0.9567\n","10/222, Train_loss: 0.0513\n","Train_dice: 0.9569\n","11/222, Train_loss: 0.0534\n","Train_dice: 0.9575\n","12/222, Train_loss: 0.0524\n","Train_dice: 0.9584\n","13/222, Train_loss: 0.0598\n","Train_dice: 0.9506\n","14/222, Train_loss: 0.0579\n","Train_dice: 0.9540\n","15/222, Train_loss: 0.0500\n","Train_dice: 0.9575\n","16/222, Train_loss: 0.0690\n","Train_dice: 0.9404\n","17/222, Train_loss: 0.0565\n","Train_dice: 0.9522\n","18/222, Train_loss: 0.0491\n","Train_dice: 0.9573\n","19/222, Train_loss: 0.0518\n","Train_dice: 0.9522\n","20/222, Train_loss: 0.0871\n","Train_dice: 0.9156\n","21/222, Train_loss: 0.0642\n","Train_dice: 0.9439\n","22/222, Train_loss: 0.0653\n","Train_dice: 0.9449\n","23/222, Train_loss: 0.0482\n","Train_dice: 0.9557\n","24/222, Train_loss: 0.0687\n","Train_dice: 0.9398\n","25/222, Train_loss: 0.1089\n","Train_dice: 0.8325\n","26/222, Train_loss: 0.0526\n","Train_dice: 0.9543\n","27/222, Train_loss: 0.0539\n","Train_dice: 0.9517\n","28/222, Train_loss: 0.0742\n","Train_dice: 0.8936\n","29/222, Train_loss: 0.0506\n","Train_dice: 0.9533\n","30/222, Train_loss: 0.0543\n","Train_dice: 0.9475\n","31/222, Train_loss: 0.0662\n","Train_dice: 0.9368\n","32/222, Train_loss: 0.0521\n","Train_dice: 0.9478\n","33/222, Train_loss: 0.0606\n","Train_dice: 0.9467\n","34/222, Train_loss: 0.0680\n","Train_dice: 0.9417\n","35/222, Train_loss: 0.0523\n","Train_dice: 0.9514\n","36/222, Train_loss: 0.0672\n","Train_dice: 0.9398\n","37/222, Train_loss: 0.0531\n","Train_dice: 0.9548\n","38/222, Train_loss: 0.0894\n","Train_dice: 0.9156\n","39/222, Train_loss: 0.0464\n","Train_dice: 0.9578\n","40/222, Train_loss: 0.0463\n","Train_dice: 0.9612\n","41/222, Train_loss: 0.0931\n","Train_dice: 0.9012\n","42/222, Train_loss: 0.0679\n","Train_dice: 0.9433\n","43/222, Train_loss: 0.0517\n","Train_dice: 0.9610\n","44/222, Train_loss: 0.1058\n","Train_dice: 0.8131\n","45/222, Train_loss: 0.0585\n","Train_dice: 0.9480\n","46/222, Train_loss: 0.0518\n","Train_dice: 0.9585\n","47/222, Train_loss: 0.0482\n","Train_dice: 0.9500\n","48/222, Train_loss: 0.0483\n","Train_dice: 0.9609\n","49/222, Train_loss: 0.0666\n","Train_dice: 0.9422\n","50/222, Train_loss: 0.0572\n","Train_dice: 0.9458\n","51/222, Train_loss: 0.1715\n","Train_dice: 0.7383\n","52/222, Train_loss: 0.0635\n","Train_dice: 0.9406\n","53/222, Train_loss: 0.0555\n","Train_dice: 0.9539\n","54/222, Train_loss: 0.0544\n","Train_dice: 0.9555\n","55/222, Train_loss: 0.0467\n","Train_dice: 0.9605\n","56/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","57/222, Train_loss: 0.0518\n","Train_dice: 0.9564\n","58/222, Train_loss: 0.0581\n","Train_dice: 0.9490\n","59/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","60/222, Train_loss: 0.0524\n","Train_dice: 0.9552\n","61/222, Train_loss: 0.0498\n","Train_dice: 0.9578\n","62/222, Train_loss: 0.0621\n","Train_dice: 0.9473\n","63/222, Train_loss: 0.5003\n","Train_dice: 0.4998\n","64/222, Train_loss: 0.0635\n","Train_dice: 0.9446\n","65/222, Train_loss: 0.0566\n","Train_dice: 0.9497\n","66/222, Train_loss: 0.0529\n","Train_dice: 0.9535\n","67/222, Train_loss: 0.0625\n","Train_dice: 0.9464\n","68/222, Train_loss: 0.0627\n","Train_dice: 0.9464\n","69/222, Train_loss: 0.0500\n","Train_dice: 0.9551\n","70/222, Train_loss: 0.0495\n","Train_dice: 0.9598\n","71/222, Train_loss: 0.0630\n","Train_dice: 0.9446\n","72/222, Train_loss: 0.0462\n","Train_dice: 0.9588\n","73/222, Train_loss: 0.0516\n","Train_dice: 0.9530\n","74/222, Train_loss: 0.0562\n","Train_dice: 0.9487\n","75/222, Train_loss: 0.0449\n","Train_dice: 0.9612\n","76/222, Train_loss: 0.0784\n","Train_dice: 0.9242\n","77/222, Train_loss: 0.0787\n","Train_dice: 0.9278\n","78/222, Train_loss: 0.0556\n","Train_dice: 0.9527\n","79/222, Train_loss: 0.0702\n","Train_dice: 0.9371\n","80/222, Train_loss: 0.0677\n","Train_dice: 0.9358\n","81/222, Train_loss: 0.0521\n","Train_dice: 0.9555\n","82/222, Train_loss: 0.0553\n","Train_dice: 0.9483\n","83/222, Train_loss: 0.0473\n","Train_dice: 0.9615\n","84/222, Train_loss: 0.0502\n","Train_dice: 0.9552\n","85/222, Train_loss: 0.0593\n","Train_dice: 0.9489\n","86/222, Train_loss: 0.1031\n","Train_dice: 0.8968\n","87/222, Train_loss: 0.0734\n","Train_dice: 0.9268\n","88/222, Train_loss: 0.0546\n","Train_dice: 0.9490\n","89/222, Train_loss: 0.0720\n","Train_dice: 0.9360\n","90/222, Train_loss: 0.0850\n","Train_dice: 0.9151\n","91/222, Train_loss: 0.0607\n","Train_dice: 0.9417\n","92/222, Train_loss: 0.0558\n","Train_dice: 0.9525\n","93/222, Train_loss: 0.0724\n","Train_dice: 0.9312\n","94/222, Train_loss: 0.0685\n","Train_dice: 0.9400\n","95/222, Train_loss: 0.0951\n","Train_dice: 0.9080\n","96/222, Train_loss: 0.0543\n","Train_dice: 0.9495\n","97/222, Train_loss: 0.0646\n","Train_dice: 0.9386\n","98/222, Train_loss: 0.0695\n","Train_dice: 0.9228\n","99/222, Train_loss: 0.0601\n","Train_dice: 0.9451\n","100/222, Train_loss: 0.0683\n","Train_dice: 0.9339\n","101/222, Train_loss: 0.0526\n","Train_dice: 0.9515\n","102/222, Train_loss: 0.0497\n","Train_dice: 0.9580\n","103/222, Train_loss: 0.0698\n","Train_dice: 0.9419\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0464\n","Train_dice: 0.9463\n","106/222, Train_loss: 0.0589\n","Train_dice: 0.9431\n","107/222, Train_loss: 0.0689\n","Train_dice: 0.9361\n","108/222, Train_loss: 0.0554\n","Train_dice: 0.9510\n","109/222, Train_loss: 0.0570\n","Train_dice: 0.9489\n","110/222, Train_loss: 0.0653\n","Train_dice: 0.9341\n","111/222, Train_loss: 0.0537\n","Train_dice: 0.9466\n","112/222, Train_loss: 0.0516\n","Train_dice: 0.9533\n","113/222, Train_loss: 0.0544\n","Train_dice: 0.9502\n","114/222, Train_loss: 0.0676\n","Train_dice: 0.9295\n","115/222, Train_loss: 0.0490\n","Train_dice: 0.9541\n","116/222, Train_loss: 0.0521\n","Train_dice: 0.9519\n","117/222, Train_loss: 0.0595\n","Train_dice: 0.9481\n","118/222, Train_loss: 0.0699\n","Train_dice: 0.9324\n","119/222, Train_loss: 0.0587\n","Train_dice: 0.9483\n","120/222, Train_loss: 0.0525\n","Train_dice: 0.9534\n","121/222, Train_loss: 0.0565\n","Train_dice: 0.9507\n","122/222, Train_loss: 0.0537\n","Train_dice: 0.9540\n","123/222, Train_loss: 0.0546\n","Train_dice: 0.9499\n","124/222, Train_loss: 0.0787\n","Train_dice: 0.8576\n","125/222, Train_loss: 0.0517\n","Train_dice: 0.9458\n","126/222, Train_loss: 0.0611\n","Train_dice: 0.9449\n","127/222, Train_loss: 0.0578\n","Train_dice: 0.9402\n","128/222, Train_loss: 0.0732\n","Train_dice: 0.9383\n","129/222, Train_loss: 0.0499\n","Train_dice: 0.9601\n","130/222, Train_loss: 0.0530\n","Train_dice: 0.9492\n","131/222, Train_loss: 0.0467\n","Train_dice: 0.9590\n","132/222, Train_loss: 0.0565\n","Train_dice: 0.9521\n","133/222, Train_loss: 0.0585\n","Train_dice: 0.9452\n","134/222, Train_loss: 0.0648\n","Train_dice: 0.9438\n","135/222, Train_loss: 0.0505\n","Train_dice: 0.9597\n","136/222, Train_loss: 0.0503\n","Train_dice: 0.9584\n","137/222, Train_loss: 0.0532\n","Train_dice: 0.9483\n","138/222, Train_loss: 0.0546\n","Train_dice: 0.9548\n","139/222, Train_loss: 0.0586\n","Train_dice: 0.9494\n","140/222, Train_loss: 0.0536\n","Train_dice: 0.9513\n","141/222, Train_loss: 0.0522\n","Train_dice: 0.9524\n","142/222, Train_loss: 0.0560\n","Train_dice: 0.9477\n","143/222, Train_loss: 0.0580\n","Train_dice: 0.9447\n","144/222, Train_loss: 0.0512\n","Train_dice: 0.9535\n","145/222, Train_loss: 0.0469\n","Train_dice: 0.9555\n","146/222, Train_loss: 0.0601\n","Train_dice: 0.9420\n","147/222, Train_loss: 0.0657\n","Train_dice: 0.9402\n","148/222, Train_loss: 0.0510\n","Train_dice: 0.9556\n","149/222, Train_loss: 0.1007\n","Train_dice: 0.8979\n","150/222, Train_loss: 0.0777\n","Train_dice: 0.9225\n","151/222, Train_loss: 0.0598\n","Train_dice: 0.9431\n","152/222, Train_loss: 0.0715\n","Train_dice: 0.9339\n","153/222, Train_loss: 0.0678\n","Train_dice: 0.9338\n","154/222, Train_loss: 0.0681\n","Train_dice: 0.9261\n","155/222, Train_loss: 0.0629\n","Train_dice: 0.9432\n","156/222, Train_loss: 0.0550\n","Train_dice: 0.9449\n","157/222, Train_loss: 0.0544\n","Train_dice: 0.9507\n","158/222, Train_loss: 0.0696\n","Train_dice: 0.9375\n","159/222, Train_loss: 0.0615\n","Train_dice: 0.9369\n","160/222, Train_loss: 0.0469\n","Train_dice: 0.9591\n","161/222, Train_loss: 0.0548\n","Train_dice: 0.9347\n","162/222, Train_loss: 0.0555\n","Train_dice: 0.9503\n","163/222, Train_loss: 0.0527\n","Train_dice: 0.9523\n","164/222, Train_loss: 0.0631\n","Train_dice: 0.9483\n","165/222, Train_loss: 0.0621\n","Train_dice: 0.9410\n","166/222, Train_loss: 0.0653\n","Train_dice: 0.9448\n","167/222, Train_loss: 0.0515\n","Train_dice: 0.9546\n","168/222, Train_loss: 0.0651\n","Train_dice: 0.9379\n","169/222, Train_loss: 0.0528\n","Train_dice: 0.9522\n","170/222, Train_loss: 0.0565\n","Train_dice: 0.9520\n","171/222, Train_loss: 0.0629\n","Train_dice: 0.9282\n","172/222, Train_loss: 0.0509\n","Train_dice: 0.9493\n","173/222, Train_loss: 0.1078\n","Train_dice: 0.8817\n","174/222, Train_loss: 0.0856\n","Train_dice: 0.9214\n","175/222, Train_loss: 0.0598\n","Train_dice: 0.9385\n","176/222, Train_loss: 0.0581\n","Train_dice: 0.9442\n","177/222, Train_loss: 0.0612\n","Train_dice: 0.9425\n","178/222, Train_loss: 0.0756\n","Train_dice: 0.9301\n","179/222, Train_loss: 0.0708\n","Train_dice: 0.9381\n","180/222, Train_loss: 0.1246\n","Train_dice: 0.8276\n","181/222, Train_loss: 0.0829\n","Train_dice: 0.9249\n","182/222, Train_loss: 0.0573\n","Train_dice: 0.9529\n","183/222, Train_loss: 0.0646\n","Train_dice: 0.9114\n","184/222, Train_loss: 0.0607\n","Train_dice: 0.9475\n","185/222, Train_loss: 0.0459\n","Train_dice: 0.9617\n","186/222, Train_loss: 0.0629\n","Train_dice: 0.9457\n","187/222, Train_loss: 0.0473\n","Train_dice: 0.9552\n","188/222, Train_loss: 0.0751\n","Train_dice: 0.9364\n","189/222, Train_loss: 0.0639\n","Train_dice: 0.9421\n","190/222, Train_loss: 0.0581\n","Train_dice: 0.9502\n","191/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0422\n","Train_dice: 0.9662\n","195/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0543\n","Train_dice: 0.9543\n","197/222, Train_loss: 0.0877\n","Train_dice: 0.8982\n","198/222, Train_loss: 0.0430\n","Train_dice: 0.9646\n","199/222, Train_loss: 0.0676\n","Train_dice: 0.9409\n","200/222, Train_loss: 0.0631\n","Train_dice: 0.9428\n","201/222, Train_loss: 0.0608\n","Train_dice: 0.9426\n","202/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","203/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","204/222, Train_loss: 0.0602\n","Train_dice: 0.9472\n","205/222, Train_loss: 0.0718\n","Train_dice: 0.9295\n","206/222, Train_loss: 0.0561\n","Train_dice: 0.9501\n","207/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","208/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","209/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","210/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","211/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0679\n","Train_dice: 0.9365\n","214/222, Train_loss: 0.0331\n","Train_dice: 0.9694\n","215/222, Train_loss: 0.0487\n","Train_dice: 0.9578\n","216/222, Train_loss: 0.0558\n","Train_dice: 0.9482\n","217/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0786\n","Train_dice: 0.9286\n","219/222, Train_loss: 0.0568\n","Train_dice: 0.9492\n","220/222, Train_loss: 0.0584\n","Train_dice: 0.9228\n","221/222, Train_loss: 0.3171\n","Train_dice: 0.6119\n","222/222, Train_loss: 0.0473\n","Train_dice: 0.9537\n","--------------------\n","Epoch_loss: 0.0959\n","Epoch_metric: 0.9065\n","test_loss_epoch: 0.2095\n","test_dice_epoch: 0.8030\n","Confusion Matrix:\n","[[58296612    66922]\n"," [  171909   184813]]\n","test_loss_epoch: 0.0037\n","test_dice_epoch: 0.0143\n","current epoch: 40 current mean dice: 0.8893\n","best mean dice: 0.0143 at epoch: 40\n","----------\n","epoch 41/150\n","1/222, Train_loss: 0.0492\n","Train_dice: 0.9575\n","2/222, Train_loss: 0.0591\n","Train_dice: 0.9512\n","3/222, Train_loss: 0.0503\n","Train_dice: 0.9574\n","4/222, Train_loss: 0.0311\n","Train_dice: 0.9750\n","5/222, Train_loss: 0.0617\n","Train_dice: 0.9489\n","6/222, Train_loss: 0.0579\n","Train_dice: 0.9513\n","7/222, Train_loss: 0.0490\n","Train_dice: 0.9610\n","8/222, Train_loss: 0.0480\n","Train_dice: 0.9585\n","9/222, Train_loss: 0.0486\n","Train_dice: 0.9592\n","10/222, Train_loss: 0.0548\n","Train_dice: 0.9525\n","11/222, Train_loss: 0.0468\n","Train_dice: 0.9585\n","12/222, Train_loss: 0.0579\n","Train_dice: 0.9531\n","13/222, Train_loss: 0.0582\n","Train_dice: 0.9523\n","14/222, Train_loss: 0.0573\n","Train_dice: 0.9542\n","15/222, Train_loss: 0.0529\n","Train_dice: 0.9546\n","16/222, Train_loss: 0.0651\n","Train_dice: 0.9431\n","17/222, Train_loss: 0.0592\n","Train_dice: 0.9482\n","18/222, Train_loss: 0.0457\n","Train_dice: 0.9606\n","19/222, Train_loss: 0.0562\n","Train_dice: 0.9457\n","20/222, Train_loss: 0.0730\n","Train_dice: 0.9308\n","21/222, Train_loss: 0.0603\n","Train_dice: 0.9415\n","22/222, Train_loss: 0.0590\n","Train_dice: 0.9500\n","23/222, Train_loss: 0.0490\n","Train_dice: 0.9573\n","24/222, Train_loss: 0.0633\n","Train_dice: 0.9413\n","25/222, Train_loss: 0.1253\n","Train_dice: 0.8182\n","26/222, Train_loss: 0.0518\n","Train_dice: 0.9567\n","27/222, Train_loss: 0.0556\n","Train_dice: 0.9557\n","28/222, Train_loss: 0.0807\n","Train_dice: 0.8980\n","29/222, Train_loss: 0.0557\n","Train_dice: 0.9524\n","30/222, Train_loss: 0.0622\n","Train_dice: 0.9418\n","31/222, Train_loss: 0.0588\n","Train_dice: 0.9465\n","32/222, Train_loss: 0.0566\n","Train_dice: 0.9538\n","33/222, Train_loss: 0.0546\n","Train_dice: 0.9518\n","34/222, Train_loss: 0.0658\n","Train_dice: 0.9437\n","35/222, Train_loss: 0.0492\n","Train_dice: 0.9590\n","36/222, Train_loss: 0.0560\n","Train_dice: 0.9511\n","37/222, Train_loss: 0.0549\n","Train_dice: 0.9537\n","38/222, Train_loss: 0.0804\n","Train_dice: 0.9229\n","39/222, Train_loss: 0.0423\n","Train_dice: 0.9635\n","40/222, Train_loss: 0.0459\n","Train_dice: 0.9594\n","41/222, Train_loss: 0.0911\n","Train_dice: 0.9064\n","42/222, Train_loss: 0.0722\n","Train_dice: 0.9394\n","43/222, Train_loss: 0.0508\n","Train_dice: 0.9565\n","44/222, Train_loss: 0.0722\n","Train_dice: 0.8587\n","45/222, Train_loss: 0.0582\n","Train_dice: 0.9465\n","46/222, Train_loss: 0.0491\n","Train_dice: 0.9586\n","47/222, Train_loss: 0.0539\n","Train_dice: 0.9517\n","48/222, Train_loss: 0.0458\n","Train_dice: 0.9612\n","49/222, Train_loss: 0.0620\n","Train_dice: 0.9461\n","50/222, Train_loss: 0.0621\n","Train_dice: 0.9424\n","51/222, Train_loss: 0.1319\n","Train_dice: 0.7286\n","52/222, Train_loss: 0.0599\n","Train_dice: 0.9466\n","53/222, Train_loss: 0.0463\n","Train_dice: 0.9605\n","54/222, Train_loss: 0.0549\n","Train_dice: 0.9541\n","55/222, Train_loss: 0.0458\n","Train_dice: 0.9614\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0498\n","Train_dice: 0.9606\n","58/222, Train_loss: 0.0578\n","Train_dice: 0.9478\n","59/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","60/222, Train_loss: 0.0554\n","Train_dice: 0.9516\n","61/222, Train_loss: 0.0579\n","Train_dice: 0.9503\n","62/222, Train_loss: 0.0579\n","Train_dice: 0.9512\n","63/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","64/222, Train_loss: 0.0586\n","Train_dice: 0.9492\n","65/222, Train_loss: 0.0622\n","Train_dice: 0.9428\n","66/222, Train_loss: 0.0528\n","Train_dice: 0.9532\n","67/222, Train_loss: 0.0697\n","Train_dice: 0.9337\n","68/222, Train_loss: 0.0564\n","Train_dice: 0.9514\n","69/222, Train_loss: 0.0472\n","Train_dice: 0.9585\n","70/222, Train_loss: 0.0488\n","Train_dice: 0.9596\n","71/222, Train_loss: 0.0591\n","Train_dice: 0.9454\n","72/222, Train_loss: 0.0513\n","Train_dice: 0.9597\n","73/222, Train_loss: 0.0536\n","Train_dice: 0.9544\n","74/222, Train_loss: 0.0553\n","Train_dice: 0.9506\n","75/222, Train_loss: 0.0478\n","Train_dice: 0.9587\n","76/222, Train_loss: 0.0876\n","Train_dice: 0.9139\n","77/222, Train_loss: 0.0667\n","Train_dice: 0.9409\n","78/222, Train_loss: 0.0537\n","Train_dice: 0.9568\n","79/222, Train_loss: 0.0665\n","Train_dice: 0.9416\n","80/222, Train_loss: 0.0624\n","Train_dice: 0.9473\n","81/222, Train_loss: 0.0468\n","Train_dice: 0.9566\n","82/222, Train_loss: 0.0558\n","Train_dice: 0.9495\n","83/222, Train_loss: 0.0484\n","Train_dice: 0.9568\n","84/222, Train_loss: 0.0569\n","Train_dice: 0.9474\n","85/222, Train_loss: 0.0573\n","Train_dice: 0.9506\n","86/222, Train_loss: 0.0812\n","Train_dice: 0.9175\n","87/222, Train_loss: 0.0649\n","Train_dice: 0.9353\n","88/222, Train_loss: 0.0522\n","Train_dice: 0.9551\n","89/222, Train_loss: 0.0673\n","Train_dice: 0.9381\n","90/222, Train_loss: 0.0778\n","Train_dice: 0.9246\n","91/222, Train_loss: 0.0565\n","Train_dice: 0.9445\n","92/222, Train_loss: 0.0619\n","Train_dice: 0.9436\n","93/222, Train_loss: 0.0728\n","Train_dice: 0.9337\n","94/222, Train_loss: 0.0724\n","Train_dice: 0.9355\n","95/222, Train_loss: 0.1005\n","Train_dice: 0.9091\n","96/222, Train_loss: 0.0544\n","Train_dice: 0.9524\n","97/222, Train_loss: 0.0639\n","Train_dice: 0.9400\n","98/222, Train_loss: 0.0642\n","Train_dice: 0.9336\n","99/222, Train_loss: 0.0562\n","Train_dice: 0.9479\n","100/222, Train_loss: 0.0690\n","Train_dice: 0.9323\n","101/222, Train_loss: 0.0506\n","Train_dice: 0.9522\n","102/222, Train_loss: 0.0502\n","Train_dice: 0.9527\n","103/222, Train_loss: 0.0606\n","Train_dice: 0.9499\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0532\n","Train_dice: 0.9354\n","106/222, Train_loss: 0.0619\n","Train_dice: 0.9414\n","107/222, Train_loss: 0.0602\n","Train_dice: 0.9421\n","108/222, Train_loss: 0.0642\n","Train_dice: 0.9360\n","109/222, Train_loss: 0.0521\n","Train_dice: 0.9499\n","110/222, Train_loss: 0.0558\n","Train_dice: 0.9458\n","111/222, Train_loss: 0.0572\n","Train_dice: 0.9499\n","112/222, Train_loss: 0.0625\n","Train_dice: 0.9452\n","113/222, Train_loss: 0.0566\n","Train_dice: 0.9507\n","114/222, Train_loss: 0.0700\n","Train_dice: 0.9310\n","115/222, Train_loss: 0.0594\n","Train_dice: 0.9468\n","116/222, Train_loss: 0.0515\n","Train_dice: 0.9521\n","117/222, Train_loss: 0.0615\n","Train_dice: 0.9475\n","118/222, Train_loss: 0.0720\n","Train_dice: 0.9284\n","119/222, Train_loss: 0.0630\n","Train_dice: 0.9370\n","120/222, Train_loss: 0.0524\n","Train_dice: 0.9571\n","121/222, Train_loss: 0.0579\n","Train_dice: 0.9491\n","122/222, Train_loss: 0.0563\n","Train_dice: 0.9539\n","123/222, Train_loss: 0.0536\n","Train_dice: 0.9501\n","124/222, Train_loss: 0.0664\n","Train_dice: 0.8695\n","125/222, Train_loss: 0.0508\n","Train_dice: 0.9468\n","126/222, Train_loss: 0.0784\n","Train_dice: 0.9250\n","127/222, Train_loss: 0.0541\n","Train_dice: 0.9450\n","128/222, Train_loss: 0.0751\n","Train_dice: 0.9358\n","129/222, Train_loss: 0.0478\n","Train_dice: 0.9610\n","130/222, Train_loss: 0.0526\n","Train_dice: 0.9497\n","131/222, Train_loss: 0.0431\n","Train_dice: 0.9637\n","132/222, Train_loss: 0.0582\n","Train_dice: 0.9504\n","133/222, Train_loss: 0.0531\n","Train_dice: 0.9502\n","134/222, Train_loss: 0.0626\n","Train_dice: 0.9416\n","135/222, Train_loss: 0.0529\n","Train_dice: 0.9527\n","136/222, Train_loss: 0.0637\n","Train_dice: 0.9419\n","137/222, Train_loss: 0.0543\n","Train_dice: 0.9498\n","138/222, Train_loss: 0.0578\n","Train_dice: 0.9518\n","139/222, Train_loss: 0.0577\n","Train_dice: 0.9486\n","140/222, Train_loss: 0.0505\n","Train_dice: 0.9575\n","141/222, Train_loss: 0.0587\n","Train_dice: 0.9505\n","142/222, Train_loss: 0.0573\n","Train_dice: 0.9518\n","143/222, Train_loss: 0.0542\n","Train_dice: 0.9536\n","144/222, Train_loss: 0.0440\n","Train_dice: 0.9601\n","145/222, Train_loss: 0.0506\n","Train_dice: 0.9528\n","146/222, Train_loss: 0.0615\n","Train_dice: 0.9408\n","147/222, Train_loss: 0.0519\n","Train_dice: 0.9545\n","148/222, Train_loss: 0.0510\n","Train_dice: 0.9556\n","149/222, Train_loss: 0.0868\n","Train_dice: 0.9130\n","150/222, Train_loss: 0.0677\n","Train_dice: 0.9329\n","151/222, Train_loss: 0.0599\n","Train_dice: 0.9404\n","152/222, Train_loss: 0.0744\n","Train_dice: 0.9338\n","153/222, Train_loss: 0.0620\n","Train_dice: 0.9464\n","154/222, Train_loss: 0.0828\n","Train_dice: 0.9120\n","155/222, Train_loss: 0.0643\n","Train_dice: 0.9448\n","156/222, Train_loss: 0.0587\n","Train_dice: 0.9379\n","157/222, Train_loss: 0.0600\n","Train_dice: 0.9442\n","158/222, Train_loss: 0.0619\n","Train_dice: 0.9437\n","159/222, Train_loss: 0.0612\n","Train_dice: 0.9368\n","160/222, Train_loss: 0.0532\n","Train_dice: 0.9526\n","161/222, Train_loss: 0.0476\n","Train_dice: 0.9366\n","162/222, Train_loss: 0.0489\n","Train_dice: 0.9556\n","163/222, Train_loss: 0.0487\n","Train_dice: 0.9531\n","164/222, Train_loss: 0.0535\n","Train_dice: 0.9558\n","165/222, Train_loss: 0.0616\n","Train_dice: 0.9378\n","166/222, Train_loss: 0.0463\n","Train_dice: 0.9593\n","167/222, Train_loss: 0.0499\n","Train_dice: 0.9540\n","168/222, Train_loss: 0.0688\n","Train_dice: 0.9363\n","169/222, Train_loss: 0.0472\n","Train_dice: 0.9560\n","170/222, Train_loss: 0.0727\n","Train_dice: 0.9381\n","171/222, Train_loss: 0.0607\n","Train_dice: 0.9372\n","172/222, Train_loss: 0.0429\n","Train_dice: 0.9579\n","173/222, Train_loss: 0.0992\n","Train_dice: 0.8993\n","174/222, Train_loss: 0.0795\n","Train_dice: 0.9280\n","175/222, Train_loss: 0.0577\n","Train_dice: 0.9441\n","176/222, Train_loss: 0.0534\n","Train_dice: 0.9488\n","177/222, Train_loss: 0.0684\n","Train_dice: 0.9326\n","178/222, Train_loss: 0.0771\n","Train_dice: 0.9303\n","179/222, Train_loss: 0.0630\n","Train_dice: 0.9413\n","180/222, Train_loss: 0.1355\n","Train_dice: 0.8238\n","181/222, Train_loss: 0.0836\n","Train_dice: 0.9226\n","182/222, Train_loss: 0.0485\n","Train_dice: 0.9588\n","183/222, Train_loss: 0.0543\n","Train_dice: 0.9281\n","184/222, Train_loss: 0.0550\n","Train_dice: 0.9525\n","185/222, Train_loss: 0.0454\n","Train_dice: 0.9640\n","186/222, Train_loss: 0.0656\n","Train_dice: 0.9455\n","187/222, Train_loss: 0.0603\n","Train_dice: 0.9474\n","188/222, Train_loss: 0.0694\n","Train_dice: 0.9421\n","189/222, Train_loss: 0.0677\n","Train_dice: 0.9338\n","190/222, Train_loss: 0.0550\n","Train_dice: 0.9547\n","191/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0434\n","Train_dice: 0.9631\n","195/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0570\n","Train_dice: 0.9527\n","197/222, Train_loss: 0.0793\n","Train_dice: 0.9074\n","198/222, Train_loss: 0.0456\n","Train_dice: 0.9626\n","199/222, Train_loss: 0.0638\n","Train_dice: 0.9431\n","200/222, Train_loss: 0.0525\n","Train_dice: 0.9528\n","201/222, Train_loss: 0.0590\n","Train_dice: 0.9453\n","202/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","203/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","204/222, Train_loss: 0.0593\n","Train_dice: 0.9461\n","205/222, Train_loss: 0.0684\n","Train_dice: 0.9375\n","206/222, Train_loss: 0.0534\n","Train_dice: 0.9551\n","207/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","208/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","209/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","210/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","211/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0661\n","Train_dice: 0.9384\n","214/222, Train_loss: 0.0369\n","Train_dice: 0.9658\n","215/222, Train_loss: 0.0468\n","Train_dice: 0.9597\n","216/222, Train_loss: 0.0533\n","Train_dice: 0.9506\n","217/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0674\n","Train_dice: 0.9344\n","219/222, Train_loss: 0.0556\n","Train_dice: 0.9475\n","220/222, Train_loss: 0.0701\n","Train_dice: 0.9101\n","221/222, Train_loss: 0.3241\n","Train_dice: 0.6087\n","222/222, Train_loss: 0.0485\n","Train_dice: 0.9524\n","--------------------\n","Epoch_loss: 0.0948\n","Epoch_metric: 0.9077\n","test_loss_epoch: 0.2113\n","test_dice_epoch: 0.8014\n","Confusion Matrix:\n","[[58300156    63378]\n"," [  174590   182132]]\n","test_loss_epoch: 0.0038\n","test_dice_epoch: 0.0143\n","current epoch: 41 current mean dice: 0.8820\n","best mean dice: 0.0143 at epoch: 40\n","----------\n","epoch 42/150\n","1/222, Train_loss: 0.0484\n","Train_dice: 0.9573\n","2/222, Train_loss: 0.0621\n","Train_dice: 0.9481\n","3/222, Train_loss: 0.0476\n","Train_dice: 0.9601\n","4/222, Train_loss: 0.0348\n","Train_dice: 0.9706\n","5/222, Train_loss: 0.0608\n","Train_dice: 0.9505\n","6/222, Train_loss: 0.0608\n","Train_dice: 0.9502\n","7/222, Train_loss: 0.0541\n","Train_dice: 0.9568\n","8/222, Train_loss: 0.0471\n","Train_dice: 0.9610\n","9/222, Train_loss: 0.0450\n","Train_dice: 0.9604\n","10/222, Train_loss: 0.0568\n","Train_dice: 0.9540\n","11/222, Train_loss: 0.0535\n","Train_dice: 0.9584\n","12/222, Train_loss: 0.0531\n","Train_dice: 0.9575\n","13/222, Train_loss: 0.0672\n","Train_dice: 0.9474\n","14/222, Train_loss: 0.0583\n","Train_dice: 0.9528\n","15/222, Train_loss: 0.0626\n","Train_dice: 0.9428\n","16/222, Train_loss: 0.0633\n","Train_dice: 0.9424\n","17/222, Train_loss: 0.0670\n","Train_dice: 0.9447\n","18/222, Train_loss: 0.0413\n","Train_dice: 0.9635\n","19/222, Train_loss: 0.0529\n","Train_dice: 0.9523\n","20/222, Train_loss: 0.0746\n","Train_dice: 0.9313\n","21/222, Train_loss: 0.0701\n","Train_dice: 0.9392\n","22/222, Train_loss: 0.0590\n","Train_dice: 0.9508\n","23/222, Train_loss: 0.0499\n","Train_dice: 0.9531\n","24/222, Train_loss: 0.0642\n","Train_dice: 0.9389\n","25/222, Train_loss: 0.1046\n","Train_dice: 0.8375\n","26/222, Train_loss: 0.0484\n","Train_dice: 0.9586\n","27/222, Train_loss: 0.0571\n","Train_dice: 0.9478\n","28/222, Train_loss: 0.0674\n","Train_dice: 0.9154\n","29/222, Train_loss: 0.0542\n","Train_dice: 0.9494\n","30/222, Train_loss: 0.0618\n","Train_dice: 0.9417\n","31/222, Train_loss: 0.0619\n","Train_dice: 0.9421\n","32/222, Train_loss: 0.0458\n","Train_dice: 0.9540\n","33/222, Train_loss: 0.0625\n","Train_dice: 0.9421\n","34/222, Train_loss: 0.0677\n","Train_dice: 0.9394\n","35/222, Train_loss: 0.0435\n","Train_dice: 0.9597\n","36/222, Train_loss: 0.0692\n","Train_dice: 0.9394\n","37/222, Train_loss: 0.0567\n","Train_dice: 0.9499\n","38/222, Train_loss: 0.0897\n","Train_dice: 0.9150\n","39/222, Train_loss: 0.0408\n","Train_dice: 0.9667\n","40/222, Train_loss: 0.0486\n","Train_dice: 0.9578\n","41/222, Train_loss: 0.1076\n","Train_dice: 0.8895\n","42/222, Train_loss: 0.0694\n","Train_dice: 0.9425\n","43/222, Train_loss: 0.0529\n","Train_dice: 0.9584\n","44/222, Train_loss: 0.0741\n","Train_dice: 0.8575\n","45/222, Train_loss: 0.0484\n","Train_dice: 0.9576\n","46/222, Train_loss: 0.0510\n","Train_dice: 0.9577\n","47/222, Train_loss: 0.0507\n","Train_dice: 0.9544\n","48/222, Train_loss: 0.0638\n","Train_dice: 0.9476\n","49/222, Train_loss: 0.0585\n","Train_dice: 0.9523\n","50/222, Train_loss: 0.0562\n","Train_dice: 0.9439\n","51/222, Train_loss: 0.1119\n","Train_dice: 0.7486\n","52/222, Train_loss: 0.0584\n","Train_dice: 0.9455\n","53/222, Train_loss: 0.0485\n","Train_dice: 0.9604\n","54/222, Train_loss: 0.0568\n","Train_dice: 0.9537\n","55/222, Train_loss: 0.0493\n","Train_dice: 0.9583\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0506\n","Train_dice: 0.9573\n","58/222, Train_loss: 0.0595\n","Train_dice: 0.9481\n","59/222, Train_loss: 0.5002\n","Train_dice: 0.4998\n","60/222, Train_loss: 0.0556\n","Train_dice: 0.9532\n","61/222, Train_loss: 0.0566\n","Train_dice: 0.9510\n","62/222, Train_loss: 0.0611\n","Train_dice: 0.9480\n","63/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","64/222, Train_loss: 0.0578\n","Train_dice: 0.9478\n","65/222, Train_loss: 0.0556\n","Train_dice: 0.9511\n","66/222, Train_loss: 0.0494\n","Train_dice: 0.9579\n","67/222, Train_loss: 0.0623\n","Train_dice: 0.9464\n","68/222, Train_loss: 0.0641\n","Train_dice: 0.9424\n","69/222, Train_loss: 0.0476\n","Train_dice: 0.9584\n","70/222, Train_loss: 0.0434\n","Train_dice: 0.9636\n","71/222, Train_loss: 0.0643\n","Train_dice: 0.9389\n","72/222, Train_loss: 0.0523\n","Train_dice: 0.9544\n","73/222, Train_loss: 0.0521\n","Train_dice: 0.9563\n","74/222, Train_loss: 0.0549\n","Train_dice: 0.9517\n","75/222, Train_loss: 0.0416\n","Train_dice: 0.9650\n","76/222, Train_loss: 0.0962\n","Train_dice: 0.9133\n","77/222, Train_loss: 0.0684\n","Train_dice: 0.9357\n","78/222, Train_loss: 0.0553\n","Train_dice: 0.9501\n","79/222, Train_loss: 0.0712\n","Train_dice: 0.9334\n","80/222, Train_loss: 0.0860\n","Train_dice: 0.9171\n","81/222, Train_loss: 0.0439\n","Train_dice: 0.9611\n","82/222, Train_loss: 0.0558\n","Train_dice: 0.9479\n","83/222, Train_loss: 0.0581\n","Train_dice: 0.9517\n","84/222, Train_loss: 0.0578\n","Train_dice: 0.9487\n","85/222, Train_loss: 0.0637\n","Train_dice: 0.9453\n","86/222, Train_loss: 0.0823\n","Train_dice: 0.9182\n","87/222, Train_loss: 0.0640\n","Train_dice: 0.9368\n","88/222, Train_loss: 0.0519\n","Train_dice: 0.9544\n","89/222, Train_loss: 0.0609\n","Train_dice: 0.9448\n","90/222, Train_loss: 0.0753\n","Train_dice: 0.9275\n","91/222, Train_loss: 0.0554\n","Train_dice: 0.9471\n","92/222, Train_loss: 0.0528\n","Train_dice: 0.9545\n","93/222, Train_loss: 0.0686\n","Train_dice: 0.9381\n","94/222, Train_loss: 0.0603\n","Train_dice: 0.9438\n","95/222, Train_loss: 0.1107\n","Train_dice: 0.8907\n","96/222, Train_loss: 0.0601\n","Train_dice: 0.9433\n","97/222, Train_loss: 0.0626\n","Train_dice: 0.9420\n","98/222, Train_loss: 0.0674\n","Train_dice: 0.9264\n","99/222, Train_loss: 0.0542\n","Train_dice: 0.9542\n","100/222, Train_loss: 0.0638\n","Train_dice: 0.9392\n","101/222, Train_loss: 0.0508\n","Train_dice: 0.9532\n","102/222, Train_loss: 0.0497\n","Train_dice: 0.9573\n","103/222, Train_loss: 0.0596\n","Train_dice: 0.9520\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0396\n","Train_dice: 0.9501\n","106/222, Train_loss: 0.0566\n","Train_dice: 0.9430\n","107/222, Train_loss: 0.0559\n","Train_dice: 0.9493\n","108/222, Train_loss: 0.0601\n","Train_dice: 0.9439\n","109/222, Train_loss: 0.0544\n","Train_dice: 0.9494\n","110/222, Train_loss: 0.0711\n","Train_dice: 0.9341\n","111/222, Train_loss: 0.0612\n","Train_dice: 0.9403\n","112/222, Train_loss: 0.0576\n","Train_dice: 0.9523\n","113/222, Train_loss: 0.0630\n","Train_dice: 0.9462\n","114/222, Train_loss: 0.0680\n","Train_dice: 0.9324\n","115/222, Train_loss: 0.0493\n","Train_dice: 0.9575\n","116/222, Train_loss: 0.0508\n","Train_dice: 0.9547\n","117/222, Train_loss: 0.0642\n","Train_dice: 0.9410\n","118/222, Train_loss: 0.0692\n","Train_dice: 0.9298\n","119/222, Train_loss: 0.0610\n","Train_dice: 0.9429\n","120/222, Train_loss: 0.0483\n","Train_dice: 0.9588\n","121/222, Train_loss: 0.0555\n","Train_dice: 0.9533\n","122/222, Train_loss: 0.0529\n","Train_dice: 0.9546\n","123/222, Train_loss: 0.0548\n","Train_dice: 0.9482\n","124/222, Train_loss: 0.0868\n","Train_dice: 0.8567\n","125/222, Train_loss: 0.0712\n","Train_dice: 0.9289\n","126/222, Train_loss: 0.0712\n","Train_dice: 0.9379\n","127/222, Train_loss: 0.0593\n","Train_dice: 0.9377\n","128/222, Train_loss: 0.0684\n","Train_dice: 0.9417\n","129/222, Train_loss: 0.0473\n","Train_dice: 0.9595\n","130/222, Train_loss: 0.0519\n","Train_dice: 0.9554\n","131/222, Train_loss: 0.0427\n","Train_dice: 0.9634\n","132/222, Train_loss: 0.0551\n","Train_dice: 0.9516\n","133/222, Train_loss: 0.0524\n","Train_dice: 0.9502\n","134/222, Train_loss: 0.0617\n","Train_dice: 0.9434\n","135/222, Train_loss: 0.0505\n","Train_dice: 0.9586\n","136/222, Train_loss: 0.0468\n","Train_dice: 0.9600\n","137/222, Train_loss: 0.0479\n","Train_dice: 0.9579\n","138/222, Train_loss: 0.0586\n","Train_dice: 0.9521\n","139/222, Train_loss: 0.0552\n","Train_dice: 0.9523\n","140/222, Train_loss: 0.0552\n","Train_dice: 0.9504\n","141/222, Train_loss: 0.0551\n","Train_dice: 0.9531\n","142/222, Train_loss: 0.0502\n","Train_dice: 0.9561\n","143/222, Train_loss: 0.0513\n","Train_dice: 0.9558\n","144/222, Train_loss: 0.0470\n","Train_dice: 0.9584\n","145/222, Train_loss: 0.0566\n","Train_dice: 0.9530\n","146/222, Train_loss: 0.0593\n","Train_dice: 0.9440\n","147/222, Train_loss: 0.0608\n","Train_dice: 0.9465\n","148/222, Train_loss: 0.0477\n","Train_dice: 0.9580\n","149/222, Train_loss: 0.0805\n","Train_dice: 0.9152\n","150/222, Train_loss: 0.0627\n","Train_dice: 0.9365\n","151/222, Train_loss: 0.0605\n","Train_dice: 0.9421\n","152/222, Train_loss: 0.0688\n","Train_dice: 0.9374\n","153/222, Train_loss: 0.0578\n","Train_dice: 0.9493\n","154/222, Train_loss: 0.0732\n","Train_dice: 0.9289\n","155/222, Train_loss: 0.0716\n","Train_dice: 0.9343\n","156/222, Train_loss: 0.0563\n","Train_dice: 0.9380\n","157/222, Train_loss: 0.0552\n","Train_dice: 0.9475\n","158/222, Train_loss: 0.0735\n","Train_dice: 0.9308\n","159/222, Train_loss: 0.0660\n","Train_dice: 0.9351\n","160/222, Train_loss: 0.0619\n","Train_dice: 0.9408\n","161/222, Train_loss: 0.0608\n","Train_dice: 0.9315\n","162/222, Train_loss: 0.0585\n","Train_dice: 0.9455\n","163/222, Train_loss: 0.0579\n","Train_dice: 0.9407\n","164/222, Train_loss: 0.0604\n","Train_dice: 0.9424\n","165/222, Train_loss: 0.0608\n","Train_dice: 0.9434\n","166/222, Train_loss: 0.0490\n","Train_dice: 0.9551\n","167/222, Train_loss: 0.0481\n","Train_dice: 0.9595\n","168/222, Train_loss: 0.0554\n","Train_dice: 0.9496\n","169/222, Train_loss: 0.0490\n","Train_dice: 0.9569\n","170/222, Train_loss: 0.0672\n","Train_dice: 0.9447\n","171/222, Train_loss: 0.0617\n","Train_dice: 0.9291\n","172/222, Train_loss: 0.0486\n","Train_dice: 0.9565\n","173/222, Train_loss: 0.1039\n","Train_dice: 0.8881\n","174/222, Train_loss: 0.0891\n","Train_dice: 0.9251\n","175/222, Train_loss: 0.0943\n","Train_dice: 0.9207\n","176/222, Train_loss: 0.0632\n","Train_dice: 0.9490\n","177/222, Train_loss: 0.0761\n","Train_dice: 0.9318\n","178/222, Train_loss: 0.0863\n","Train_dice: 0.9257\n","179/222, Train_loss: 0.0733\n","Train_dice: 0.9394\n","180/222, Train_loss: 0.1075\n","Train_dice: 0.8538\n","181/222, Train_loss: 0.0714\n","Train_dice: 0.9335\n","182/222, Train_loss: 0.0510\n","Train_dice: 0.9558\n","183/222, Train_loss: 0.0594\n","Train_dice: 0.9242\n","184/222, Train_loss: 0.0588\n","Train_dice: 0.9467\n","185/222, Train_loss: 0.0485\n","Train_dice: 0.9575\n","186/222, Train_loss: 0.0628\n","Train_dice: 0.9422\n","187/222, Train_loss: 0.0585\n","Train_dice: 0.9403\n","188/222, Train_loss: 0.0674\n","Train_dice: 0.9400\n","189/222, Train_loss: 0.0627\n","Train_dice: 0.9388\n","190/222, Train_loss: 0.0575\n","Train_dice: 0.9446\n","191/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","194/222, Train_loss: 0.0488\n","Train_dice: 0.9578\n","195/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0544\n","Train_dice: 0.9522\n","197/222, Train_loss: 0.0815\n","Train_dice: 0.9037\n","198/222, Train_loss: 0.0494\n","Train_dice: 0.9592\n","199/222, Train_loss: 0.0755\n","Train_dice: 0.9292\n","200/222, Train_loss: 0.0506\n","Train_dice: 0.9510\n","201/222, Train_loss: 0.0618\n","Train_dice: 0.9430\n","202/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","203/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","204/222, Train_loss: 0.0575\n","Train_dice: 0.9510\n","205/222, Train_loss: 0.0706\n","Train_dice: 0.9363\n","206/222, Train_loss: 0.0567\n","Train_dice: 0.9505\n","207/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","208/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","209/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","210/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","211/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0737\n","Train_dice: 0.9382\n","214/222, Train_loss: 0.0350\n","Train_dice: 0.9729\n","215/222, Train_loss: 0.0542\n","Train_dice: 0.9595\n","216/222, Train_loss: 0.0515\n","Train_dice: 0.9560\n","217/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0651\n","Train_dice: 0.9428\n","219/222, Train_loss: 0.0505\n","Train_dice: 0.9556\n","220/222, Train_loss: 0.0574\n","Train_dice: 0.9290\n","221/222, Train_loss: 0.2944\n","Train_dice: 0.6171\n","222/222, Train_loss: 0.0432\n","Train_dice: 0.9573\n","--------------------\n","Epoch_loss: 0.0951\n","Epoch_metric: 0.9076\n","test_loss_epoch: 0.2143\n","test_dice_epoch: 0.7989\n","Confusion Matrix:\n","[[58304989    58545]\n"," [  180203   176519]]\n","test_loss_epoch: 0.0038\n","test_dice_epoch: 0.0143\n","current epoch: 42 current mean dice: 0.8731\n","best mean dice: 0.0143 at epoch: 40\n","----------\n","epoch 43/150\n","1/222, Train_loss: 0.0451\n","Train_dice: 0.9632\n","2/222, Train_loss: 0.0635\n","Train_dice: 0.9457\n","3/222, Train_loss: 0.0504\n","Train_dice: 0.9551\n","4/222, Train_loss: 0.0374\n","Train_dice: 0.9661\n","5/222, Train_loss: 0.0561\n","Train_dice: 0.9538\n","6/222, Train_loss: 0.0582\n","Train_dice: 0.9498\n","7/222, Train_loss: 0.0480\n","Train_dice: 0.9582\n","8/222, Train_loss: 0.0469\n","Train_dice: 0.9596\n","9/222, Train_loss: 0.0485\n","Train_dice: 0.9564\n","10/222, Train_loss: 0.0520\n","Train_dice: 0.9538\n","11/222, Train_loss: 0.0476\n","Train_dice: 0.9603\n","12/222, Train_loss: 0.0528\n","Train_dice: 0.9575\n","13/222, Train_loss: 0.0576\n","Train_dice: 0.9513\n","14/222, Train_loss: 0.0576\n","Train_dice: 0.9532\n","15/222, Train_loss: 0.0560\n","Train_dice: 0.9533\n","16/222, Train_loss: 0.0721\n","Train_dice: 0.9345\n","17/222, Train_loss: 0.0597\n","Train_dice: 0.9501\n","18/222, Train_loss: 0.0605\n","Train_dice: 0.9549\n","19/222, Train_loss: 0.0511\n","Train_dice: 0.9541\n","20/222, Train_loss: 0.0752\n","Train_dice: 0.9281\n","21/222, Train_loss: 0.0543\n","Train_dice: 0.9466\n","22/222, Train_loss: 0.0637\n","Train_dice: 0.9477\n","23/222, Train_loss: 0.0496\n","Train_dice: 0.9594\n","24/222, Train_loss: 0.0648\n","Train_dice: 0.9407\n","25/222, Train_loss: 0.1239\n","Train_dice: 0.8441\n","26/222, Train_loss: 0.0539\n","Train_dice: 0.9568\n","27/222, Train_loss: 0.0512\n","Train_dice: 0.9589\n","28/222, Train_loss: 0.0713\n","Train_dice: 0.9069\n","29/222, Train_loss: 0.0539\n","Train_dice: 0.9560\n","30/222, Train_loss: 0.0611\n","Train_dice: 0.9386\n","31/222, Train_loss: 0.0657\n","Train_dice: 0.9428\n","32/222, Train_loss: 0.0453\n","Train_dice: 0.9620\n","33/222, Train_loss: 0.0603\n","Train_dice: 0.9506\n","34/222, Train_loss: 0.0644\n","Train_dice: 0.9454\n","35/222, Train_loss: 0.0470\n","Train_dice: 0.9643\n","36/222, Train_loss: 0.0651\n","Train_dice: 0.9437\n","37/222, Train_loss: 0.0525\n","Train_dice: 0.9566\n","38/222, Train_loss: 0.0721\n","Train_dice: 0.9342\n","39/222, Train_loss: 0.0402\n","Train_dice: 0.9659\n","40/222, Train_loss: 0.0427\n","Train_dice: 0.9606\n","41/222, Train_loss: 0.1026\n","Train_dice: 0.8904\n","42/222, Train_loss: 0.0648\n","Train_dice: 0.9447\n","43/222, Train_loss: 0.0443\n","Train_dice: 0.9629\n","44/222, Train_loss: 0.0776\n","Train_dice: 0.8503\n","45/222, Train_loss: 0.0551\n","Train_dice: 0.9458\n","46/222, Train_loss: 0.0535\n","Train_dice: 0.9526\n","47/222, Train_loss: 0.0454\n","Train_dice: 0.9566\n","48/222, Train_loss: 0.0488\n","Train_dice: 0.9553\n","49/222, Train_loss: 0.0664\n","Train_dice: 0.9369\n","50/222, Train_loss: 0.0516\n","Train_dice: 0.9530\n","51/222, Train_loss: 0.1223\n","Train_dice: 0.7632\n","52/222, Train_loss: 0.0592\n","Train_dice: 0.9459\n","53/222, Train_loss: 0.0483\n","Train_dice: 0.9593\n","54/222, Train_loss: 0.0539\n","Train_dice: 0.9551\n","55/222, Train_loss: 0.0529\n","Train_dice: 0.9575\n","56/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","57/222, Train_loss: 0.0524\n","Train_dice: 0.9554\n","58/222, Train_loss: 0.0542\n","Train_dice: 0.9538\n","59/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","60/222, Train_loss: 0.0525\n","Train_dice: 0.9537\n","61/222, Train_loss: 0.0505\n","Train_dice: 0.9595\n","62/222, Train_loss: 0.0677\n","Train_dice: 0.9446\n","63/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","64/222, Train_loss: 0.0687\n","Train_dice: 0.9415\n","65/222, Train_loss: 0.0626\n","Train_dice: 0.9500\n","66/222, Train_loss: 0.0499\n","Train_dice: 0.9577\n","67/222, Train_loss: 0.0650\n","Train_dice: 0.9435\n","68/222, Train_loss: 0.0557\n","Train_dice: 0.9529\n","69/222, Train_loss: 0.0446\n","Train_dice: 0.9603\n","70/222, Train_loss: 0.0479\n","Train_dice: 0.9598\n","71/222, Train_loss: 0.0618\n","Train_dice: 0.9420\n","72/222, Train_loss: 0.0434\n","Train_dice: 0.9646\n","73/222, Train_loss: 0.0524\n","Train_dice: 0.9528\n","74/222, Train_loss: 0.0567\n","Train_dice: 0.9485\n","75/222, Train_loss: 0.0484\n","Train_dice: 0.9578\n","76/222, Train_loss: 0.1291\n","Train_dice: 0.8733\n","77/222, Train_loss: 0.0663\n","Train_dice: 0.9400\n","78/222, Train_loss: 0.0552\n","Train_dice: 0.9538\n","79/222, Train_loss: 0.0737\n","Train_dice: 0.9309\n","80/222, Train_loss: 0.0610\n","Train_dice: 0.9429\n","81/222, Train_loss: 0.0470\n","Train_dice: 0.9589\n","82/222, Train_loss: 0.0524\n","Train_dice: 0.9507\n","83/222, Train_loss: 0.0513\n","Train_dice: 0.9542\n","84/222, Train_loss: 0.0601\n","Train_dice: 0.9480\n","85/222, Train_loss: 0.0609\n","Train_dice: 0.9513\n","86/222, Train_loss: 0.0647\n","Train_dice: 0.9326\n","87/222, Train_loss: 0.0580\n","Train_dice: 0.9485\n","88/222, Train_loss: 0.0541\n","Train_dice: 0.9539\n","89/222, Train_loss: 0.0595\n","Train_dice: 0.9502\n","90/222, Train_loss: 0.0858\n","Train_dice: 0.9197\n","91/222, Train_loss: 0.0544\n","Train_dice: 0.9487\n","92/222, Train_loss: 0.0494\n","Train_dice: 0.9586\n","93/222, Train_loss: 0.0636\n","Train_dice: 0.9431\n","94/222, Train_loss: 0.0581\n","Train_dice: 0.9447\n","95/222, Train_loss: 0.0885\n","Train_dice: 0.9163\n","96/222, Train_loss: 0.0555\n","Train_dice: 0.9470\n","97/222, Train_loss: 0.0642\n","Train_dice: 0.9392\n","98/222, Train_loss: 0.0641\n","Train_dice: 0.9343\n","99/222, Train_loss: 0.0570\n","Train_dice: 0.9488\n","100/222, Train_loss: 0.0662\n","Train_dice: 0.9333\n","101/222, Train_loss: 0.0550\n","Train_dice: 0.9468\n","102/222, Train_loss: 0.0489\n","Train_dice: 0.9555\n","103/222, Train_loss: 0.0562\n","Train_dice: 0.9521\n","104/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","105/222, Train_loss: 0.0421\n","Train_dice: 0.9460\n","106/222, Train_loss: 0.0513\n","Train_dice: 0.9504\n","107/222, Train_loss: 0.0659\n","Train_dice: 0.9368\n","108/222, Train_loss: 0.0556\n","Train_dice: 0.9468\n","109/222, Train_loss: 0.0588\n","Train_dice: 0.9454\n","110/222, Train_loss: 0.0555\n","Train_dice: 0.9432\n","111/222, Train_loss: 0.0577\n","Train_dice: 0.9425\n","112/222, Train_loss: 0.0578\n","Train_dice: 0.9521\n","113/222, Train_loss: 0.0532\n","Train_dice: 0.9543\n","114/222, Train_loss: 0.0725\n","Train_dice: 0.9290\n","115/222, Train_loss: 0.0510\n","Train_dice: 0.9584\n","116/222, Train_loss: 0.0471\n","Train_dice: 0.9601\n","117/222, Train_loss: 0.0613\n","Train_dice: 0.9483\n","118/222, Train_loss: 0.0857\n","Train_dice: 0.9234\n","119/222, Train_loss: 0.0747\n","Train_dice: 0.9331\n","120/222, Train_loss: 0.0489\n","Train_dice: 0.9614\n","121/222, Train_loss: 0.0580\n","Train_dice: 0.9483\n","122/222, Train_loss: 0.0548\n","Train_dice: 0.9545\n","123/222, Train_loss: 0.0485\n","Train_dice: 0.9541\n","124/222, Train_loss: 0.0590\n","Train_dice: 0.8780\n","125/222, Train_loss: 0.0555\n","Train_dice: 0.9442\n","126/222, Train_loss: 0.0690\n","Train_dice: 0.9358\n","127/222, Train_loss: 0.0553\n","Train_dice: 0.9453\n","128/222, Train_loss: 0.0688\n","Train_dice: 0.9388\n","129/222, Train_loss: 0.0481\n","Train_dice: 0.9572\n","130/222, Train_loss: 0.0593\n","Train_dice: 0.9398\n","131/222, Train_loss: 0.0484\n","Train_dice: 0.9562\n","132/222, Train_loss: 0.0521\n","Train_dice: 0.9522\n","133/222, Train_loss: 0.0675\n","Train_dice: 0.9334\n","134/222, Train_loss: 0.0730\n","Train_dice: 0.9322\n","135/222, Train_loss: 0.0513\n","Train_dice: 0.9548\n","136/222, Train_loss: 0.0519\n","Train_dice: 0.9537\n","137/222, Train_loss: 0.0497\n","Train_dice: 0.9505\n","138/222, Train_loss: 0.0592\n","Train_dice: 0.9500\n","139/222, Train_loss: 0.0569\n","Train_dice: 0.9515\n","140/222, Train_loss: 0.0509\n","Train_dice: 0.9563\n","141/222, Train_loss: 0.0521\n","Train_dice: 0.9562\n","142/222, Train_loss: 0.0545\n","Train_dice: 0.9536\n","143/222, Train_loss: 0.0591\n","Train_dice: 0.9480\n","144/222, Train_loss: 0.0554\n","Train_dice: 0.9548\n","145/222, Train_loss: 0.0543\n","Train_dice: 0.9546\n","146/222, Train_loss: 0.0735\n","Train_dice: 0.9366\n","147/222, Train_loss: 0.0502\n","Train_dice: 0.9568\n","148/222, Train_loss: 0.0499\n","Train_dice: 0.9577\n","149/222, Train_loss: 0.0888\n","Train_dice: 0.9162\n","150/222, Train_loss: 0.0661\n","Train_dice: 0.9400\n","151/222, Train_loss: 0.0588\n","Train_dice: 0.9394\n","152/222, Train_loss: 0.0687\n","Train_dice: 0.9391\n","153/222, Train_loss: 0.0686\n","Train_dice: 0.9350\n","154/222, Train_loss: 0.0866\n","Train_dice: 0.9094\n","155/222, Train_loss: 0.0665\n","Train_dice: 0.9377\n","156/222, Train_loss: 0.0524\n","Train_dice: 0.9444\n","157/222, Train_loss: 0.0606\n","Train_dice: 0.9445\n","158/222, Train_loss: 0.0642\n","Train_dice: 0.9393\n","159/222, Train_loss: 0.0618\n","Train_dice: 0.9412\n","160/222, Train_loss: 0.0471\n","Train_dice: 0.9584\n","161/222, Train_loss: 0.0505\n","Train_dice: 0.9374\n","162/222, Train_loss: 0.0612\n","Train_dice: 0.9385\n","163/222, Train_loss: 0.0583\n","Train_dice: 0.9414\n","164/222, Train_loss: 0.0613\n","Train_dice: 0.9410\n","165/222, Train_loss: 0.0695\n","Train_dice: 0.9273\n","166/222, Train_loss: 0.0467\n","Train_dice: 0.9583\n","167/222, Train_loss: 0.0497\n","Train_dice: 0.9521\n","168/222, Train_loss: 0.0751\n","Train_dice: 0.9273\n","169/222, Train_loss: 0.0489\n","Train_dice: 0.9542\n","170/222, Train_loss: 0.0569\n","Train_dice: 0.9496\n","171/222, Train_loss: 0.0532\n","Train_dice: 0.9393\n","172/222, Train_loss: 0.0396\n","Train_dice: 0.9608\n","173/222, Train_loss: 0.0894\n","Train_dice: 0.9046\n","174/222, Train_loss: 0.0922\n","Train_dice: 0.9163\n","175/222, Train_loss: 0.0638\n","Train_dice: 0.9394\n","176/222, Train_loss: 0.0540\n","Train_dice: 0.9513\n","177/222, Train_loss: 0.0650\n","Train_dice: 0.9387\n","178/222, Train_loss: 0.0814\n","Train_dice: 0.9291\n","179/222, Train_loss: 0.0725\n","Train_dice: 0.9436\n","180/222, Train_loss: 0.1063\n","Train_dice: 0.8506\n","181/222, Train_loss: 0.0815\n","Train_dice: 0.9275\n","182/222, Train_loss: 0.0606\n","Train_dice: 0.9522\n","183/222, Train_loss: 0.0662\n","Train_dice: 0.9156\n","184/222, Train_loss: 0.0592\n","Train_dice: 0.9473\n","185/222, Train_loss: 0.0473\n","Train_dice: 0.9610\n","186/222, Train_loss: 0.0608\n","Train_dice: 0.9490\n","187/222, Train_loss: 0.0435\n","Train_dice: 0.9611\n","188/222, Train_loss: 0.0537\n","Train_dice: 0.9564\n","189/222, Train_loss: 0.0584\n","Train_dice: 0.9481\n","190/222, Train_loss: 0.0560\n","Train_dice: 0.9504\n","191/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","192/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","193/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","194/222, Train_loss: 0.0466\n","Train_dice: 0.9607\n","195/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","196/222, Train_loss: 0.0567\n","Train_dice: 0.9472\n","197/222, Train_loss: 0.0721\n","Train_dice: 0.9098\n","198/222, Train_loss: 0.0426\n","Train_dice: 0.9634\n","199/222, Train_loss: 0.0656\n","Train_dice: 0.9372\n","200/222, Train_loss: 0.0495\n","Train_dice: 0.9539\n","201/222, Train_loss: 0.0570\n","Train_dice: 0.9449\n","202/222, Train_loss: 0.5001\n","Train_dice: 0.4999\n","203/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","204/222, Train_loss: 0.0609\n","Train_dice: 0.9482\n","205/222, Train_loss: 0.0722\n","Train_dice: 0.9304\n","206/222, Train_loss: 0.0547\n","Train_dice: 0.9553\n","207/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","208/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","209/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","210/222, Train_loss: 0.5002\n","Train_dice: 0.4999\n","211/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","212/222, Train_loss: 0.5001\n","Train_dice: 0.5000\n","213/222, Train_loss: 0.0648\n","Train_dice: 0.9388\n","214/222, Train_loss: 0.0289\n","Train_dice: 0.9741\n","215/222, Train_loss: 0.0497\n","Train_dice: 0.9592\n","216/222, Train_loss: 0.0538\n","Train_dice: 0.9502\n","217/222, Train_loss: 0.5000\n","Train_dice: 0.5000\n","218/222, Train_loss: 0.0531\n","Train_dice: 0.9513\n","219/222, Train_loss: 0.0627\n","Train_dice: 0.9461\n","220/222, Train_loss: 0.0612\n","Train_dice: 0.9236\n","221/222, Train_loss: 0.3000\n","Train_dice: 0.6011\n","222/222, Train_loss: 0.0449\n","Train_dice: 0.9591\n","--------------------\n","Epoch_loss: 0.0943\n","Epoch_metric: 0.9083\n","test_loss_epoch: 0.2172\n","test_dice_epoch: 0.7962\n","Confusion Matrix:\n","[[58308997    54537]\n"," [  183324   173398]]\n","test_loss_epoch: 0.0039\n","test_dice_epoch: 0.0142\n","current epoch: 43 current mean dice: 0.8443\n","best mean dice: 0.0143 at epoch: 40\n","----------\n","epoch 44/150\n","1/222, Train_loss: 0.0483\n","Train_dice: 0.9596\n","2/222, Train_loss: 0.0597\n","Train_dice: 0.9515\n","3/222, Train_loss: 0.0472\n","Train_dice: 0.9617\n","4/222, Train_loss: 0.0369\n","Train_dice: 0.9688\n","5/222, Train_loss: 0.0560\n","Train_dice: 0.9546\n","6/222, Train_loss: 0.0575\n","Train_dice: 0.9525\n","7/222, Train_loss: 0.0473\n","Train_dice: 0.9601\n","8/222, Train_loss: 0.0452\n","Train_dice: 0.9619\n","9/222, Train_loss: 0.0475\n","Train_dice: 0.9596\n","10/222, Train_loss: 0.0517\n","Train_dice: 0.9539\n","11/222, Train_loss: 0.0431\n","Train_dice: 0.9631\n","12/222, Train_loss: 0.0471\n","Train_dice: 0.9616\n","13/222, Train_loss: 0.0612\n","Train_dice: 0.9482\n","14/222, Train_loss: 0.0558\n","Train_dice: 0.9543\n","15/222, Train_loss: 0.0508\n","Train_dice: 0.9543\n","16/222, Train_loss: 0.0572\n","Train_dice: 0.9496\n","17/222, Train_loss: 0.0609\n","Train_dice: 0.9422\n","18/222, Train_loss: 0.0497\n","Train_dice: 0.9563\n","19/222, Train_loss: 0.0474\n","Train_dice: 0.9524\n","20/222, Train_loss: 0.0721\n","Train_dice: 0.9325\n","21/222, Train_loss: 0.0527\n","Train_dice: 0.9514\n","22/222, Train_loss: 0.0572\n","Train_dice: 0.9532\n","23/222, Train_loss: 0.0501\n","Train_dice: 0.9599\n","24/222, Train_loss: 0.0608\n","Train_dice: 0.9463\n","25/222, Train_loss: 0.0958\n","Train_dice: 0.8618\n","26/222, Train_loss: 0.0555\n","Train_dice: 0.9535\n","27/222, Train_loss: 0.0569\n","Train_dice: 0.9545\n","28/222, Train_loss: 0.0711\n","Train_dice: 0.9163\n","29/222, Train_loss: 0.0610\n","Train_dice: 0.9502\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-191985153b3b>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/final_utilities.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_in, loss, optim, max_epochs, model_dir, test_interval, device)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtrain_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mepoch_metric_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mtrain_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# dataset[[1, 3, 4]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfirst_random\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/transforms/compose.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_, start, end, threading, lazy)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         result = execute_compose(\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/transforms/compose.py\u001b[0m in \u001b[0;36mexecute_compose\u001b[0;34m(data, transforms, map_items, unpack_items, start, end, lazy, overrides, threading, log_stats)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0m_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mThreadUnsafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         data = apply_transform(\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmap_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_stats\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# if in debug mode, don't swallow exception so that the breakpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36m_apply_transform\u001b[0;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyTrait\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyTrait\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/final_preprocess.py\u001b[0m in \u001b[0;36mcombined_transforms\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcombined_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0menhanced_vol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"vol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0menhanced_vol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seg\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/final_preprocess.py\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(image, a_min, a_max)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# convert the PyTorch tensor to a NumPy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnormalized_image_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0menhanced_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexposure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalize_adapthist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_image_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0menhanced_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/color/adapt_rgb.py\u001b[0m in \u001b[0;36mimage_filter_adapted\u001b[0;34m(image, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimage_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage_filter_adapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/exposure/_adapthist.py\u001b[0m in \u001b[0;36mequalize_adapthist\u001b[0;34m(image, kernel_size, clip_limit, nbins)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clahe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrescale_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/exposure/_adapthist.py\u001b[0m in \u001b[0;36m_clahe\u001b[0;34m(image, kernel_size, clip_limit, nbins)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# apply map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0medge_mapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_maps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# interpolate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mtake_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","from torch import nn\n","from monai.losses import DiceLoss\n","from sklearn.metrics import confusion_matrix\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","args = {\n","    'model_name': 'UNet',\n","    'pretrained': True,\n","    'dropout': 0.1\n","}\n","model = get_model(args)\n","model = model.to(device)\n","\n","# loss_function = nn.CrossEntropyLoss().to(device)\n","loss_function = DiceLoss(to_onehot_y=True, softmax=True).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), 1e-4, amsgrad=True)\n","\n","if __name__ == '__main__':\n","    train(model, data_in, loss_function, optimizer, 150, model_dir)"]},{"cell_type":"markdown","metadata":{"id":"dBejD7L32MIz"},"source":["## Check the Size of Data (Add to main) - For Debugging"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qe9HMsaw3pk9"},"outputs":[],"source":["# assuming prepare function has been imported from another file\n","train_loader, test_loader = prepare(data_dir)\n","\n","for batch_data in  train_loader:\n","  volume = batch_data[\"vol\"]\n","  label = batch_data[\"seg\"]\n","\n","  # print size of volume and label tensors\n","  print(f\"Volume size: {volume.size()}\")\n","  print(f\"Label size: {label.size()}\")\n","\n","  # only process one batch\n","  break"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}